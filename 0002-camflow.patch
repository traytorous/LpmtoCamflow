From b182b8807648e65c87abee4619c665155234a958 Mon Sep 17 00:00:00 2001
From: Tray <Tray@gmail.com>
Date: Tue, 7 Dec 2021 18:09:08 -0500
Subject: [PATCH 2/2] camflow

Signed-off-by: Tray <Tray@gmail.com>
---
 include/linux/provenance_query.h              |   37 +
 include/linux/provenance_types.h              |   27 +
 include/net/_sock.h                           | 2833 +++++++++++++++
 include/uapi/linux/_xattr.h                   |   88 +
 include/uapi/linux/provenance.h               |  351 ++
 include/uapi/linux/provenance_fs.h            |  129 +
 include/uapi/linux/provenance_types.h         |  284 ++
 security/Kconfig                              |    9 +-
 security/_Kconfig                             |  307 ++
 security/_Makefile                            |   30 +
 security/provenance/Kconfig                   |   32 +
 security/provenance/Makefile                  |    8 +
 security/provenance/fs.c                      | 1159 ++++++
 security/provenance/hooks.c                   | 3237 +++++++++++++++++
 security/provenance/include/memcpy_ss.h       |   23 +
 security/provenance/include/provenance.h      |  306 ++
 .../provenance/include/provenance_filter.h    |  319 ++
 .../provenance/include/provenance_inode.h     |  604 +++
 .../provenance/include/provenance_machine.h   |   24 +
 security/provenance/include/provenance_net.h  |  411 +++
 security/provenance/include/provenance_ns.h   |  139 +
 .../provenance/include/provenance_policy.h    |   62 +
 .../provenance/include/provenance_query.h     |   97 +
 .../provenance/include/provenance_record.h    |  583 +++
 .../provenance/include/provenance_relay.h     |  189 +
 security/provenance/include/provenance_task.h |  582 +++
 .../provenance/include/provenance_utils.h     |   31 +
 security/provenance/machine.c                 |   51 +
 security/provenance/memcpy_ss.c               |   66 +
 security/provenance/netfilter.c               |  155 +
 security/provenance/propagate.c               |   43 +
 security/provenance/query.c                   |   49 +
 security/provenance/relay.c                   |  356 ++
 security/provenance/type.c                    |  547 +++
 34 files changed, 13160 insertions(+), 8 deletions(-)
 create mode 100644 include/linux/provenance_query.h
 create mode 100644 include/linux/provenance_types.h
 create mode 100644 include/net/_sock.h
 create mode 100644 include/uapi/linux/_xattr.h
 create mode 100644 include/uapi/linux/provenance.h
 create mode 100644 include/uapi/linux/provenance_fs.h
 create mode 100644 include/uapi/linux/provenance_types.h
 create mode 100644 security/_Kconfig
 create mode 100644 security/_Makefile
 create mode 100644 security/provenance/Kconfig
 create mode 100644 security/provenance/Makefile
 create mode 100644 security/provenance/fs.c
 create mode 100644 security/provenance/hooks.c
 create mode 100644 security/provenance/include/memcpy_ss.h
 create mode 100644 security/provenance/include/provenance.h
 create mode 100644 security/provenance/include/provenance_filter.h
 create mode 100644 security/provenance/include/provenance_inode.h
 create mode 100644 security/provenance/include/provenance_machine.h
 create mode 100644 security/provenance/include/provenance_net.h
 create mode 100644 security/provenance/include/provenance_ns.h
 create mode 100644 security/provenance/include/provenance_policy.h
 create mode 100644 security/provenance/include/provenance_query.h
 create mode 100644 security/provenance/include/provenance_record.h
 create mode 100644 security/provenance/include/provenance_relay.h
 create mode 100644 security/provenance/include/provenance_task.h
 create mode 100644 security/provenance/include/provenance_utils.h
 create mode 100644 security/provenance/machine.c
 create mode 100644 security/provenance/memcpy_ss.c
 create mode 100644 security/provenance/netfilter.c
 create mode 100644 security/provenance/propagate.c
 create mode 100644 security/provenance/query.c
 create mode 100644 security/provenance/relay.c
 create mode 100644 security/provenance/type.c

diff --git a/include/linux/provenance_query.h b/include/linux/provenance_query.h
new file mode 100644
index 000000000..b59ce646e
--- /dev/null
+++ b/include/linux/provenance_query.h
@@ -0,0 +1,37 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2020 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+ #ifndef _LINUX_PROVENANCE_QUERY_H
+ #define _LINUX_PROVENANCE_QUERY_H
+
+ #include <uapi/linux/provenance.h>
+
+ #define PROVENANCE_RAISE_WARNING       1
+ #define PROVENANCE_PREVENT_FLOW        2
+
+ #define QUERY_HOOK_INIT(HEAD, HOOK)    .HEAD = &HOOK
+
+struct provenance_query_hooks {
+	struct list_head list;
+	int (*flow)(prov_entry_t *, prov_entry_t *, prov_entry_t *);
+	int (*alloc)(prov_entry_t *);
+	int (*free)(prov_entry_t *);
+};
+
+extern struct list_head provenance_query_hooks;
+
+int register_provenance_query_hooks( struct provenance_query_hooks *hook);
+int unregister_provenance_query_hooks( struct provenance_query_hooks *hook);
+#endif
diff --git a/include/linux/provenance_types.h b/include/linux/provenance_types.h
new file mode 100644
index 000000000..396932985
--- /dev/null
+++ b/include/linux/provenance_types.h
@@ -0,0 +1,27 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2020 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+#ifndef _PROVENANCE_TYPES_H
+#define _PROVENANCE_TYPES_H
+
+#include <linux/types.h>
+#include <uapi/linux/provenance_types.h>
+
+const char *relation_str(uint64_t type);
+uint64_t relation_id(const char *str);
+const char *node_str(uint64_t type);
+uint64_t node_id(const char *str);
+
+#endif /* _PROVENANCE_TYPES_H */
diff --git a/include/net/_sock.h b/include/net/_sock.h
new file mode 100644
index 000000000..2e3a8fdd0
--- /dev/null
+++ b/include/net/_sock.h
@@ -0,0 +1,2833 @@
+/* SPDX-License-Identifier: GPL-2.0-or-later */
+/*
+ * INET		An implementation of the TCP/IP protocol suite for the LINUX
+ *		operating system.  INET is implemented using the  BSD Socket
+ *		interface as the means of communication with the user level.
+ *
+ *		Definitions for the AF_INET socket handler.
+ *
+ * Version:	@(#)sock.h	1.0.4	05/13/93
+ *
+ * Authors:	Ross Biro
+ *		Fred N. van Kempen, <waltje@uWalt.NL.Mugnet.ORG>
+ *		Corey Minyard <wf-rch!minyard@relay.EU.net>
+ *		Florian La Roche <flla@stud.uni-sb.de>
+ *
+ * Fixes:
+ *		Alan Cox	:	Volatiles in skbuff pointers. See
+ *					skbuff comments. May be overdone,
+ *					better to prove they can be removed
+ *					than the reverse.
+ *		Alan Cox	:	Added a zapped field for tcp to note
+ *					a socket is reset and must stay shut up
+ *		Alan Cox	:	New fields for options
+ *	Pauline Middelink	:	identd support
+ *		Alan Cox	:	Eliminate low level recv/recvfrom
+ *		David S. Miller	:	New socket lookup architecture.
+ *              Steve Whitehouse:       Default routines for sock_ops
+ *              Arnaldo C. Melo :	removed net_pinfo, tp_pinfo and made
+ *              			protinfo be just a void pointer, as the
+ *              			protocol specific parts were moved to
+ *              			respective headers and ipv4/v6, etc now
+ *              			use private slabcaches for its socks
+ *              Pedro Hortas	:	New flags field for socket options
+ */
+#ifndef _SOCK_H
+#define _SOCK_H
+
+#include <linux/hardirq.h>
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/list_nulls.h>
+#include <linux/timer.h>
+#include <linux/cache.h>
+#include <linux/bitops.h>
+#include <linux/lockdep.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>	/* struct sk_buff */
+#include <linux/mm.h>
+#include <linux/security.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/page_counter.h>
+#include <linux/memcontrol.h>
+#include <linux/static_key.h>
+#include <linux/sched.h>
+#include <linux/wait.h>
+#include <linux/cgroup-defs.h>
+#include <linux/rbtree.h>
+#include <linux/filter.h>
+#include <linux/rculist_nulls.h>
+#include <linux/poll.h>
+#include <linux/sockptr.h>
+#include <linux/indirect_call_wrapper.h>
+#include <linux/atomic.h>
+#include <linux/refcount.h>
+#include <net/dst.h>
+#include <net/checksum.h>
+#include <net/tcp_states.h>
+#include <linux/net_tstamp.h>
+#include <net/l3mdev.h>
+#include <uapi/linux/socket.h>
+
+/*
+ * This structure really needs to be cleaned up.
+ * Most of it is for TCP, and not used by any of
+ * the other protocols.
+ */
+
+/* Define this to get the SOCK_DBG debugging facility. */
+#define SOCK_DEBUGGING
+#ifdef SOCK_DEBUGGING
+#define SOCK_DEBUG(sk, msg...) do { if ((sk) && sock_flag((sk), SOCK_DBG)) \
+					printk(KERN_DEBUG msg); } while (0)
+#else
+/* Validate arguments and do nothing */
+static inline __printf(2, 3)
+void SOCK_DEBUG(const struct sock *sk, const char *msg, ...)
+{
+}
+#endif
+
+/* This is the per-socket lock.  The spinlock provides a synchronization
+ * between user contexts and software interrupt processing, whereas the
+ * mini-semaphore synchronizes multiple users amongst themselves.
+ */
+typedef struct {
+	spinlock_t		slock;
+	int			owned;
+	wait_queue_head_t	wq;
+	/*
+	 * We express the mutex-alike socket_lock semantics
+	 * to the lock validator by explicitly managing
+	 * the slock as a lock variant (in addition to
+	 * the slock itself):
+	 */
+#ifdef CONFIG_DEBUG_LOCK_ALLOC
+	struct lockdep_map dep_map;
+#endif
+} socket_lock_t;
+
+struct sock;
+struct proto;
+struct net;
+
+typedef __u32 __bitwise __portpair;
+typedef __u64 __bitwise __addrpair;
+
+/**
+ *	struct sock_common - minimal network layer representation of sockets
+ *	@skc_daddr: Foreign IPv4 addr
+ *	@skc_rcv_saddr: Bound local IPv4 addr
+ *	@skc_addrpair: 8-byte-aligned __u64 union of @skc_daddr & @skc_rcv_saddr
+ *	@skc_hash: hash value used with various protocol lookup tables
+ *	@skc_u16hashes: two u16 hash values used by UDP lookup tables
+ *	@skc_dport: placeholder for inet_dport/tw_dport
+ *	@skc_num: placeholder for inet_num/tw_num
+ *	@skc_portpair: __u32 union of @skc_dport & @skc_num
+ *	@skc_family: network address family
+ *	@skc_state: Connection state
+ *	@skc_reuse: %SO_REUSEADDR setting
+ *	@skc_reuseport: %SO_REUSEPORT setting
+ *	@skc_ipv6only: socket is IPV6 only
+ *	@skc_net_refcnt: socket is using net ref counting
+ *	@skc_bound_dev_if: bound device index if != 0
+ *	@skc_bind_node: bind hash linkage for various protocol lookup tables
+ *	@skc_portaddr_node: second hash linkage for UDP/UDP-Lite protocol
+ *	@skc_prot: protocol handlers inside a network family
+ *	@skc_net: reference to the network namespace of this socket
+ *	@skc_v6_daddr: IPV6 destination address
+ *	@skc_v6_rcv_saddr: IPV6 source address
+ *	@skc_cookie: socket's cookie value
+ *	@skc_node: main hash linkage for various protocol lookup tables
+ *	@skc_nulls_node: main hash linkage for TCP/UDP/UDP-Lite protocol
+ *	@skc_tx_queue_mapping: tx queue number for this connection
+ *	@skc_rx_queue_mapping: rx queue number for this connection
+ *	@skc_flags: place holder for sk_flags
+ *		%SO_LINGER (l_onoff), %SO_BROADCAST, %SO_KEEPALIVE,
+ *		%SO_OOBINLINE settings, %SO_TIMESTAMPING settings
+ *	@skc_listener: connection request listener socket (aka rsk_listener)
+ *		[union with @skc_flags]
+ *	@skc_tw_dr: (aka tw_dr) ptr to &struct inet_timewait_death_row
+ *		[union with @skc_flags]
+ *	@skc_incoming_cpu: record/match cpu processing incoming packets
+ *	@skc_rcv_wnd: (aka rsk_rcv_wnd) TCP receive window size (possibly scaled)
+ *		[union with @skc_incoming_cpu]
+ *	@skc_tw_rcv_nxt: (aka tw_rcv_nxt) TCP window next expected seq number
+ *		[union with @skc_incoming_cpu]
+ *	@skc_refcnt: reference count
+ *
+ *	This is the minimal network layer representation of sockets, the header
+ *	for struct sock and struct inet_timewait_sock.
+ */
+struct sock_common {
+	/* skc_daddr and skc_rcv_saddr must be grouped on a 8 bytes aligned
+	 * address on 64bit arches : cf INET_MATCH()
+	 */
+	union {
+		__addrpair	skc_addrpair;
+		struct {
+			__be32	skc_daddr;
+			__be32	skc_rcv_saddr;
+		};
+	};
+	union  {
+		unsigned int	skc_hash;
+		__u16		skc_u16hashes[2];
+	};
+	/* skc_dport && skc_num must be grouped as well */
+	union {
+		__portpair	skc_portpair;
+		struct {
+			__be16	skc_dport;
+			__u16	skc_num;
+		};
+	};
+
+	unsigned short		skc_family;
+	volatile unsigned char	skc_state;
+	unsigned char		skc_reuse:4;
+	unsigned char		skc_reuseport:1;
+	unsigned char		skc_ipv6only:1;
+	unsigned char		skc_net_refcnt:1;
+	int			skc_bound_dev_if;
+	union {
+		struct hlist_node	skc_bind_node;
+		struct hlist_node	skc_portaddr_node;
+	};
+	struct proto		*skc_prot;
+	possible_net_t		skc_net;
+
+#if IS_ENABLED(CONFIG_IPV6)
+	struct in6_addr		skc_v6_daddr;
+	struct in6_addr		skc_v6_rcv_saddr;
+#endif
+
+	atomic64_t		skc_cookie;
+
+	/* following fields are padding to force
+	 * offset(struct sock, sk_refcnt) == 128 on 64bit arches
+	 * assuming IPV6 is enabled. We use this padding differently
+	 * for different kind of 'sockets'
+	 */
+	union {
+		unsigned long	skc_flags;
+		struct sock	*skc_listener; /* request_sock */
+		struct inet_timewait_death_row *skc_tw_dr; /* inet_timewait_sock */
+	};
+	/*
+	 * fields between dontcopy_begin/dontcopy_end
+	 * are not copied in sock_copy()
+	 */
+	/* private: */
+	int			skc_dontcopy_begin[0];
+	/* public: */
+	union {
+		struct hlist_node	skc_node;
+		struct hlist_nulls_node skc_nulls_node;
+	};
+	unsigned short		skc_tx_queue_mapping;
+#ifdef CONFIG_SOCK_RX_QUEUE_MAPPING
+	unsigned short		skc_rx_queue_mapping;
+#endif
+	union {
+		int		skc_incoming_cpu;
+		u32		skc_rcv_wnd;
+		u32		skc_tw_rcv_nxt; /* struct tcp_timewait_sock  */
+	};
+
+	refcount_t		skc_refcnt;
+	/* private: */
+	int                     skc_dontcopy_end[0];
+	union {
+		u32		skc_rxhash;
+		u32		skc_window_clamp;
+		u32		skc_tw_snd_nxt; /* struct tcp_timewait_sock */
+	};
+	/* public: */
+};
+
+struct bpf_local_storage;
+
+/**
+  *	struct sock - network layer representation of sockets
+  *	@__sk_common: shared layout with inet_timewait_sock
+  *	@sk_shutdown: mask of %SEND_SHUTDOWN and/or %RCV_SHUTDOWN
+  *	@sk_userlocks: %SO_SNDBUF and %SO_RCVBUF settings
+  *	@sk_lock:	synchronizer
+  *	@sk_kern_sock: True if sock is using kernel lock classes
+  *	@sk_rcvbuf: size of receive buffer in bytes
+  *	@sk_wq: sock wait queue and async head
+  *	@sk_rx_dst: receive input route used by early demux
+  *	@sk_dst_cache: destination cache
+  *	@sk_dst_pending_confirm: need to confirm neighbour
+  *	@sk_policy: flow policy
+  *	@sk_rx_skb_cache: cache copy of recently accessed RX skb
+  *	@sk_receive_queue: incoming packets
+  *	@sk_wmem_alloc: transmit queue bytes committed
+  *	@sk_tsq_flags: TCP Small Queues flags
+  *	@sk_write_queue: Packet sending queue
+  *	@sk_omem_alloc: "o" is "option" or "other"
+  *	@sk_wmem_queued: persistent queue size
+  *	@sk_forward_alloc: space allocated forward
+  *	@sk_napi_id: id of the last napi context to receive data for sk
+  *	@sk_ll_usec: usecs to busypoll when there is no data
+  *	@sk_allocation: allocation mode
+  *	@sk_pacing_rate: Pacing rate (if supported by transport/packet scheduler)
+  *	@sk_pacing_status: Pacing status (requested, handled by sch_fq)
+  *	@sk_max_pacing_rate: Maximum pacing rate (%SO_MAX_PACING_RATE)
+  *	@sk_sndbuf: size of send buffer in bytes
+  *	@__sk_flags_offset: empty field used to determine location of bitfield
+  *	@sk_padding: unused element for alignment
+  *	@sk_no_check_tx: %SO_NO_CHECK setting, set checksum in TX packets
+  *	@sk_no_check_rx: allow zero checksum in RX packets
+  *	@sk_route_caps: route capabilities (e.g. %NETIF_F_TSO)
+  *	@sk_route_nocaps: forbidden route capabilities (e.g NETIF_F_GSO_MASK)
+  *	@sk_route_forced_caps: static, forced route capabilities
+  *		(set in tcp_init_sock())
+  *	@sk_gso_type: GSO type (e.g. %SKB_GSO_TCPV4)
+  *	@sk_gso_max_size: Maximum GSO segment size to build
+  *	@sk_gso_max_segs: Maximum number of GSO segments
+  *	@sk_pacing_shift: scaling factor for TCP Small Queues
+  *	@sk_lingertime: %SO_LINGER l_linger setting
+  *	@sk_backlog: always used with the per-socket spinlock held
+  *	@sk_callback_lock: used with the callbacks in the end of this struct
+  *	@sk_error_queue: rarely used
+  *	@sk_prot_creator: sk_prot of original sock creator (see ipv6_setsockopt,
+  *			  IPV6_ADDRFORM for instance)
+  *	@sk_err: last error
+  *	@sk_err_soft: errors that don't cause failure but are the cause of a
+  *		      persistent failure not just 'timed out'
+  *	@sk_drops: raw/udp drops counter
+  *	@sk_ack_backlog: current listen backlog
+  *	@sk_max_ack_backlog: listen backlog set in listen()
+  *	@sk_uid: user id of owner
+  *	@sk_prefer_busy_poll: prefer busypolling over softirq processing
+  *	@sk_busy_poll_budget: napi processing budget when busypolling
+  *	@sk_priority: %SO_PRIORITY setting
+  *	@sk_type: socket type (%SOCK_STREAM, etc)
+  *	@sk_protocol: which protocol this socket belongs in this network family
+  *	@sk_peer_lock: lock protecting @sk_peer_pid and @sk_peer_cred
+  *	@sk_peer_pid: &struct pid for this socket's peer
+  *	@sk_peer_cred: %SO_PEERCRED setting
+  *	@sk_rcvlowat: %SO_RCVLOWAT setting
+  *	@sk_rcvtimeo: %SO_RCVTIMEO setting
+  *	@sk_sndtimeo: %SO_SNDTIMEO setting
+  *	@sk_txhash: computed flow hash for use on transmit
+  *	@sk_filter: socket filtering instructions
+  *	@sk_timer: sock cleanup timer
+  *	@sk_stamp: time stamp of last packet received
+  *	@sk_stamp_seq: lock for accessing sk_stamp on 32 bit architectures only
+  *	@sk_tsflags: SO_TIMESTAMPING flags
+  *	@sk_bind_phc: SO_TIMESTAMPING bind PHC index of PTP virtual clock
+  *	              for timestamping
+  *	@sk_tskey: counter to disambiguate concurrent tstamp requests
+  *	@sk_zckey: counter to order MSG_ZEROCOPY notifications
+  *	@sk_socket: Identd and reporting IO signals
+  *	@sk_user_data: RPC layer private data
+  *	@sk_frag: cached page frag
+  *	@sk_peek_off: current peek_offset value
+  *	@sk_send_head: front of stuff to transmit
+  *	@tcp_rtx_queue: TCP re-transmit queue [union with @sk_send_head]
+  *	@sk_tx_skb_cache: cache copy of recently accessed TX skb
+  *	@sk_security: used by security modules
+  *	@sk_provenance: used by provenance modules
+  *	@sk_mark: generic packet mark
+  *	@sk_cgrp_data: cgroup data for this cgroup
+  *	@sk_memcg: this socket's memory cgroup association
+  *	@sk_write_pending: a write to stream socket waits to start
+  *	@sk_state_change: callback to indicate change in the state of the sock
+  *	@sk_data_ready: callback to indicate there is data to be processed
+  *	@sk_write_space: callback to indicate there is bf sending space available
+  *	@sk_error_report: callback to indicate errors (e.g. %MSG_ERRQUEUE)
+  *	@sk_backlog_rcv: callback to process the backlog
+  *	@sk_validate_xmit_skb: ptr to an optional validate function
+  *	@sk_destruct: called at sock freeing time, i.e. when all refcnt == 0
+  *	@sk_reuseport_cb: reuseport group container
+  *	@sk_bpf_storage: ptr to cache and control for bpf_sk_storage
+  *	@sk_rcu: used during RCU grace period
+  *	@sk_clockid: clockid used by time-based scheduling (SO_TXTIME)
+  *	@sk_txtime_deadline_mode: set deadline mode for SO_TXTIME
+  *	@sk_txtime_report_errors: set report errors mode for SO_TXTIME
+  *	@sk_txtime_unused: unused txtime flags
+  */
+struct sock {
+	/*
+	 * Now struct inet_timewait_sock also uses sock_common, so please just
+	 * don't add nothing before this first member (__sk_common) --acme
+	 */
+	struct sock_common	__sk_common;
+#define sk_node			__sk_common.skc_node
+#define sk_nulls_node		__sk_common.skc_nulls_node
+#define sk_refcnt		__sk_common.skc_refcnt
+#define sk_tx_queue_mapping	__sk_common.skc_tx_queue_mapping
+#ifdef CONFIG_SOCK_RX_QUEUE_MAPPING
+#define sk_rx_queue_mapping	__sk_common.skc_rx_queue_mapping
+#endif
+
+#define sk_dontcopy_begin	__sk_common.skc_dontcopy_begin
+#define sk_dontcopy_end		__sk_common.skc_dontcopy_end
+#define sk_hash			__sk_common.skc_hash
+#define sk_portpair		__sk_common.skc_portpair
+#define sk_num			__sk_common.skc_num
+#define sk_dport		__sk_common.skc_dport
+#define sk_addrpair		__sk_common.skc_addrpair
+#define sk_daddr		__sk_common.skc_daddr
+#define sk_rcv_saddr		__sk_common.skc_rcv_saddr
+#define sk_family		__sk_common.skc_family
+#define sk_state		__sk_common.skc_state
+#define sk_reuse		__sk_common.skc_reuse
+#define sk_reuseport		__sk_common.skc_reuseport
+#define sk_ipv6only		__sk_common.skc_ipv6only
+#define sk_net_refcnt		__sk_common.skc_net_refcnt
+#define sk_bound_dev_if		__sk_common.skc_bound_dev_if
+#define sk_bind_node		__sk_common.skc_bind_node
+#define sk_prot			__sk_common.skc_prot
+#define sk_net			__sk_common.skc_net
+#define sk_v6_daddr		__sk_common.skc_v6_daddr
+#define sk_v6_rcv_saddr	__sk_common.skc_v6_rcv_saddr
+#define sk_cookie		__sk_common.skc_cookie
+#define sk_incoming_cpu		__sk_common.skc_incoming_cpu
+#define sk_flags		__sk_common.skc_flags
+#define sk_rxhash		__sk_common.skc_rxhash
+
+	socket_lock_t		sk_lock;
+	atomic_t		sk_drops;
+	int			sk_rcvlowat;
+	struct sk_buff_head	sk_error_queue;
+	struct sk_buff		*sk_rx_skb_cache;
+	struct sk_buff_head	sk_receive_queue;
+	/*
+	 * The backlog queue is special, it is always used with
+	 * the per-socket spinlock held and requires low latency
+	 * access. Therefore we special case it's implementation.
+	 * Note : rmem_alloc is in this structure to fill a hole
+	 * on 64bit arches, not because its logically part of
+	 * backlog.
+	 */
+	struct {
+		atomic_t	rmem_alloc;
+		int		len;
+		struct sk_buff	*head;
+		struct sk_buff	*tail;
+	} sk_backlog;
+#define sk_rmem_alloc sk_backlog.rmem_alloc
+
+	int			sk_forward_alloc;
+#ifdef CONFIG_NET_RX_BUSY_POLL
+	unsigned int		sk_ll_usec;
+	/* ===== mostly read cache line ===== */
+	unsigned int		sk_napi_id;
+#endif
+	int			sk_rcvbuf;
+
+	struct sk_filter __rcu	*sk_filter;
+	union {
+		struct socket_wq __rcu	*sk_wq;
+		/* private: */
+		struct socket_wq	*sk_wq_raw;
+		/* public: */
+	};
+#ifdef CONFIG_XFRM
+	struct xfrm_policy __rcu *sk_policy[2];
+#endif
+	struct dst_entry	*sk_rx_dst;
+	struct dst_entry __rcu	*sk_dst_cache;
+	atomic_t		sk_omem_alloc;
+	int			sk_sndbuf;
+
+	/* ===== cache line for TX ===== */
+	int			sk_wmem_queued;
+	refcount_t		sk_wmem_alloc;
+	unsigned long		sk_tsq_flags;
+	union {
+		struct sk_buff	*sk_send_head;
+		struct rb_root	tcp_rtx_queue;
+	};
+	struct sk_buff		*sk_tx_skb_cache;
+	struct sk_buff_head	sk_write_queue;
+	__s32			sk_peek_off;
+	int			sk_write_pending;
+	__u32			sk_dst_pending_confirm;
+	u32			sk_pacing_status; /* see enum sk_pacing */
+	long			sk_sndtimeo;
+	struct timer_list	sk_timer;
+	__u32			sk_priority;
+	__u32			sk_mark;
+	unsigned long		sk_pacing_rate; /* bytes per second */
+	unsigned long		sk_max_pacing_rate;
+	struct page_frag	sk_frag;
+	netdev_features_t	sk_route_caps;
+	netdev_features_t	sk_route_nocaps;
+	netdev_features_t	sk_route_forced_caps;
+	int			sk_gso_type;
+	unsigned int		sk_gso_max_size;
+	gfp_t			sk_allocation;
+	__u32			sk_txhash;
+
+	/*
+	 * Because of non atomicity rules, all
+	 * changes are protected by socket lock.
+	 */
+	u8			sk_padding : 1,
+				sk_kern_sock : 1,
+				sk_no_check_tx : 1,
+				sk_no_check_rx : 1,
+				sk_userlocks : 4;
+	u8			sk_pacing_shift;
+	u16			sk_type;
+	u16			sk_protocol;
+	u16			sk_gso_max_segs;
+	unsigned long	        sk_lingertime;
+	struct proto		*sk_prot_creator;
+	rwlock_t		sk_callback_lock;
+	int			sk_err,
+				sk_err_soft;
+	u32			sk_ack_backlog;
+	u32			sk_max_ack_backlog;
+	kuid_t			sk_uid;
+#ifdef CONFIG_NET_RX_BUSY_POLL
+	u8			sk_prefer_busy_poll;
+	u16			sk_busy_poll_budget;
+#endif
+	spinlock_t		sk_peer_lock;
+	struct pid		*sk_peer_pid;
+	const struct cred	*sk_peer_cred;
+
+	long			sk_rcvtimeo;
+	ktime_t			sk_stamp;
+#if BITS_PER_LONG==32
+	seqlock_t		sk_stamp_seq;
+#endif
+	u16			sk_tsflags;
+	int			sk_bind_phc;
+	u8			sk_shutdown;
+	u32			sk_tskey;
+	atomic_t		sk_zckey;
+
+	u8			sk_clockid;
+	u8			sk_txtime_deadline_mode : 1,
+				sk_txtime_report_errors : 1,
+				sk_txtime_unused : 6;
+
+	struct socket		*sk_socket;
+	void			*sk_user_data;
+#ifdef CONFIG_SECURITY
+	void			*sk_security;
+#ifdef CONFIG_SECURITY_PROVENANCE
+	void 			*sk_provenance;
+#endif
+#endif
+	struct sock_cgroup_data	sk_cgrp_data;
+	struct mem_cgroup	*sk_memcg;
+	void			(*sk_state_change)(struct sock *sk);
+	void			(*sk_data_ready)(struct sock *sk);
+	void			(*sk_write_space)(struct sock *sk);
+	void			(*sk_error_report)(struct sock *sk);
+	int			(*sk_backlog_rcv)(struct sock *sk,
+						  struct sk_buff *skb);
+#ifdef CONFIG_SOCK_VALIDATE_XMIT
+	struct sk_buff*		(*sk_validate_xmit_skb)(struct sock *sk,
+							struct net_device *dev,
+							struct sk_buff *skb);
+#endif
+	void                    (*sk_destruct)(struct sock *sk);
+	struct sock_reuseport __rcu	*sk_reuseport_cb;
+#ifdef CONFIG_BPF_SYSCALL
+	struct bpf_local_storage __rcu	*sk_bpf_storage;
+#endif
+	struct rcu_head		sk_rcu;
+};
+
+enum sk_pacing {
+	SK_PACING_NONE		= 0,
+	SK_PACING_NEEDED	= 1,
+	SK_PACING_FQ		= 2,
+};
+
+/* Pointer stored in sk_user_data might not be suitable for copying
+ * when cloning the socket. For instance, it can point to a reference
+ * counted object. sk_user_data bottom bit is set if pointer must not
+ * be copied.
+ */
+#define SK_USER_DATA_NOCOPY	1UL
+#define SK_USER_DATA_BPF	2UL	/* Managed by BPF */
+#define SK_USER_DATA_PTRMASK	~(SK_USER_DATA_NOCOPY | SK_USER_DATA_BPF)
+
+/**
+ * sk_user_data_is_nocopy - Test if sk_user_data pointer must not be copied
+ * @sk: socket
+ */
+static inline bool sk_user_data_is_nocopy(const struct sock *sk)
+{
+	return ((uintptr_t)sk->sk_user_data & SK_USER_DATA_NOCOPY);
+}
+
+#define __sk_user_data(sk) ((*((void __rcu **)&(sk)->sk_user_data)))
+
+#define rcu_dereference_sk_user_data(sk)				\
+({									\
+	void *__tmp = rcu_dereference(__sk_user_data((sk)));		\
+	(void *)((uintptr_t)__tmp & SK_USER_DATA_PTRMASK);		\
+})
+#define rcu_assign_sk_user_data(sk, ptr)				\
+({									\
+	uintptr_t __tmp = (uintptr_t)(ptr);				\
+	WARN_ON_ONCE(__tmp & ~SK_USER_DATA_PTRMASK);			\
+	rcu_assign_pointer(__sk_user_data((sk)), __tmp);		\
+})
+#define rcu_assign_sk_user_data_nocopy(sk, ptr)				\
+({									\
+	uintptr_t __tmp = (uintptr_t)(ptr);				\
+	WARN_ON_ONCE(__tmp & ~SK_USER_DATA_PTRMASK);			\
+	rcu_assign_pointer(__sk_user_data((sk)),			\
+			   __tmp | SK_USER_DATA_NOCOPY);		\
+})
+
+/*
+ * SK_CAN_REUSE and SK_NO_REUSE on a socket mean that the socket is OK
+ * or not whether his port will be reused by someone else. SK_FORCE_REUSE
+ * on a socket means that the socket will reuse everybody else's port
+ * without looking at the other's sk_reuse value.
+ */
+
+#define SK_NO_REUSE	0
+#define SK_CAN_REUSE	1
+#define SK_FORCE_REUSE	2
+
+int sk_set_peek_off(struct sock *sk, int val);
+
+static inline int sk_peek_offset(struct sock *sk, int flags)
+{
+	if (unlikely(flags & MSG_PEEK)) {
+		return READ_ONCE(sk->sk_peek_off);
+	}
+
+	return 0;
+}
+
+static inline void sk_peek_offset_bwd(struct sock *sk, int val)
+{
+	s32 off = READ_ONCE(sk->sk_peek_off);
+
+	if (unlikely(off >= 0)) {
+		off = max_t(s32, off - val, 0);
+		WRITE_ONCE(sk->sk_peek_off, off);
+	}
+}
+
+static inline void sk_peek_offset_fwd(struct sock *sk, int val)
+{
+	sk_peek_offset_bwd(sk, -val);
+}
+
+/*
+ * Hashed lists helper routines
+ */
+static inline struct sock *sk_entry(const struct hlist_node *node)
+{
+	return hlist_entry(node, struct sock, sk_node);
+}
+
+static inline struct sock *__sk_head(const struct hlist_head *head)
+{
+	return hlist_entry(head->first, struct sock, sk_node);
+}
+
+static inline struct sock *sk_head(const struct hlist_head *head)
+{
+	return hlist_empty(head) ? NULL : __sk_head(head);
+}
+
+static inline struct sock *__sk_nulls_head(const struct hlist_nulls_head *head)
+{
+	return hlist_nulls_entry(head->first, struct sock, sk_nulls_node);
+}
+
+static inline struct sock *sk_nulls_head(const struct hlist_nulls_head *head)
+{
+	return hlist_nulls_empty(head) ? NULL : __sk_nulls_head(head);
+}
+
+static inline struct sock *sk_next(const struct sock *sk)
+{
+	return hlist_entry_safe(sk->sk_node.next, struct sock, sk_node);
+}
+
+static inline struct sock *sk_nulls_next(const struct sock *sk)
+{
+	return (!is_a_nulls(sk->sk_nulls_node.next)) ?
+		hlist_nulls_entry(sk->sk_nulls_node.next,
+				  struct sock, sk_nulls_node) :
+		NULL;
+}
+
+static inline bool sk_unhashed(const struct sock *sk)
+{
+	return hlist_unhashed(&sk->sk_node);
+}
+
+static inline bool sk_hashed(const struct sock *sk)
+{
+	return !sk_unhashed(sk);
+}
+
+static inline void sk_node_init(struct hlist_node *node)
+{
+	node->pprev = NULL;
+}
+
+static inline void sk_nulls_node_init(struct hlist_nulls_node *node)
+{
+	node->pprev = NULL;
+}
+
+static inline void __sk_del_node(struct sock *sk)
+{
+	__hlist_del(&sk->sk_node);
+}
+
+/* NB: equivalent to hlist_del_init_rcu */
+static inline bool __sk_del_node_init(struct sock *sk)
+{
+	if (sk_hashed(sk)) {
+		__sk_del_node(sk);
+		sk_node_init(&sk->sk_node);
+		return true;
+	}
+	return false;
+}
+
+/* Grab socket reference count. This operation is valid only
+   when sk is ALREADY grabbed f.e. it is found in hash table
+   or a list and the lookup is made under lock preventing hash table
+   modifications.
+ */
+
+static __always_inline void sock_hold(struct sock *sk)
+{
+	refcount_inc(&sk->sk_refcnt);
+}
+
+/* Ungrab socket in the context, which assumes that socket refcnt
+   cannot hit zero, f.e. it is true in context of any socketcall.
+ */
+static __always_inline void __sock_put(struct sock *sk)
+{
+	refcount_dec(&sk->sk_refcnt);
+}
+
+static inline bool sk_del_node_init(struct sock *sk)
+{
+	bool rc = __sk_del_node_init(sk);
+
+	if (rc) {
+		/* paranoid for a while -acme */
+		WARN_ON(refcount_read(&sk->sk_refcnt) == 1);
+		__sock_put(sk);
+	}
+	return rc;
+}
+#define sk_del_node_init_rcu(sk)	sk_del_node_init(sk)
+
+static inline bool __sk_nulls_del_node_init_rcu(struct sock *sk)
+{
+	if (sk_hashed(sk)) {
+		hlist_nulls_del_init_rcu(&sk->sk_nulls_node);
+		return true;
+	}
+	return false;
+}
+
+static inline bool sk_nulls_del_node_init_rcu(struct sock *sk)
+{
+	bool rc = __sk_nulls_del_node_init_rcu(sk);
+
+	if (rc) {
+		/* paranoid for a while -acme */
+		WARN_ON(refcount_read(&sk->sk_refcnt) == 1);
+		__sock_put(sk);
+	}
+	return rc;
+}
+
+static inline void __sk_add_node(struct sock *sk, struct hlist_head *list)
+{
+	hlist_add_head(&sk->sk_node, list);
+}
+
+static inline void sk_add_node(struct sock *sk, struct hlist_head *list)
+{
+	sock_hold(sk);
+	__sk_add_node(sk, list);
+}
+
+static inline void sk_add_node_rcu(struct sock *sk, struct hlist_head *list)
+{
+	sock_hold(sk);
+	if (IS_ENABLED(CONFIG_IPV6) && sk->sk_reuseport &&
+	    sk->sk_family == AF_INET6)
+		hlist_add_tail_rcu(&sk->sk_node, list);
+	else
+		hlist_add_head_rcu(&sk->sk_node, list);
+}
+
+static inline void sk_add_node_tail_rcu(struct sock *sk, struct hlist_head *list)
+{
+	sock_hold(sk);
+	hlist_add_tail_rcu(&sk->sk_node, list);
+}
+
+static inline void __sk_nulls_add_node_rcu(struct sock *sk, struct hlist_nulls_head *list)
+{
+	hlist_nulls_add_head_rcu(&sk->sk_nulls_node, list);
+}
+
+static inline void __sk_nulls_add_node_tail_rcu(struct sock *sk, struct hlist_nulls_head *list)
+{
+	hlist_nulls_add_tail_rcu(&sk->sk_nulls_node, list);
+}
+
+static inline void sk_nulls_add_node_rcu(struct sock *sk, struct hlist_nulls_head *list)
+{
+	sock_hold(sk);
+	__sk_nulls_add_node_rcu(sk, list);
+}
+
+static inline void __sk_del_bind_node(struct sock *sk)
+{
+	__hlist_del(&sk->sk_bind_node);
+}
+
+static inline void sk_add_bind_node(struct sock *sk,
+					struct hlist_head *list)
+{
+	hlist_add_head(&sk->sk_bind_node, list);
+}
+
+#define sk_for_each(__sk, list) \
+	hlist_for_each_entry(__sk, list, sk_node)
+#define sk_for_each_rcu(__sk, list) \
+	hlist_for_each_entry_rcu(__sk, list, sk_node)
+#define sk_nulls_for_each(__sk, node, list) \
+	hlist_nulls_for_each_entry(__sk, node, list, sk_nulls_node)
+#define sk_nulls_for_each_rcu(__sk, node, list) \
+	hlist_nulls_for_each_entry_rcu(__sk, node, list, sk_nulls_node)
+#define sk_for_each_from(__sk) \
+	hlist_for_each_entry_from(__sk, sk_node)
+#define sk_nulls_for_each_from(__sk, node) \
+	if (__sk && ({ node = &(__sk)->sk_nulls_node; 1; })) \
+		hlist_nulls_for_each_entry_from(__sk, node, sk_nulls_node)
+#define sk_for_each_safe(__sk, tmp, list) \
+	hlist_for_each_entry_safe(__sk, tmp, list, sk_node)
+#define sk_for_each_bound(__sk, list) \
+	hlist_for_each_entry(__sk, list, sk_bind_node)
+
+/**
+ * sk_for_each_entry_offset_rcu - iterate over a list at a given struct offset
+ * @tpos:	the type * to use as a loop cursor.
+ * @pos:	the &struct hlist_node to use as a loop cursor.
+ * @head:	the head for your list.
+ * @offset:	offset of hlist_node within the struct.
+ *
+ */
+#define sk_for_each_entry_offset_rcu(tpos, pos, head, offset)		       \
+	for (pos = rcu_dereference(hlist_first_rcu(head));		       \
+	     pos != NULL &&						       \
+		({ tpos = (typeof(*tpos) *)((void *)pos - offset); 1;});       \
+	     pos = rcu_dereference(hlist_next_rcu(pos)))
+
+static inline struct user_namespace *sk_user_ns(struct sock *sk)
+{
+	/* Careful only use this in a context where these parameters
+	 * can not change and must all be valid, such as recvmsg from
+	 * userspace.
+	 */
+	return sk->sk_socket->file->f_cred->user_ns;
+}
+
+/* Sock flags */
+enum sock_flags {
+	SOCK_DEAD,
+	SOCK_DONE,
+	SOCK_URGINLINE,
+	SOCK_KEEPOPEN,
+	SOCK_LINGER,
+	SOCK_DESTROY,
+	SOCK_BROADCAST,
+	SOCK_TIMESTAMP,
+	SOCK_ZAPPED,
+	SOCK_USE_WRITE_QUEUE, /* whether to call sk->sk_write_space in sock_wfree */
+	SOCK_DBG, /* %SO_DEBUG setting */
+	SOCK_RCVTSTAMP, /* %SO_TIMESTAMP setting */
+	SOCK_RCVTSTAMPNS, /* %SO_TIMESTAMPNS setting */
+	SOCK_LOCALROUTE, /* route locally only, %SO_DONTROUTE setting */
+	SOCK_MEMALLOC, /* VM depends on this socket for swapping */
+	SOCK_TIMESTAMPING_RX_SOFTWARE,  /* %SOF_TIMESTAMPING_RX_SOFTWARE */
+	SOCK_FASYNC, /* fasync() active */
+	SOCK_RXQ_OVFL,
+	SOCK_ZEROCOPY, /* buffers from userspace */
+	SOCK_WIFI_STATUS, /* push wifi status to userspace */
+	SOCK_NOFCS, /* Tell NIC not to do the Ethernet FCS.
+		     * Will use last 4 bytes of packet sent from
+		     * user-space instead.
+		     */
+	SOCK_FILTER_LOCKED, /* Filter cannot be changed anymore */
+	SOCK_SELECT_ERR_QUEUE, /* Wake select on error queue */
+	SOCK_RCU_FREE, /* wait rcu grace period in sk_destruct() */
+	SOCK_TXTIME,
+	SOCK_XDP, /* XDP is attached */
+	SOCK_TSTAMP_NEW, /* Indicates 64 bit timestamps always */
+};
+
+#define SK_FLAGS_TIMESTAMP ((1UL << SOCK_TIMESTAMP) | (1UL << SOCK_TIMESTAMPING_RX_SOFTWARE))
+
+static inline void sock_copy_flags(struct sock *nsk, struct sock *osk)
+{
+	nsk->sk_flags = osk->sk_flags;
+}
+
+static inline void sock_set_flag(struct sock *sk, enum sock_flags flag)
+{
+	__set_bit(flag, &sk->sk_flags);
+}
+
+static inline void sock_reset_flag(struct sock *sk, enum sock_flags flag)
+{
+	__clear_bit(flag, &sk->sk_flags);
+}
+
+static inline void sock_valbool_flag(struct sock *sk, enum sock_flags bit,
+				     int valbool)
+{
+	if (valbool)
+		sock_set_flag(sk, bit);
+	else
+		sock_reset_flag(sk, bit);
+}
+
+static inline bool sock_flag(const struct sock *sk, enum sock_flags flag)
+{
+	return test_bit(flag, &sk->sk_flags);
+}
+
+#ifdef CONFIG_NET
+DECLARE_STATIC_KEY_FALSE(memalloc_socks_key);
+static inline int sk_memalloc_socks(void)
+{
+	return static_branch_unlikely(&memalloc_socks_key);
+}
+
+void __receive_sock(struct file *file);
+#else
+
+static inline int sk_memalloc_socks(void)
+{
+	return 0;
+}
+
+static inline void __receive_sock(struct file *file)
+{ }
+#endif
+
+static inline gfp_t sk_gfp_mask(const struct sock *sk, gfp_t gfp_mask)
+{
+	return gfp_mask | (sk->sk_allocation & __GFP_MEMALLOC);
+}
+
+static inline void sk_acceptq_removed(struct sock *sk)
+{
+	WRITE_ONCE(sk->sk_ack_backlog, sk->sk_ack_backlog - 1);
+}
+
+static inline void sk_acceptq_added(struct sock *sk)
+{
+	WRITE_ONCE(sk->sk_ack_backlog, sk->sk_ack_backlog + 1);
+}
+
+/* Note: If you think the test should be:
+ *	return READ_ONCE(sk->sk_ack_backlog) >= READ_ONCE(sk->sk_max_ack_backlog);
+ * Then please take a look at commit 64a146513f8f ("[NET]: Revert incorrect accept queue backlog changes.")
+ */
+static inline bool sk_acceptq_is_full(const struct sock *sk)
+{
+	return READ_ONCE(sk->sk_ack_backlog) > READ_ONCE(sk->sk_max_ack_backlog);
+}
+
+/*
+ * Compute minimal free write space needed to queue new packets.
+ */
+static inline int sk_stream_min_wspace(const struct sock *sk)
+{
+	return READ_ONCE(sk->sk_wmem_queued) >> 1;
+}
+
+static inline int sk_stream_wspace(const struct sock *sk)
+{
+	return READ_ONCE(sk->sk_sndbuf) - READ_ONCE(sk->sk_wmem_queued);
+}
+
+static inline void sk_wmem_queued_add(struct sock *sk, int val)
+{
+	WRITE_ONCE(sk->sk_wmem_queued, sk->sk_wmem_queued + val);
+}
+
+void sk_stream_write_space(struct sock *sk);
+
+/* OOB backlog add */
+static inline void __sk_add_backlog(struct sock *sk, struct sk_buff *skb)
+{
+	/* dont let skb dst not refcounted, we are going to leave rcu lock */
+	skb_dst_force(skb);
+
+	if (!sk->sk_backlog.tail)
+		WRITE_ONCE(sk->sk_backlog.head, skb);
+	else
+		sk->sk_backlog.tail->next = skb;
+
+	WRITE_ONCE(sk->sk_backlog.tail, skb);
+	skb->next = NULL;
+}
+
+/*
+ * Take into account size of receive queue and backlog queue
+ * Do not take into account this skb truesize,
+ * to allow even a single big packet to come.
+ */
+static inline bool sk_rcvqueues_full(const struct sock *sk, unsigned int limit)
+{
+	unsigned int qsize = sk->sk_backlog.len + atomic_read(&sk->sk_rmem_alloc);
+
+	return qsize > limit;
+}
+
+/* The per-socket spinlock must be held here. */
+static inline __must_check int sk_add_backlog(struct sock *sk, struct sk_buff *skb,
+					      unsigned int limit)
+{
+	if (sk_rcvqueues_full(sk, limit))
+		return -ENOBUFS;
+
+	/*
+	 * If the skb was allocated from pfmemalloc reserves, only
+	 * allow SOCK_MEMALLOC sockets to use it as this socket is
+	 * helping free memory
+	 */
+	if (skb_pfmemalloc(skb) && !sock_flag(sk, SOCK_MEMALLOC))
+		return -ENOMEM;
+
+	__sk_add_backlog(sk, skb);
+	sk->sk_backlog.len += skb->truesize;
+	return 0;
+}
+
+int __sk_backlog_rcv(struct sock *sk, struct sk_buff *skb);
+
+static inline int sk_backlog_rcv(struct sock *sk, struct sk_buff *skb)
+{
+	if (sk_memalloc_socks() && skb_pfmemalloc(skb))
+		return __sk_backlog_rcv(sk, skb);
+
+	return sk->sk_backlog_rcv(sk, skb);
+}
+
+static inline void sk_incoming_cpu_update(struct sock *sk)
+{
+	int cpu = raw_smp_processor_id();
+
+	if (unlikely(READ_ONCE(sk->sk_incoming_cpu) != cpu))
+		WRITE_ONCE(sk->sk_incoming_cpu, cpu);
+}
+
+static inline void sock_rps_record_flow_hash(__u32 hash)
+{
+#ifdef CONFIG_RPS
+	struct rps_sock_flow_table *sock_flow_table;
+
+	rcu_read_lock();
+	sock_flow_table = rcu_dereference(rps_sock_flow_table);
+	rps_record_sock_flow(sock_flow_table, hash);
+	rcu_read_unlock();
+#endif
+}
+
+static inline void sock_rps_record_flow(const struct sock *sk)
+{
+#ifdef CONFIG_RPS
+	if (static_branch_unlikely(&rfs_needed)) {
+		/* Reading sk->sk_rxhash might incur an expensive cache line
+		 * miss.
+		 *
+		 * TCP_ESTABLISHED does cover almost all states where RFS
+		 * might be useful, and is cheaper [1] than testing :
+		 *	IPv4: inet_sk(sk)->inet_daddr
+		 * 	IPv6: ipv6_addr_any(&sk->sk_v6_daddr)
+		 * OR	an additional socket flag
+		 * [1] : sk_state and sk_prot are in the same cache line.
+		 */
+		if (sk->sk_state == TCP_ESTABLISHED)
+			sock_rps_record_flow_hash(sk->sk_rxhash);
+	}
+#endif
+}
+
+static inline void sock_rps_save_rxhash(struct sock *sk,
+					const struct sk_buff *skb)
+{
+#ifdef CONFIG_RPS
+	if (unlikely(sk->sk_rxhash != skb->hash))
+		sk->sk_rxhash = skb->hash;
+#endif
+}
+
+static inline void sock_rps_reset_rxhash(struct sock *sk)
+{
+#ifdef CONFIG_RPS
+	sk->sk_rxhash = 0;
+#endif
+}
+
+#define sk_wait_event(__sk, __timeo, __condition, __wait)		\
+	({	int __rc;						\
+		release_sock(__sk);					\
+		__rc = __condition;					\
+		if (!__rc) {						\
+			*(__timeo) = wait_woken(__wait,			\
+						TASK_INTERRUPTIBLE,	\
+						*(__timeo));		\
+		}							\
+		sched_annotate_sleep();					\
+		lock_sock(__sk);					\
+		__rc = __condition;					\
+		__rc;							\
+	})
+
+int sk_stream_wait_connect(struct sock *sk, long *timeo_p);
+int sk_stream_wait_memory(struct sock *sk, long *timeo_p);
+void sk_stream_wait_close(struct sock *sk, long timeo_p);
+int sk_stream_error(struct sock *sk, int flags, int err);
+void sk_stream_kill_queues(struct sock *sk);
+void sk_set_memalloc(struct sock *sk);
+void sk_clear_memalloc(struct sock *sk);
+
+void __sk_flush_backlog(struct sock *sk);
+
+static inline bool sk_flush_backlog(struct sock *sk)
+{
+	if (unlikely(READ_ONCE(sk->sk_backlog.tail))) {
+		__sk_flush_backlog(sk);
+		return true;
+	}
+	return false;
+}
+
+int sk_wait_data(struct sock *sk, long *timeo, const struct sk_buff *skb);
+
+struct request_sock_ops;
+struct timewait_sock_ops;
+struct inet_hashinfo;
+struct raw_hashinfo;
+struct smc_hashinfo;
+struct module;
+struct sk_psock;
+
+/*
+ * caches using SLAB_TYPESAFE_BY_RCU should let .next pointer from nulls nodes
+ * un-modified. Special care is taken when initializing object to zero.
+ */
+static inline void sk_prot_clear_nulls(struct sock *sk, int size)
+{
+	if (offsetof(struct sock, sk_node.next) != 0)
+		memset(sk, 0, offsetof(struct sock, sk_node.next));
+	memset(&sk->sk_node.pprev, 0,
+	       size - offsetof(struct sock, sk_node.pprev));
+}
+
+/* Networking protocol blocks we attach to sockets.
+ * socket layer -> transport layer interface
+ */
+struct proto {
+	void			(*close)(struct sock *sk,
+					long timeout);
+	int			(*pre_connect)(struct sock *sk,
+					struct sockaddr *uaddr,
+					int addr_len);
+	int			(*connect)(struct sock *sk,
+					struct sockaddr *uaddr,
+					int addr_len);
+	int			(*disconnect)(struct sock *sk, int flags);
+
+	struct sock *		(*accept)(struct sock *sk, int flags, int *err,
+					  bool kern);
+
+	int			(*ioctl)(struct sock *sk, int cmd,
+					 unsigned long arg);
+	int			(*init)(struct sock *sk);
+	void			(*destroy)(struct sock *sk);
+	void			(*shutdown)(struct sock *sk, int how);
+	int			(*setsockopt)(struct sock *sk, int level,
+					int optname, sockptr_t optval,
+					unsigned int optlen);
+	int			(*getsockopt)(struct sock *sk, int level,
+					int optname, char __user *optval,
+					int __user *option);
+	void			(*keepalive)(struct sock *sk, int valbool);
+#ifdef CONFIG_COMPAT
+	int			(*compat_ioctl)(struct sock *sk,
+					unsigned int cmd, unsigned long arg);
+#endif
+	int			(*sendmsg)(struct sock *sk, struct msghdr *msg,
+					   size_t len);
+	int			(*recvmsg)(struct sock *sk, struct msghdr *msg,
+					   size_t len, int noblock, int flags,
+					   int *addr_len);
+	int			(*sendpage)(struct sock *sk, struct page *page,
+					int offset, size_t size, int flags);
+	int			(*bind)(struct sock *sk,
+					struct sockaddr *addr, int addr_len);
+	int			(*bind_add)(struct sock *sk,
+					struct sockaddr *addr, int addr_len);
+
+	int			(*backlog_rcv) (struct sock *sk,
+						struct sk_buff *skb);
+	bool			(*bpf_bypass_getsockopt)(int level,
+							 int optname);
+
+	void		(*release_cb)(struct sock *sk);
+
+	/* Keeping track of sk's, looking them up, and port selection methods. */
+	int			(*hash)(struct sock *sk);
+	void			(*unhash)(struct sock *sk);
+	void			(*rehash)(struct sock *sk);
+	int			(*get_port)(struct sock *sk, unsigned short snum);
+#ifdef CONFIG_BPF_SYSCALL
+	int			(*psock_update_sk_prot)(struct sock *sk,
+							struct sk_psock *psock,
+							bool restore);
+#endif
+
+	/* Keeping track of sockets in use */
+#ifdef CONFIG_PROC_FS
+	unsigned int		inuse_idx;
+#endif
+
+	bool			(*stream_memory_free)(const struct sock *sk, int wake);
+	bool			(*sock_is_readable)(struct sock *sk);
+	/* Memory pressure */
+	void			(*enter_memory_pressure)(struct sock *sk);
+	void			(*leave_memory_pressure)(struct sock *sk);
+	atomic_long_t		*memory_allocated;	/* Current allocated memory. */
+	struct percpu_counter	*sockets_allocated;	/* Current number of sockets. */
+	/*
+	 * Pressure flag: try to collapse.
+	 * Technical note: it is used by multiple contexts non atomically.
+	 * All the __sk_mem_schedule() is of this nature: accounting
+	 * is strict, actions are advisory and have some latency.
+	 */
+	unsigned long		*memory_pressure;
+	long			*sysctl_mem;
+
+	int			*sysctl_wmem;
+	int			*sysctl_rmem;
+	u32			sysctl_wmem_offset;
+	u32			sysctl_rmem_offset;
+
+	int			max_header;
+	bool			no_autobind;
+
+	struct kmem_cache	*slab;
+	unsigned int		obj_size;
+	slab_flags_t		slab_flags;
+	unsigned int		useroffset;	/* Usercopy region offset */
+	unsigned int		usersize;	/* Usercopy region size */
+
+	unsigned int __percpu	*orphan_count;
+
+	struct request_sock_ops	*rsk_prot;
+	struct timewait_sock_ops *twsk_prot;
+
+	union {
+		struct inet_hashinfo	*hashinfo;
+		struct udp_table	*udp_table;
+		struct raw_hashinfo	*raw_hash;
+		struct smc_hashinfo	*smc_hash;
+	} h;
+
+	struct module		*owner;
+
+	char			name[32];
+
+	struct list_head	node;
+#ifdef SOCK_REFCNT_DEBUG
+	atomic_t		socks;
+#endif
+	int			(*diag_destroy)(struct sock *sk, int err);
+} __randomize_layout;
+
+int proto_register(struct proto *prot, int alloc_slab);
+void proto_unregister(struct proto *prot);
+int sock_load_diag_module(int family, int protocol);
+
+#ifdef SOCK_REFCNT_DEBUG
+static inline void sk_refcnt_debug_inc(struct sock *sk)
+{
+	atomic_inc(&sk->sk_prot->socks);
+}
+
+static inline void sk_refcnt_debug_dec(struct sock *sk)
+{
+	atomic_dec(&sk->sk_prot->socks);
+	printk(KERN_DEBUG "%s socket %p released, %d are still alive\n",
+	       sk->sk_prot->name, sk, atomic_read(&sk->sk_prot->socks));
+}
+
+static inline void sk_refcnt_debug_release(const struct sock *sk)
+{
+	if (refcount_read(&sk->sk_refcnt) != 1)
+		printk(KERN_DEBUG "Destruction of the %s socket %p delayed, refcnt=%d\n",
+		       sk->sk_prot->name, sk, refcount_read(&sk->sk_refcnt));
+}
+#else /* SOCK_REFCNT_DEBUG */
+#define sk_refcnt_debug_inc(sk) do { } while (0)
+#define sk_refcnt_debug_dec(sk) do { } while (0)
+#define sk_refcnt_debug_release(sk) do { } while (0)
+#endif /* SOCK_REFCNT_DEBUG */
+
+INDIRECT_CALLABLE_DECLARE(bool tcp_stream_memory_free(const struct sock *sk, int wake));
+
+static inline bool __sk_stream_memory_free(const struct sock *sk, int wake)
+{
+	if (READ_ONCE(sk->sk_wmem_queued) >= READ_ONCE(sk->sk_sndbuf))
+		return false;
+
+#ifdef CONFIG_INET
+	return sk->sk_prot->stream_memory_free ?
+		INDIRECT_CALL_1(sk->sk_prot->stream_memory_free,
+			        tcp_stream_memory_free,
+				sk, wake) : true;
+#else
+	return sk->sk_prot->stream_memory_free ?
+		sk->sk_prot->stream_memory_free(sk, wake) : true;
+#endif
+}
+
+static inline bool sk_stream_memory_free(const struct sock *sk)
+{
+	return __sk_stream_memory_free(sk, 0);
+}
+
+static inline bool __sk_stream_is_writeable(const struct sock *sk, int wake)
+{
+	return sk_stream_wspace(sk) >= sk_stream_min_wspace(sk) &&
+	       __sk_stream_memory_free(sk, wake);
+}
+
+static inline bool sk_stream_is_writeable(const struct sock *sk)
+{
+	return __sk_stream_is_writeable(sk, 0);
+}
+
+static inline int sk_under_cgroup_hierarchy(struct sock *sk,
+					    struct cgroup *ancestor)
+{
+#ifdef CONFIG_SOCK_CGROUP_DATA
+	return cgroup_is_descendant(sock_cgroup_ptr(&sk->sk_cgrp_data),
+				    ancestor);
+#else
+	return -ENOTSUPP;
+#endif
+}
+
+static inline bool sk_has_memory_pressure(const struct sock *sk)
+{
+	return sk->sk_prot->memory_pressure != NULL;
+}
+
+static inline bool sk_under_memory_pressure(const struct sock *sk)
+{
+	if (!sk->sk_prot->memory_pressure)
+		return false;
+
+	if (mem_cgroup_sockets_enabled && sk->sk_memcg &&
+	    mem_cgroup_under_socket_pressure(sk->sk_memcg))
+		return true;
+
+	return !!*sk->sk_prot->memory_pressure;
+}
+
+static inline long
+sk_memory_allocated(const struct sock *sk)
+{
+	return atomic_long_read(sk->sk_prot->memory_allocated);
+}
+
+static inline long
+sk_memory_allocated_add(struct sock *sk, int amt)
+{
+	return atomic_long_add_return(amt, sk->sk_prot->memory_allocated);
+}
+
+static inline void
+sk_memory_allocated_sub(struct sock *sk, int amt)
+{
+	atomic_long_sub(amt, sk->sk_prot->memory_allocated);
+}
+
+#define SK_ALLOC_PERCPU_COUNTER_BATCH 16
+
+static inline void sk_sockets_allocated_dec(struct sock *sk)
+{
+	percpu_counter_add_batch(sk->sk_prot->sockets_allocated, -1,
+				 SK_ALLOC_PERCPU_COUNTER_BATCH);
+}
+
+static inline void sk_sockets_allocated_inc(struct sock *sk)
+{
+	percpu_counter_add_batch(sk->sk_prot->sockets_allocated, 1,
+				 SK_ALLOC_PERCPU_COUNTER_BATCH);
+}
+
+static inline u64
+sk_sockets_allocated_read_positive(struct sock *sk)
+{
+	return percpu_counter_read_positive(sk->sk_prot->sockets_allocated);
+}
+
+static inline int
+proto_sockets_allocated_sum_positive(struct proto *prot)
+{
+	return percpu_counter_sum_positive(prot->sockets_allocated);
+}
+
+static inline long
+proto_memory_allocated(struct proto *prot)
+{
+	return atomic_long_read(prot->memory_allocated);
+}
+
+static inline bool
+proto_memory_pressure(struct proto *prot)
+{
+	if (!prot->memory_pressure)
+		return false;
+	return !!*prot->memory_pressure;
+}
+
+
+#ifdef CONFIG_PROC_FS
+/* Called with local bh disabled */
+void sock_prot_inuse_add(struct net *net, struct proto *prot, int inc);
+int sock_prot_inuse_get(struct net *net, struct proto *proto);
+int sock_inuse_get(struct net *net);
+#else
+static inline void sock_prot_inuse_add(struct net *net, struct proto *prot,
+		int inc)
+{
+}
+#endif
+
+
+/* With per-bucket locks this operation is not-atomic, so that
+ * this version is not worse.
+ */
+static inline int __sk_prot_rehash(struct sock *sk)
+{
+	sk->sk_prot->unhash(sk);
+	return sk->sk_prot->hash(sk);
+}
+
+/* About 10 seconds */
+#define SOCK_DESTROY_TIME (10*HZ)
+
+/* Sockets 0-1023 can't be bound to unless you are superuser */
+#define PROT_SOCK	1024
+
+#define SHUTDOWN_MASK	3
+#define RCV_SHUTDOWN	1
+#define SEND_SHUTDOWN	2
+
+#define SOCK_BINDADDR_LOCK	4
+#define SOCK_BINDPORT_LOCK	8
+
+struct socket_alloc {
+	struct socket socket;
+	struct inode vfs_inode;
+};
+
+static inline struct socket *SOCKET_I(struct inode *inode)
+{
+	return &container_of(inode, struct socket_alloc, vfs_inode)->socket;
+}
+
+static inline struct inode *SOCK_INODE(struct socket *socket)
+{
+	return &container_of(socket, struct socket_alloc, socket)->vfs_inode;
+}
+
+/*
+ * Functions for memory accounting
+ */
+int __sk_mem_raise_allocated(struct sock *sk, int size, int amt, int kind);
+int __sk_mem_schedule(struct sock *sk, int size, int kind);
+void __sk_mem_reduce_allocated(struct sock *sk, int amount);
+void __sk_mem_reclaim(struct sock *sk, int amount);
+
+/* We used to have PAGE_SIZE here, but systems with 64KB pages
+ * do not necessarily have 16x time more memory than 4KB ones.
+ */
+#define SK_MEM_QUANTUM 4096
+#define SK_MEM_QUANTUM_SHIFT ilog2(SK_MEM_QUANTUM)
+#define SK_MEM_SEND	0
+#define SK_MEM_RECV	1
+
+/* sysctl_mem values are in pages, we convert them in SK_MEM_QUANTUM units */
+static inline long sk_prot_mem_limits(const struct sock *sk, int index)
+{
+	long val = sk->sk_prot->sysctl_mem[index];
+
+#if PAGE_SIZE > SK_MEM_QUANTUM
+	val <<= PAGE_SHIFT - SK_MEM_QUANTUM_SHIFT;
+#elif PAGE_SIZE < SK_MEM_QUANTUM
+	val >>= SK_MEM_QUANTUM_SHIFT - PAGE_SHIFT;
+#endif
+	return val;
+}
+
+static inline int sk_mem_pages(int amt)
+{
+	return (amt + SK_MEM_QUANTUM - 1) >> SK_MEM_QUANTUM_SHIFT;
+}
+
+static inline bool sk_has_account(struct sock *sk)
+{
+	/* return true if protocol supports memory accounting */
+	return !!sk->sk_prot->memory_allocated;
+}
+
+static inline bool sk_wmem_schedule(struct sock *sk, int size)
+{
+	if (!sk_has_account(sk))
+		return true;
+	return size <= sk->sk_forward_alloc ||
+		__sk_mem_schedule(sk, size, SK_MEM_SEND);
+}
+
+static inline bool
+sk_rmem_schedule(struct sock *sk, struct sk_buff *skb, int size)
+{
+	if (!sk_has_account(sk))
+		return true;
+	return size <= sk->sk_forward_alloc ||
+		__sk_mem_schedule(sk, size, SK_MEM_RECV) ||
+		skb_pfmemalloc(skb);
+}
+
+static inline void sk_mem_reclaim(struct sock *sk)
+{
+	if (!sk_has_account(sk))
+		return;
+	if (sk->sk_forward_alloc >= SK_MEM_QUANTUM)
+		__sk_mem_reclaim(sk, sk->sk_forward_alloc);
+}
+
+static inline void sk_mem_reclaim_partial(struct sock *sk)
+{
+	if (!sk_has_account(sk))
+		return;
+	if (sk->sk_forward_alloc > SK_MEM_QUANTUM)
+		__sk_mem_reclaim(sk, sk->sk_forward_alloc - 1);
+}
+
+static inline void sk_mem_charge(struct sock *sk, int size)
+{
+	if (!sk_has_account(sk))
+		return;
+	sk->sk_forward_alloc -= size;
+}
+
+static inline void sk_mem_uncharge(struct sock *sk, int size)
+{
+	if (!sk_has_account(sk))
+		return;
+	sk->sk_forward_alloc += size;
+
+	/* Avoid a possible overflow.
+	 * TCP send queues can make this happen, if sk_mem_reclaim()
+	 * is not called and more than 2 GBytes are released at once.
+	 *
+	 * If we reach 2 MBytes, reclaim 1 MBytes right now, there is
+	 * no need to hold that much forward allocation anyway.
+	 */
+	if (unlikely(sk->sk_forward_alloc >= 1 << 21))
+		__sk_mem_reclaim(sk, 1 << 20);
+}
+
+DECLARE_STATIC_KEY_FALSE(tcp_tx_skb_cache_key);
+static inline void sk_wmem_free_skb(struct sock *sk, struct sk_buff *skb)
+{
+	sk_wmem_queued_add(sk, -skb->truesize);
+	sk_mem_uncharge(sk, skb->truesize);
+	if (static_branch_unlikely(&tcp_tx_skb_cache_key) &&
+	    !sk->sk_tx_skb_cache && !skb_cloned(skb)) {
+		skb_ext_reset(skb);
+		skb_zcopy_clear(skb, true);
+		sk->sk_tx_skb_cache = skb;
+		return;
+	}
+	__kfree_skb(skb);
+}
+
+static inline void sock_release_ownership(struct sock *sk)
+{
+	if (sk->sk_lock.owned) {
+		sk->sk_lock.owned = 0;
+
+		/* The sk_lock has mutex_unlock() semantics: */
+		mutex_release(&sk->sk_lock.dep_map, _RET_IP_);
+	}
+}
+
+/*
+ * Macro so as to not evaluate some arguments when
+ * lockdep is not enabled.
+ *
+ * Mark both the sk_lock and the sk_lock.slock as a
+ * per-address-family lock class.
+ */
+#define sock_lock_init_class_and_name(sk, sname, skey, name, key)	\
+do {									\
+	sk->sk_lock.owned = 0;						\
+	init_waitqueue_head(&sk->sk_lock.wq);				\
+	spin_lock_init(&(sk)->sk_lock.slock);				\
+	debug_check_no_locks_freed((void *)&(sk)->sk_lock,		\
+			sizeof((sk)->sk_lock));				\
+	lockdep_set_class_and_name(&(sk)->sk_lock.slock,		\
+				(skey), (sname));				\
+	lockdep_init_map(&(sk)->sk_lock.dep_map, (name), (key), 0);	\
+} while (0)
+
+static inline bool lockdep_sock_is_held(const struct sock *sk)
+{
+	return lockdep_is_held(&sk->sk_lock) ||
+	       lockdep_is_held(&sk->sk_lock.slock);
+}
+
+void lock_sock_nested(struct sock *sk, int subclass);
+
+static inline void lock_sock(struct sock *sk)
+{
+	lock_sock_nested(sk, 0);
+}
+
+void __lock_sock(struct sock *sk);
+void __release_sock(struct sock *sk);
+void release_sock(struct sock *sk);
+
+/* BH context may only use the following locking interface. */
+#define bh_lock_sock(__sk)	spin_lock(&((__sk)->sk_lock.slock))
+#define bh_lock_sock_nested(__sk) \
+				spin_lock_nested(&((__sk)->sk_lock.slock), \
+				SINGLE_DEPTH_NESTING)
+#define bh_unlock_sock(__sk)	spin_unlock(&((__sk)->sk_lock.slock))
+
+bool __lock_sock_fast(struct sock *sk) __acquires(&sk->sk_lock.slock);
+
+/**
+ * lock_sock_fast - fast version of lock_sock
+ * @sk: socket
+ *
+ * This version should be used for very small section, where process wont block
+ * return false if fast path is taken:
+ *
+ *   sk_lock.slock locked, owned = 0, BH disabled
+ *
+ * return true if slow path is taken:
+ *
+ *   sk_lock.slock unlocked, owned = 1, BH enabled
+ */
+static inline bool lock_sock_fast(struct sock *sk)
+{
+	/* The sk_lock has mutex_lock() semantics here. */
+	mutex_acquire(&sk->sk_lock.dep_map, 0, 0, _RET_IP_);
+
+	return __lock_sock_fast(sk);
+}
+
+/* fast socket lock variant for caller already holding a [different] socket lock */
+static inline bool lock_sock_fast_nested(struct sock *sk)
+{
+	mutex_acquire(&sk->sk_lock.dep_map, SINGLE_DEPTH_NESTING, 0, _RET_IP_);
+
+	return __lock_sock_fast(sk);
+}
+
+/**
+ * unlock_sock_fast - complement of lock_sock_fast
+ * @sk: socket
+ * @slow: slow mode
+ *
+ * fast unlock socket for user context.
+ * If slow mode is on, we call regular release_sock()
+ */
+static inline void unlock_sock_fast(struct sock *sk, bool slow)
+	__releases(&sk->sk_lock.slock)
+{
+	if (slow) {
+		release_sock(sk);
+		__release(&sk->sk_lock.slock);
+	} else {
+		mutex_release(&sk->sk_lock.dep_map, _RET_IP_);
+		spin_unlock_bh(&sk->sk_lock.slock);
+	}
+}
+
+/* Used by processes to "lock" a socket state, so that
+ * interrupts and bottom half handlers won't change it
+ * from under us. It essentially blocks any incoming
+ * packets, so that we won't get any new data or any
+ * packets that change the state of the socket.
+ *
+ * While locked, BH processing will add new packets to
+ * the backlog queue.  This queue is processed by the
+ * owner of the socket lock right before it is released.
+ *
+ * Since ~2.3.5 it is also exclusive sleep lock serializing
+ * accesses from user process context.
+ */
+
+static inline void sock_owned_by_me(const struct sock *sk)
+{
+#ifdef CONFIG_LOCKDEP
+	WARN_ON_ONCE(!lockdep_sock_is_held(sk) && debug_locks);
+#endif
+}
+
+static inline bool sock_owned_by_user(const struct sock *sk)
+{
+	sock_owned_by_me(sk);
+	return sk->sk_lock.owned;
+}
+
+static inline bool sock_owned_by_user_nocheck(const struct sock *sk)
+{
+	return sk->sk_lock.owned;
+}
+
+/* no reclassification while locks are held */
+static inline bool sock_allow_reclassification(const struct sock *csk)
+{
+	struct sock *sk = (struct sock *)csk;
+
+	return !sk->sk_lock.owned && !spin_is_locked(&sk->sk_lock.slock);
+}
+
+struct sock *sk_alloc(struct net *net, int family, gfp_t priority,
+		      struct proto *prot, int kern);
+void sk_free(struct sock *sk);
+void sk_destruct(struct sock *sk);
+struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority);
+void sk_free_unlock_clone(struct sock *sk);
+
+struct sk_buff *sock_wmalloc(struct sock *sk, unsigned long size, int force,
+			     gfp_t priority);
+void __sock_wfree(struct sk_buff *skb);
+void sock_wfree(struct sk_buff *skb);
+struct sk_buff *sock_omalloc(struct sock *sk, unsigned long size,
+			     gfp_t priority);
+void skb_orphan_partial(struct sk_buff *skb);
+void sock_rfree(struct sk_buff *skb);
+void sock_efree(struct sk_buff *skb);
+#ifdef CONFIG_INET
+void sock_edemux(struct sk_buff *skb);
+void sock_pfree(struct sk_buff *skb);
+#else
+#define sock_edemux sock_efree
+#endif
+
+int sock_setsockopt(struct socket *sock, int level, int op,
+		    sockptr_t optval, unsigned int optlen);
+
+int sock_getsockopt(struct socket *sock, int level, int op,
+		    char __user *optval, int __user *optlen);
+int sock_gettstamp(struct socket *sock, void __user *userstamp,
+		   bool timeval, bool time32);
+struct sk_buff *sock_alloc_send_skb(struct sock *sk, unsigned long size,
+				    int noblock, int *errcode);
+struct sk_buff *sock_alloc_send_pskb(struct sock *sk, unsigned long header_len,
+				     unsigned long data_len, int noblock,
+				     int *errcode, int max_page_order);
+void *sock_kmalloc(struct sock *sk, int size, gfp_t priority);
+void sock_kfree_s(struct sock *sk, void *mem, int size);
+void sock_kzfree_s(struct sock *sk, void *mem, int size);
+void sk_send_sigurg(struct sock *sk);
+
+struct sockcm_cookie {
+	u64 transmit_time;
+	u32 mark;
+	u16 tsflags;
+};
+
+static inline void sockcm_init(struct sockcm_cookie *sockc,
+			       const struct sock *sk)
+{
+	*sockc = (struct sockcm_cookie) { .tsflags = sk->sk_tsflags };
+}
+
+int __sock_cmsg_send(struct sock *sk, struct msghdr *msg, struct cmsghdr *cmsg,
+		     struct sockcm_cookie *sockc);
+int sock_cmsg_send(struct sock *sk, struct msghdr *msg,
+		   struct sockcm_cookie *sockc);
+
+/*
+ * Functions to fill in entries in struct proto_ops when a protocol
+ * does not implement a particular function.
+ */
+int sock_no_bind(struct socket *, struct sockaddr *, int);
+int sock_no_connect(struct socket *, struct sockaddr *, int, int);
+int sock_no_socketpair(struct socket *, struct socket *);
+int sock_no_accept(struct socket *, struct socket *, int, bool);
+int sock_no_getname(struct socket *, struct sockaddr *, int);
+int sock_no_ioctl(struct socket *, unsigned int, unsigned long);
+int sock_no_listen(struct socket *, int);
+int sock_no_shutdown(struct socket *, int);
+int sock_no_sendmsg(struct socket *, struct msghdr *, size_t);
+int sock_no_sendmsg_locked(struct sock *sk, struct msghdr *msg, size_t len);
+int sock_no_recvmsg(struct socket *, struct msghdr *, size_t, int);
+int sock_no_mmap(struct file *file, struct socket *sock,
+		 struct vm_area_struct *vma);
+ssize_t sock_no_sendpage(struct socket *sock, struct page *page, int offset,
+			 size_t size, int flags);
+ssize_t sock_no_sendpage_locked(struct sock *sk, struct page *page,
+				int offset, size_t size, int flags);
+
+/*
+ * Functions to fill in entries in struct proto_ops when a protocol
+ * uses the inet style.
+ */
+int sock_common_getsockopt(struct socket *sock, int level, int optname,
+				  char __user *optval, int __user *optlen);
+int sock_common_recvmsg(struct socket *sock, struct msghdr *msg, size_t size,
+			int flags);
+int sock_common_setsockopt(struct socket *sock, int level, int optname,
+			   sockptr_t optval, unsigned int optlen);
+
+void sk_common_release(struct sock *sk);
+
+/*
+ *	Default socket callbacks and setup code
+ */
+
+/* Initialise core socket variables */
+void sock_init_data(struct socket *sock, struct sock *sk);
+
+/*
+ * Socket reference counting postulates.
+ *
+ * * Each user of socket SHOULD hold a reference count.
+ * * Each access point to socket (an hash table bucket, reference from a list,
+ *   running timer, skb in flight MUST hold a reference count.
+ * * When reference count hits 0, it means it will never increase back.
+ * * When reference count hits 0, it means that no references from
+ *   outside exist to this socket and current process on current CPU
+ *   is last user and may/should destroy this socket.
+ * * sk_free is called from any context: process, BH, IRQ. When
+ *   it is called, socket has no references from outside -> sk_free
+ *   may release descendant resources allocated by the socket, but
+ *   to the time when it is called, socket is NOT referenced by any
+ *   hash tables, lists etc.
+ * * Packets, delivered from outside (from network or from another process)
+ *   and enqueued on receive/error queues SHOULD NOT grab reference count,
+ *   when they sit in queue. Otherwise, packets will leak to hole, when
+ *   socket is looked up by one cpu and unhasing is made by another CPU.
+ *   It is true for udp/raw, netlink (leak to receive and error queues), tcp
+ *   (leak to backlog). Packet socket does all the processing inside
+ *   BR_NETPROTO_LOCK, so that it has not this race condition. UNIX sockets
+ *   use separate SMP lock, so that they are prone too.
+ */
+
+/* Ungrab socket and destroy it, if it was the last reference. */
+static inline void sock_put(struct sock *sk)
+{
+	if (refcount_dec_and_test(&sk->sk_refcnt))
+		sk_free(sk);
+}
+/* Generic version of sock_put(), dealing with all sockets
+ * (TCP_TIMEWAIT, TCP_NEW_SYN_RECV, ESTABLISHED...)
+ */
+void sock_gen_put(struct sock *sk);
+
+int __sk_receive_skb(struct sock *sk, struct sk_buff *skb, const int nested,
+		     unsigned int trim_cap, bool refcounted);
+static inline int sk_receive_skb(struct sock *sk, struct sk_buff *skb,
+				 const int nested)
+{
+	return __sk_receive_skb(sk, skb, nested, 1, true);
+}
+
+static inline void sk_tx_queue_set(struct sock *sk, int tx_queue)
+{
+	/* sk_tx_queue_mapping accept only upto a 16-bit value */
+	if (WARN_ON_ONCE((unsigned short)tx_queue >= USHRT_MAX))
+		return;
+	sk->sk_tx_queue_mapping = tx_queue;
+}
+
+#define NO_QUEUE_MAPPING	USHRT_MAX
+
+static inline void sk_tx_queue_clear(struct sock *sk)
+{
+	sk->sk_tx_queue_mapping = NO_QUEUE_MAPPING;
+}
+
+static inline int sk_tx_queue_get(const struct sock *sk)
+{
+	if (sk && sk->sk_tx_queue_mapping != NO_QUEUE_MAPPING)
+		return sk->sk_tx_queue_mapping;
+
+	return -1;
+}
+
+static inline void sk_rx_queue_set(struct sock *sk, const struct sk_buff *skb)
+{
+#ifdef CONFIG_SOCK_RX_QUEUE_MAPPING
+	if (skb_rx_queue_recorded(skb)) {
+		u16 rx_queue = skb_get_rx_queue(skb);
+
+		if (WARN_ON_ONCE(rx_queue == NO_QUEUE_MAPPING))
+			return;
+
+		sk->sk_rx_queue_mapping = rx_queue;
+	}
+#endif
+}
+
+static inline void sk_rx_queue_clear(struct sock *sk)
+{
+#ifdef CONFIG_SOCK_RX_QUEUE_MAPPING
+	sk->sk_rx_queue_mapping = NO_QUEUE_MAPPING;
+#endif
+}
+
+static inline int sk_rx_queue_get(const struct sock *sk)
+{
+#ifdef CONFIG_SOCK_RX_QUEUE_MAPPING
+	if (sk && sk->sk_rx_queue_mapping != NO_QUEUE_MAPPING)
+		return sk->sk_rx_queue_mapping;
+#endif
+
+	return -1;
+}
+
+static inline void sk_set_socket(struct sock *sk, struct socket *sock)
+{
+	sk->sk_socket = sock;
+}
+
+static inline wait_queue_head_t *sk_sleep(struct sock *sk)
+{
+	BUILD_BUG_ON(offsetof(struct socket_wq, wait) != 0);
+	return &rcu_dereference_raw(sk->sk_wq)->wait;
+}
+/* Detach socket from process context.
+ * Announce socket dead, detach it from wait queue and inode.
+ * Note that parent inode held reference count on this struct sock,
+ * we do not release it in this function, because protocol
+ * probably wants some additional cleanups or even continuing
+ * to work with this socket (TCP).
+ */
+static inline void sock_orphan(struct sock *sk)
+{
+	write_lock_bh(&sk->sk_callback_lock);
+	sock_set_flag(sk, SOCK_DEAD);
+	sk_set_socket(sk, NULL);
+	sk->sk_wq  = NULL;
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+static inline void sock_graft(struct sock *sk, struct socket *parent)
+{
+	WARN_ON(parent->sk);
+	write_lock_bh(&sk->sk_callback_lock);
+	rcu_assign_pointer(sk->sk_wq, &parent->wq);
+	parent->sk = sk;
+	sk_set_socket(sk, parent);
+	sk->sk_uid = SOCK_INODE(parent)->i_uid;
+	security_sock_graft(sk, parent);
+	write_unlock_bh(&sk->sk_callback_lock);
+}
+
+kuid_t sock_i_uid(struct sock *sk);
+unsigned long sock_i_ino(struct sock *sk);
+
+static inline kuid_t sock_net_uid(const struct net *net, const struct sock *sk)
+{
+	return sk ? sk->sk_uid : make_kuid(net->user_ns, 0);
+}
+
+static inline u32 net_tx_rndhash(void)
+{
+	u32 v = prandom_u32();
+
+	return v ?: 1;
+}
+
+static inline void sk_set_txhash(struct sock *sk)
+{
+	/* This pairs with READ_ONCE() in skb_set_hash_from_sk() */
+	WRITE_ONCE(sk->sk_txhash, net_tx_rndhash());
+}
+
+static inline bool sk_rethink_txhash(struct sock *sk)
+{
+	if (sk->sk_txhash) {
+		sk_set_txhash(sk);
+		return true;
+	}
+	return false;
+}
+
+static inline struct dst_entry *
+__sk_dst_get(struct sock *sk)
+{
+	return rcu_dereference_check(sk->sk_dst_cache,
+				     lockdep_sock_is_held(sk));
+}
+
+static inline struct dst_entry *
+sk_dst_get(struct sock *sk)
+{
+	struct dst_entry *dst;
+
+	rcu_read_lock();
+	dst = rcu_dereference(sk->sk_dst_cache);
+	if (dst && !atomic_inc_not_zero(&dst->__refcnt))
+		dst = NULL;
+	rcu_read_unlock();
+	return dst;
+}
+
+static inline void __dst_negative_advice(struct sock *sk)
+{
+	struct dst_entry *ndst, *dst = __sk_dst_get(sk);
+
+	if (dst && dst->ops->negative_advice) {
+		ndst = dst->ops->negative_advice(dst);
+
+		if (ndst != dst) {
+			rcu_assign_pointer(sk->sk_dst_cache, ndst);
+			sk_tx_queue_clear(sk);
+			sk->sk_dst_pending_confirm = 0;
+		}
+	}
+}
+
+static inline void dst_negative_advice(struct sock *sk)
+{
+	sk_rethink_txhash(sk);
+	__dst_negative_advice(sk);
+}
+
+static inline void
+__sk_dst_set(struct sock *sk, struct dst_entry *dst)
+{
+	struct dst_entry *old_dst;
+
+	sk_tx_queue_clear(sk);
+	sk->sk_dst_pending_confirm = 0;
+	old_dst = rcu_dereference_protected(sk->sk_dst_cache,
+					    lockdep_sock_is_held(sk));
+	rcu_assign_pointer(sk->sk_dst_cache, dst);
+	dst_release(old_dst);
+}
+
+static inline void
+sk_dst_set(struct sock *sk, struct dst_entry *dst)
+{
+	struct dst_entry *old_dst;
+
+	sk_tx_queue_clear(sk);
+	sk->sk_dst_pending_confirm = 0;
+	old_dst = xchg((__force struct dst_entry **)&sk->sk_dst_cache, dst);
+	dst_release(old_dst);
+}
+
+static inline void
+__sk_dst_reset(struct sock *sk)
+{
+	__sk_dst_set(sk, NULL);
+}
+
+static inline void
+sk_dst_reset(struct sock *sk)
+{
+	sk_dst_set(sk, NULL);
+}
+
+struct dst_entry *__sk_dst_check(struct sock *sk, u32 cookie);
+
+struct dst_entry *sk_dst_check(struct sock *sk, u32 cookie);
+
+static inline void sk_dst_confirm(struct sock *sk)
+{
+	if (!READ_ONCE(sk->sk_dst_pending_confirm))
+		WRITE_ONCE(sk->sk_dst_pending_confirm, 1);
+}
+
+static inline void sock_confirm_neigh(struct sk_buff *skb, struct neighbour *n)
+{
+	if (skb_get_dst_pending_confirm(skb)) {
+		struct sock *sk = skb->sk;
+		unsigned long now = jiffies;
+
+		/* avoid dirtying neighbour */
+		if (READ_ONCE(n->confirmed) != now)
+			WRITE_ONCE(n->confirmed, now);
+		if (sk && READ_ONCE(sk->sk_dst_pending_confirm))
+			WRITE_ONCE(sk->sk_dst_pending_confirm, 0);
+	}
+}
+
+bool sk_mc_loop(struct sock *sk);
+
+static inline bool sk_can_gso(const struct sock *sk)
+{
+	return net_gso_ok(sk->sk_route_caps, sk->sk_gso_type);
+}
+
+void sk_setup_caps(struct sock *sk, struct dst_entry *dst);
+
+static inline void sk_nocaps_add(struct sock *sk, netdev_features_t flags)
+{
+	sk->sk_route_nocaps |= flags;
+	sk->sk_route_caps &= ~flags;
+}
+
+static inline int skb_do_copy_data_nocache(struct sock *sk, struct sk_buff *skb,
+					   struct iov_iter *from, char *to,
+					   int copy, int offset)
+{
+	if (skb->ip_summed == CHECKSUM_NONE) {
+		__wsum csum = 0;
+		if (!csum_and_copy_from_iter_full(to, copy, &csum, from))
+			return -EFAULT;
+		skb->csum = csum_block_add(skb->csum, csum, offset);
+	} else if (sk->sk_route_caps & NETIF_F_NOCACHE_COPY) {
+		if (!copy_from_iter_full_nocache(to, copy, from))
+			return -EFAULT;
+	} else if (!copy_from_iter_full(to, copy, from))
+		return -EFAULT;
+
+	return 0;
+}
+
+static inline int skb_add_data_nocache(struct sock *sk, struct sk_buff *skb,
+				       struct iov_iter *from, int copy)
+{
+	int err, offset = skb->len;
+
+	err = skb_do_copy_data_nocache(sk, skb, from, skb_put(skb, copy),
+				       copy, offset);
+	if (err)
+		__skb_trim(skb, offset);
+
+	return err;
+}
+
+static inline int skb_copy_to_page_nocache(struct sock *sk, struct iov_iter *from,
+					   struct sk_buff *skb,
+					   struct page *page,
+					   int off, int copy)
+{
+	int err;
+
+	err = skb_do_copy_data_nocache(sk, skb, from, page_address(page) + off,
+				       copy, skb->len);
+	if (err)
+		return err;
+
+	skb->len	     += copy;
+	skb->data_len	     += copy;
+	skb->truesize	     += copy;
+	sk_wmem_queued_add(sk, copy);
+	sk_mem_charge(sk, copy);
+	return 0;
+}
+
+/**
+ * sk_wmem_alloc_get - returns write allocations
+ * @sk: socket
+ *
+ * Return: sk_wmem_alloc minus initial offset of one
+ */
+static inline int sk_wmem_alloc_get(const struct sock *sk)
+{
+	return refcount_read(&sk->sk_wmem_alloc) - 1;
+}
+
+/**
+ * sk_rmem_alloc_get - returns read allocations
+ * @sk: socket
+ *
+ * Return: sk_rmem_alloc
+ */
+static inline int sk_rmem_alloc_get(const struct sock *sk)
+{
+	return atomic_read(&sk->sk_rmem_alloc);
+}
+
+/**
+ * sk_has_allocations - check if allocations are outstanding
+ * @sk: socket
+ *
+ * Return: true if socket has write or read allocations
+ */
+static inline bool sk_has_allocations(const struct sock *sk)
+{
+	return sk_wmem_alloc_get(sk) || sk_rmem_alloc_get(sk);
+}
+
+/**
+ * skwq_has_sleeper - check if there are any waiting processes
+ * @wq: struct socket_wq
+ *
+ * Return: true if socket_wq has waiting processes
+ *
+ * The purpose of the skwq_has_sleeper and sock_poll_wait is to wrap the memory
+ * barrier call. They were added due to the race found within the tcp code.
+ *
+ * Consider following tcp code paths::
+ *
+ *   CPU1                CPU2
+ *   sys_select          receive packet
+ *   ...                 ...
+ *   __add_wait_queue    update tp->rcv_nxt
+ *   ...                 ...
+ *   tp->rcv_nxt check   sock_def_readable
+ *   ...                 {
+ *   schedule               rcu_read_lock();
+ *                          wq = rcu_dereference(sk->sk_wq);
+ *                          if (wq && waitqueue_active(&wq->wait))
+ *                              wake_up_interruptible(&wq->wait)
+ *                          ...
+ *                       }
+ *
+ * The race for tcp fires when the __add_wait_queue changes done by CPU1 stay
+ * in its cache, and so does the tp->rcv_nxt update on CPU2 side.  The CPU1
+ * could then endup calling schedule and sleep forever if there are no more
+ * data on the socket.
+ *
+ */
+static inline bool skwq_has_sleeper(struct socket_wq *wq)
+{
+	return wq && wq_has_sleeper(&wq->wait);
+}
+
+/**
+ * sock_poll_wait - place memory barrier behind the poll_wait call.
+ * @filp:           file
+ * @sock:           socket to wait on
+ * @p:              poll_table
+ *
+ * See the comments in the wq_has_sleeper function.
+ */
+static inline void sock_poll_wait(struct file *filp, struct socket *sock,
+				  poll_table *p)
+{
+	if (!poll_does_not_wait(p)) {
+		poll_wait(filp, &sock->wq.wait, p);
+		/* We need to be sure we are in sync with the
+		 * socket flags modification.
+		 *
+		 * This memory barrier is paired in the wq_has_sleeper.
+		 */
+		smp_mb();
+	}
+}
+
+static inline void skb_set_hash_from_sk(struct sk_buff *skb, struct sock *sk)
+{
+	/* This pairs with WRITE_ONCE() in sk_set_txhash() */
+	u32 txhash = READ_ONCE(sk->sk_txhash);
+
+	if (txhash) {
+		skb->l4_hash = 1;
+		skb->hash = txhash;
+	}
+}
+
+void skb_set_owner_w(struct sk_buff *skb, struct sock *sk);
+
+/*
+ *	Queue a received datagram if it will fit. Stream and sequenced
+ *	protocols can't normally use this as they need to fit buffers in
+ *	and play with them.
+ *
+ *	Inlined as it's very short and called for pretty much every
+ *	packet ever received.
+ */
+static inline void skb_set_owner_r(struct sk_buff *skb, struct sock *sk)
+{
+	skb_orphan(skb);
+	skb->sk = sk;
+	skb->destructor = sock_rfree;
+	atomic_add(skb->truesize, &sk->sk_rmem_alloc);
+	sk_mem_charge(sk, skb->truesize);
+}
+
+static inline __must_check bool skb_set_owner_sk_safe(struct sk_buff *skb, struct sock *sk)
+{
+	if (sk && refcount_inc_not_zero(&sk->sk_refcnt)) {
+		skb_orphan(skb);
+		skb->destructor = sock_efree;
+		skb->sk = sk;
+		return true;
+	}
+	return false;
+}
+
+static inline void skb_prepare_for_gro(struct sk_buff *skb)
+{
+	if (skb->destructor != sock_wfree) {
+		skb_orphan(skb);
+		return;
+	}
+	skb->slow_gro = 1;
+}
+
+void sk_reset_timer(struct sock *sk, struct timer_list *timer,
+		    unsigned long expires);
+
+void sk_stop_timer(struct sock *sk, struct timer_list *timer);
+
+void sk_stop_timer_sync(struct sock *sk, struct timer_list *timer);
+
+int __sk_queue_drop_skb(struct sock *sk, struct sk_buff_head *sk_queue,
+			struct sk_buff *skb, unsigned int flags,
+			void (*destructor)(struct sock *sk,
+					   struct sk_buff *skb));
+int __sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
+int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
+
+int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb);
+struct sk_buff *sock_dequeue_err_skb(struct sock *sk);
+
+/*
+ *	Recover an error report and clear atomically
+ */
+
+static inline int sock_error(struct sock *sk)
+{
+	int err;
+
+	/* Avoid an atomic operation for the common case.
+	 * This is racy since another cpu/thread can change sk_err under us.
+	 */
+	if (likely(data_race(!sk->sk_err)))
+		return 0;
+
+	err = xchg(&sk->sk_err, 0);
+	return -err;
+}
+
+void sk_error_report(struct sock *sk);
+
+static inline unsigned long sock_wspace(struct sock *sk)
+{
+	int amt = 0;
+
+	if (!(sk->sk_shutdown & SEND_SHUTDOWN)) {
+		amt = sk->sk_sndbuf - refcount_read(&sk->sk_wmem_alloc);
+		if (amt < 0)
+			amt = 0;
+	}
+	return amt;
+}
+
+/* Note:
+ *  We use sk->sk_wq_raw, from contexts knowing this
+ *  pointer is not NULL and cannot disappear/change.
+ */
+static inline void sk_set_bit(int nr, struct sock *sk)
+{
+	if ((nr == SOCKWQ_ASYNC_NOSPACE || nr == SOCKWQ_ASYNC_WAITDATA) &&
+	    !sock_flag(sk, SOCK_FASYNC))
+		return;
+
+	set_bit(nr, &sk->sk_wq_raw->flags);
+}
+
+static inline void sk_clear_bit(int nr, struct sock *sk)
+{
+	if ((nr == SOCKWQ_ASYNC_NOSPACE || nr == SOCKWQ_ASYNC_WAITDATA) &&
+	    !sock_flag(sk, SOCK_FASYNC))
+		return;
+
+	clear_bit(nr, &sk->sk_wq_raw->flags);
+}
+
+static inline void sk_wake_async(const struct sock *sk, int how, int band)
+{
+	if (sock_flag(sk, SOCK_FASYNC)) {
+		rcu_read_lock();
+		sock_wake_async(rcu_dereference(sk->sk_wq), how, band);
+		rcu_read_unlock();
+	}
+}
+
+/* Since sk_{r,w}mem_alloc sums skb->truesize, even a small frame might
+ * need sizeof(sk_buff) + MTU + padding, unless net driver perform copybreak.
+ * Note: for send buffers, TCP works better if we can build two skbs at
+ * minimum.
+ */
+#define TCP_SKB_MIN_TRUESIZE	(2048 + SKB_DATA_ALIGN(sizeof(struct sk_buff)))
+
+#define SOCK_MIN_SNDBUF		(TCP_SKB_MIN_TRUESIZE * 2)
+#define SOCK_MIN_RCVBUF		 TCP_SKB_MIN_TRUESIZE
+
+static inline void sk_stream_moderate_sndbuf(struct sock *sk)
+{
+	u32 val;
+
+	if (sk->sk_userlocks & SOCK_SNDBUF_LOCK)
+		return;
+
+	val = min(sk->sk_sndbuf, sk->sk_wmem_queued >> 1);
+
+	WRITE_ONCE(sk->sk_sndbuf, max_t(u32, val, SOCK_MIN_SNDBUF));
+}
+
+struct sk_buff *sk_stream_alloc_skb(struct sock *sk, int size, gfp_t gfp,
+				    bool force_schedule);
+
+/**
+ * sk_page_frag - return an appropriate page_frag
+ * @sk: socket
+ *
+ * Use the per task page_frag instead of the per socket one for
+ * optimization when we know that we're in the normal context and owns
+ * everything that's associated with %current.
+ *
+ * gfpflags_allow_blocking() isn't enough here as direct reclaim may nest
+ * inside other socket operations and end up recursing into sk_page_frag()
+ * while it's already in use.
+ *
+ * Return: a per task page_frag if context allows that,
+ * otherwise a per socket one.
+ */
+static inline struct page_frag *sk_page_frag(struct sock *sk)
+{
+	if (gfpflags_normal_context(sk->sk_allocation))
+		return &current->task_frag;
+
+	return &sk->sk_frag;
+}
+
+bool sk_page_frag_refill(struct sock *sk, struct page_frag *pfrag);
+
+/*
+ *	Default write policy as shown to user space via poll/select/SIGIO
+ */
+static inline bool sock_writeable(const struct sock *sk)
+{
+	return refcount_read(&sk->sk_wmem_alloc) < (READ_ONCE(sk->sk_sndbuf) >> 1);
+}
+
+static inline gfp_t gfp_any(void)
+{
+	return in_softirq() ? GFP_ATOMIC : GFP_KERNEL;
+}
+
+static inline gfp_t gfp_memcg_charge(void)
+{
+	return in_softirq() ? GFP_NOWAIT : GFP_KERNEL;
+}
+
+static inline long sock_rcvtimeo(const struct sock *sk, bool noblock)
+{
+	return noblock ? 0 : sk->sk_rcvtimeo;
+}
+
+static inline long sock_sndtimeo(const struct sock *sk, bool noblock)
+{
+	return noblock ? 0 : sk->sk_sndtimeo;
+}
+
+static inline int sock_rcvlowat(const struct sock *sk, int waitall, int len)
+{
+	int v = waitall ? len : min_t(int, READ_ONCE(sk->sk_rcvlowat), len);
+
+	return v ?: 1;
+}
+
+/* Alas, with timeout socket operations are not restartable.
+ * Compare this to poll().
+ */
+static inline int sock_intr_errno(long timeo)
+{
+	return timeo == MAX_SCHEDULE_TIMEOUT ? -ERESTARTSYS : -EINTR;
+}
+
+struct sock_skb_cb {
+	u32 dropcount;
+};
+
+/* Store sock_skb_cb at the end of skb->cb[] so protocol families
+ * using skb->cb[] would keep using it directly and utilize its
+ * alignement guarantee.
+ */
+#define SOCK_SKB_CB_OFFSET ((sizeof_field(struct sk_buff, cb) - \
+			    sizeof(struct sock_skb_cb)))
+
+#define SOCK_SKB_CB(__skb) ((struct sock_skb_cb *)((__skb)->cb + \
+			    SOCK_SKB_CB_OFFSET))
+
+#define sock_skb_cb_check_size(size) \
+	BUILD_BUG_ON((size) > SOCK_SKB_CB_OFFSET)
+
+static inline void
+sock_skb_set_dropcount(const struct sock *sk, struct sk_buff *skb)
+{
+	SOCK_SKB_CB(skb)->dropcount = sock_flag(sk, SOCK_RXQ_OVFL) ?
+						atomic_read(&sk->sk_drops) : 0;
+}
+
+static inline void sk_drops_add(struct sock *sk, const struct sk_buff *skb)
+{
+	int segs = max_t(u16, 1, skb_shinfo(skb)->gso_segs);
+
+	atomic_add(segs, &sk->sk_drops);
+}
+
+static inline ktime_t sock_read_timestamp(struct sock *sk)
+{
+#if BITS_PER_LONG==32
+	unsigned int seq;
+	ktime_t kt;
+
+	do {
+		seq = read_seqbegin(&sk->sk_stamp_seq);
+		kt = sk->sk_stamp;
+	} while (read_seqretry(&sk->sk_stamp_seq, seq));
+
+	return kt;
+#else
+	return READ_ONCE(sk->sk_stamp);
+#endif
+}
+
+static inline void sock_write_timestamp(struct sock *sk, ktime_t kt)
+{
+#if BITS_PER_LONG==32
+	write_seqlock(&sk->sk_stamp_seq);
+	sk->sk_stamp = kt;
+	write_sequnlock(&sk->sk_stamp_seq);
+#else
+	WRITE_ONCE(sk->sk_stamp, kt);
+#endif
+}
+
+void __sock_recv_timestamp(struct msghdr *msg, struct sock *sk,
+			   struct sk_buff *skb);
+void __sock_recv_wifi_status(struct msghdr *msg, struct sock *sk,
+			     struct sk_buff *skb);
+
+static inline void
+sock_recv_timestamp(struct msghdr *msg, struct sock *sk, struct sk_buff *skb)
+{
+	ktime_t kt = skb->tstamp;
+	struct skb_shared_hwtstamps *hwtstamps = skb_hwtstamps(skb);
+
+	/*
+	 * generate control messages if
+	 * - receive time stamping in software requested
+	 * - software time stamp available and wanted
+	 * - hardware time stamps available and wanted
+	 */
+	if (sock_flag(sk, SOCK_RCVTSTAMP) ||
+	    (sk->sk_tsflags & SOF_TIMESTAMPING_RX_SOFTWARE) ||
+	    (kt && sk->sk_tsflags & SOF_TIMESTAMPING_SOFTWARE) ||
+	    (hwtstamps->hwtstamp &&
+	     (sk->sk_tsflags & SOF_TIMESTAMPING_RAW_HARDWARE)))
+		__sock_recv_timestamp(msg, sk, skb);
+	else
+		sock_write_timestamp(sk, kt);
+
+	if (sock_flag(sk, SOCK_WIFI_STATUS) && skb->wifi_acked_valid)
+		__sock_recv_wifi_status(msg, sk, skb);
+}
+
+void __sock_recv_ts_and_drops(struct msghdr *msg, struct sock *sk,
+			      struct sk_buff *skb);
+
+#define SK_DEFAULT_STAMP (-1L * NSEC_PER_SEC)
+static inline void sock_recv_ts_and_drops(struct msghdr *msg, struct sock *sk,
+					  struct sk_buff *skb)
+{
+#define FLAGS_TS_OR_DROPS ((1UL << SOCK_RXQ_OVFL)			| \
+			   (1UL << SOCK_RCVTSTAMP))
+#define TSFLAGS_ANY	  (SOF_TIMESTAMPING_SOFTWARE			| \
+			   SOF_TIMESTAMPING_RAW_HARDWARE)
+
+	if (sk->sk_flags & FLAGS_TS_OR_DROPS || sk->sk_tsflags & TSFLAGS_ANY)
+		__sock_recv_ts_and_drops(msg, sk, skb);
+	else if (unlikely(sock_flag(sk, SOCK_TIMESTAMP)))
+		sock_write_timestamp(sk, skb->tstamp);
+	else if (unlikely(sk->sk_stamp == SK_DEFAULT_STAMP))
+		sock_write_timestamp(sk, 0);
+}
+
+void __sock_tx_timestamp(__u16 tsflags, __u8 *tx_flags);
+
+/**
+ * _sock_tx_timestamp - checks whether the outgoing packet is to be time stamped
+ * @sk:		socket sending this packet
+ * @tsflags:	timestamping flags to use
+ * @tx_flags:	completed with instructions for time stamping
+ * @tskey:      filled in with next sk_tskey (not for TCP, which uses seqno)
+ *
+ * Note: callers should take care of initial ``*tx_flags`` value (usually 0)
+ */
+static inline void _sock_tx_timestamp(struct sock *sk, __u16 tsflags,
+				      __u8 *tx_flags, __u32 *tskey)
+{
+	if (unlikely(tsflags)) {
+		__sock_tx_timestamp(tsflags, tx_flags);
+		if (tsflags & SOF_TIMESTAMPING_OPT_ID && tskey &&
+		    tsflags & SOF_TIMESTAMPING_TX_RECORD_MASK)
+			*tskey = sk->sk_tskey++;
+	}
+	if (unlikely(sock_flag(sk, SOCK_WIFI_STATUS)))
+		*tx_flags |= SKBTX_WIFI_STATUS;
+}
+
+static inline void sock_tx_timestamp(struct sock *sk, __u16 tsflags,
+				     __u8 *tx_flags)
+{
+	_sock_tx_timestamp(sk, tsflags, tx_flags, NULL);
+}
+
+static inline void skb_setup_tx_timestamp(struct sk_buff *skb, __u16 tsflags)
+{
+	_sock_tx_timestamp(skb->sk, tsflags, &skb_shinfo(skb)->tx_flags,
+			   &skb_shinfo(skb)->tskey);
+}
+
+DECLARE_STATIC_KEY_FALSE(tcp_rx_skb_cache_key);
+/**
+ * sk_eat_skb - Release a skb if it is no longer needed
+ * @sk: socket to eat this skb from
+ * @skb: socket buffer to eat
+ *
+ * This routine must be called with interrupts disabled or with the socket
+ * locked so that the sk_buff queue operation is ok.
+*/
+static inline void sk_eat_skb(struct sock *sk, struct sk_buff *skb)
+{
+	__skb_unlink(skb, &sk->sk_receive_queue);
+	if (static_branch_unlikely(&tcp_rx_skb_cache_key) &&
+	    !sk->sk_rx_skb_cache) {
+		sk->sk_rx_skb_cache = skb;
+		skb_orphan(skb);
+		return;
+	}
+	__kfree_skb(skb);
+}
+
+static inline
+struct net *sock_net(const struct sock *sk)
+{
+	return read_pnet(&sk->sk_net);
+}
+
+static inline
+void sock_net_set(struct sock *sk, struct net *net)
+{
+	write_pnet(&sk->sk_net, net);
+}
+
+static inline bool
+skb_sk_is_prefetched(struct sk_buff *skb)
+{
+#ifdef CONFIG_INET
+	return skb->destructor == sock_pfree;
+#else
+	return false;
+#endif /* CONFIG_INET */
+}
+
+/* This helper checks if a socket is a full socket,
+ * ie _not_ a timewait or request socket.
+ */
+static inline bool sk_fullsock(const struct sock *sk)
+{
+	return (1 << sk->sk_state) & ~(TCPF_TIME_WAIT | TCPF_NEW_SYN_RECV);
+}
+
+static inline bool
+sk_is_refcounted(struct sock *sk)
+{
+	/* Only full sockets have sk->sk_flags. */
+	return !sk_fullsock(sk) || !sock_flag(sk, SOCK_RCU_FREE);
+}
+
+/**
+ * skb_steal_sock - steal a socket from an sk_buff
+ * @skb: sk_buff to steal the socket from
+ * @refcounted: is set to true if the socket is reference-counted
+ */
+static inline struct sock *
+skb_steal_sock(struct sk_buff *skb, bool *refcounted)
+{
+	if (skb->sk) {
+		struct sock *sk = skb->sk;
+
+		*refcounted = true;
+		if (skb_sk_is_prefetched(skb))
+			*refcounted = sk_is_refcounted(sk);
+		skb->destructor = NULL;
+		skb->sk = NULL;
+		return sk;
+	}
+	*refcounted = false;
+	return NULL;
+}
+
+/* Checks if this SKB belongs to an HW offloaded socket
+ * and whether any SW fallbacks are required based on dev.
+ * Check decrypted mark in case skb_orphan() cleared socket.
+ */
+static inline struct sk_buff *sk_validate_xmit_skb(struct sk_buff *skb,
+						   struct net_device *dev)
+{
+#ifdef CONFIG_SOCK_VALIDATE_XMIT
+	struct sock *sk = skb->sk;
+
+	if (sk && sk_fullsock(sk) && sk->sk_validate_xmit_skb) {
+		skb = sk->sk_validate_xmit_skb(sk, dev, skb);
+#ifdef CONFIG_TLS_DEVICE
+	} else if (unlikely(skb->decrypted)) {
+		pr_warn_ratelimited("unencrypted skb with no associated socket - dropping\n");
+		kfree_skb(skb);
+		skb = NULL;
+#endif
+	}
+#endif
+
+	return skb;
+}
+
+/* This helper checks if a socket is a LISTEN or NEW_SYN_RECV
+ * SYNACK messages can be attached to either ones (depending on SYNCOOKIE)
+ */
+static inline bool sk_listener(const struct sock *sk)
+{
+	return (1 << sk->sk_state) & (TCPF_LISTEN | TCPF_NEW_SYN_RECV);
+}
+
+void sock_enable_timestamp(struct sock *sk, enum sock_flags flag);
+int sock_recv_errqueue(struct sock *sk, struct msghdr *msg, int len, int level,
+		       int type);
+
+bool sk_ns_capable(const struct sock *sk,
+		   struct user_namespace *user_ns, int cap);
+bool sk_capable(const struct sock *sk, int cap);
+bool sk_net_capable(const struct sock *sk, int cap);
+
+void sk_get_meminfo(const struct sock *sk, u32 *meminfo);
+
+/* Take into consideration the size of the struct sk_buff overhead in the
+ * determination of these values, since that is non-constant across
+ * platforms.  This makes socket queueing behavior and performance
+ * not depend upon such differences.
+ */
+#define _SK_MEM_PACKETS		256
+#define _SK_MEM_OVERHEAD	SKB_TRUESIZE(256)
+#define SK_WMEM_MAX		(_SK_MEM_OVERHEAD * _SK_MEM_PACKETS)
+#define SK_RMEM_MAX		(_SK_MEM_OVERHEAD * _SK_MEM_PACKETS)
+
+extern __u32 sysctl_wmem_max;
+extern __u32 sysctl_rmem_max;
+
+extern int sysctl_tstamp_allow_data;
+extern int sysctl_optmem_max;
+
+extern __u32 sysctl_wmem_default;
+extern __u32 sysctl_rmem_default;
+
+#define SKB_FRAG_PAGE_ORDER	get_order(32768)
+DECLARE_STATIC_KEY_FALSE(net_high_order_alloc_disable_key);
+
+static inline int sk_get_wmem0(const struct sock *sk, const struct proto *proto)
+{
+	/* Does this proto have per netns sysctl_wmem ? */
+	if (proto->sysctl_wmem_offset)
+		return *(int *)((void *)sock_net(sk) + proto->sysctl_wmem_offset);
+
+	return *proto->sysctl_wmem;
+}
+
+static inline int sk_get_rmem0(const struct sock *sk, const struct proto *proto)
+{
+	/* Does this proto have per netns sysctl_rmem ? */
+	if (proto->sysctl_rmem_offset)
+		return *(int *)((void *)sock_net(sk) + proto->sysctl_rmem_offset);
+
+	return *proto->sysctl_rmem;
+}
+
+/* Default TCP Small queue budget is ~1 ms of data (1sec >> 10)
+ * Some wifi drivers need to tweak it to get more chunks.
+ * They can use this helper from their ndo_start_xmit()
+ */
+static inline void sk_pacing_shift_update(struct sock *sk, int val)
+{
+	if (!sk || !sk_fullsock(sk) || READ_ONCE(sk->sk_pacing_shift) == val)
+		return;
+	WRITE_ONCE(sk->sk_pacing_shift, val);
+}
+
+/* if a socket is bound to a device, check that the given device
+ * index is either the same or that the socket is bound to an L3
+ * master device and the given device index is also enslaved to
+ * that L3 master
+ */
+static inline bool sk_dev_equal_l3scope(struct sock *sk, int dif)
+{
+	int mdif;
+
+	if (!sk->sk_bound_dev_if || sk->sk_bound_dev_if == dif)
+		return true;
+
+	mdif = l3mdev_master_ifindex_by_index(sock_net(sk), dif);
+	if (mdif && mdif == sk->sk_bound_dev_if)
+		return true;
+
+	return false;
+}
+
+void sock_def_readable(struct sock *sk);
+
+int sock_bindtoindex(struct sock *sk, int ifindex, bool lock_sk);
+void sock_set_timestamp(struct sock *sk, int optname, bool valbool);
+int sock_set_timestamping(struct sock *sk, int optname,
+			  struct so_timestamping timestamping);
+
+void sock_enable_timestamps(struct sock *sk);
+void sock_no_linger(struct sock *sk);
+void sock_set_keepalive(struct sock *sk);
+void sock_set_priority(struct sock *sk, u32 priority);
+void sock_set_rcvbuf(struct sock *sk, int val);
+void sock_set_mark(struct sock *sk, u32 val);
+void sock_set_reuseaddr(struct sock *sk);
+void sock_set_reuseport(struct sock *sk);
+void sock_set_sndtimeo(struct sock *sk, s64 secs);
+
+int sock_bind_add(struct sock *sk, struct sockaddr *addr, int addr_len);
+
+static inline bool sk_is_readable(struct sock *sk)
+{
+	if (sk->sk_prot->sock_is_readable)
+		return sk->sk_prot->sock_is_readable(sk);
+	return false;
+}
+#endif	/* _SOCK_H */
diff --git a/include/uapi/linux/_xattr.h b/include/uapi/linux/_xattr.h
new file mode 100644
index 000000000..dcd30b009
--- /dev/null
+++ b/include/uapi/linux/_xattr.h
@@ -0,0 +1,88 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+  File: linux/xattr.h
+
+  Extended attributes handling.
+
+  Copyright (C) 2001 by Andreas Gruenbacher <a.gruenbacher@computer.org>
+  Copyright (c) 2001-2002 Silicon Graphics, Inc.  All Rights Reserved.
+  Copyright (c) 2004 Red Hat, Inc., James Morris <jmorris@redhat.com>
+  Copyright (c) 2020 Jan (janneke) Nieuwenhuizen <janneke@gnu.org>
+*/
+
+#include <linux/libc-compat.h>
+
+#ifndef _UAPI_LINUX_XATTR_H
+#define _UAPI_LINUX_XATTR_H
+
+#if __UAPI_DEF_XATTR
+#define __USE_KERNEL_XATTR_DEFS
+
+#define XATTR_CREATE	0x1	/* set value, fail if attr already exists */
+#define XATTR_REPLACE	0x2	/* set value, fail if attr does not exist */
+#endif
+
+/* Namespaces */
+#define XATTR_OS2_PREFIX "os2."
+#define XATTR_OS2_PREFIX_LEN (sizeof(XATTR_OS2_PREFIX) - 1)
+
+#define XATTR_MAC_OSX_PREFIX "osx."
+#define XATTR_MAC_OSX_PREFIX_LEN (sizeof(XATTR_MAC_OSX_PREFIX) - 1)
+
+#define XATTR_BTRFS_PREFIX "btrfs."
+#define XATTR_BTRFS_PREFIX_LEN (sizeof(XATTR_BTRFS_PREFIX) - 1)
+
+#define XATTR_HURD_PREFIX "gnu."
+#define XATTR_HURD_PREFIX_LEN (sizeof(XATTR_HURD_PREFIX) - 1)
+
+#define XATTR_SECURITY_PREFIX	"security."
+#define XATTR_SECURITY_PREFIX_LEN (sizeof(XATTR_SECURITY_PREFIX) - 1)
+
+#define XATTR_SYSTEM_PREFIX "system."
+#define XATTR_SYSTEM_PREFIX_LEN (sizeof(XATTR_SYSTEM_PREFIX) - 1)
+
+#define XATTR_TRUSTED_PREFIX "trusted."
+#define XATTR_TRUSTED_PREFIX_LEN (sizeof(XATTR_TRUSTED_PREFIX) - 1)
+
+#define XATTR_USER_PREFIX "user."
+#define XATTR_USER_PREFIX_LEN (sizeof(XATTR_USER_PREFIX) - 1)
+
+/* Security namespace */
+#define XATTR_EVM_SUFFIX "evm"
+#define XATTR_NAME_EVM XATTR_SECURITY_PREFIX XATTR_EVM_SUFFIX
+
+#define XATTR_IMA_SUFFIX "ima"
+#define XATTR_NAME_IMA XATTR_SECURITY_PREFIX XATTR_IMA_SUFFIX
+
+#define XATTR_SELINUX_SUFFIX "selinux"
+#define XATTR_NAME_SELINUX XATTR_SECURITY_PREFIX XATTR_SELINUX_SUFFIX
+
+#define XATTR_PROVENANCE_SUFFIX "provenance"
+#define XATTR_NAME_PROVENANCE XATTR_SECURITY_PREFIX XATTR_PROVENANCE_SUFFIX
+
+#define XATTR_SMACK_SUFFIX "SMACK64"
+#define XATTR_SMACK_IPIN "SMACK64IPIN"
+#define XATTR_SMACK_IPOUT "SMACK64IPOUT"
+#define XATTR_SMACK_EXEC "SMACK64EXEC"
+#define XATTR_SMACK_TRANSMUTE "SMACK64TRANSMUTE"
+#define XATTR_SMACK_MMAP "SMACK64MMAP"
+#define XATTR_NAME_SMACK XATTR_SECURITY_PREFIX XATTR_SMACK_SUFFIX
+#define XATTR_NAME_SMACKIPIN	XATTR_SECURITY_PREFIX XATTR_SMACK_IPIN
+#define XATTR_NAME_SMACKIPOUT	XATTR_SECURITY_PREFIX XATTR_SMACK_IPOUT
+#define XATTR_NAME_SMACKEXEC	XATTR_SECURITY_PREFIX XATTR_SMACK_EXEC
+#define XATTR_NAME_SMACKTRANSMUTE XATTR_SECURITY_PREFIX XATTR_SMACK_TRANSMUTE
+#define XATTR_NAME_SMACKMMAP XATTR_SECURITY_PREFIX XATTR_SMACK_MMAP
+
+#define XATTR_APPARMOR_SUFFIX "apparmor"
+#define XATTR_NAME_APPARMOR XATTR_SECURITY_PREFIX XATTR_APPARMOR_SUFFIX
+
+#define XATTR_CAPS_SUFFIX "capability"
+#define XATTR_NAME_CAPS XATTR_SECURITY_PREFIX XATTR_CAPS_SUFFIX
+
+#define XATTR_POSIX_ACL_ACCESS  "posix_acl_access"
+#define XATTR_NAME_POSIX_ACL_ACCESS XATTR_SYSTEM_PREFIX XATTR_POSIX_ACL_ACCESS
+#define XATTR_POSIX_ACL_DEFAULT  "posix_acl_default"
+#define XATTR_NAME_POSIX_ACL_DEFAULT XATTR_SYSTEM_PREFIX XATTR_POSIX_ACL_DEFAULT
+
+
+#endif /* _UAPI_LINUX_XATTR_H */
diff --git a/include/uapi/linux/provenance.h b/include/uapi/linux/provenance.h
new file mode 100644
index 000000000..eef4bdf6f
--- /dev/null
+++ b/include/uapi/linux/provenance.h
@@ -0,0 +1,351 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2020 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+#ifndef _UAPI_LINUX_PROVENANCE_H
+#define _UAPI_LINUX_PROVENANCE_H
+
+#ifdef __KERNEL__
+#include <linux/socket.h>
+#include <linux/mutex.h>
+#endif
+#ifndef __KERNEL__
+#include <stdint.h>
+#include <stdbool.h>
+#include <stdio.h>
+#include <string.h>
+#include <sys/socket.h>
+#endif
+#include <linux/limits.h>
+#include <linux/utsname.h>
+
+#define xstr(s)         str(s)
+#define str(s)          # s
+
+#define CAMFLOW_VERSION_MAJOR           0
+#define CAMFLOW_VERSION_MINOR           8
+#define CAMFLOW_VERSION_PATCH           0
+#define CAMFLOW_VERSION_STR             "v"xstr (CAMFLOW_VERSION_MAJOR)	\
+	"."xstr (CAMFLOW_VERSION_MINOR)					\
+	"."xstr (CAMFLOW_VERSION_PATCH)					\
+
+#define CAMFLOW_COMMIT "600569346e121e0fd06cfa7a8fa06c5d4217abab"
+
+#define PROVENANCE_HASH                 "sha256"
+
+#define FLOW_ALLOWED                            0
+#define FLOW_DISALLOWED                         1
+
+#define prov_id_buffer(prov)                    ((prov)->node_info.identifier.buffer)
+#define node_identifier(node)                   ((node)->node_info.identifier.node_id)
+#define relation_identifier(relation)           ((relation)->relation_info.identifier.relation_id)
+#define get_prov_identifier(node)               ((node)->node_info.identifier)
+#define packet_identifier(packet)               ((packet)->pck_info.identifier.packet_id)
+#define packet_info(packet)                                                                                     ((packet)->pck_info)
+#define node_secid(node)                        ((node)->node_info.secid)
+#define node_uid(node)                          ((node)->node_info.uid)
+#define node_gid(node)                          ((node)->node_info.gid)
+#define node_previous_id(node)                  ((node)->node_info.previous_id)
+#define node_previous_version(node)             ((node)->node_info.previous_version)
+#define node_previous_type(node)                ((node)->node_info.previous_type)
+#define node_kernel_version(node)               ((node)->node_info.k_version)
+
+#define prov_flag(prov)                         ((prov)->msg_info.internal_flag)
+#define prov_taint(prov)                        ((prov)->msg_info.taint)
+#define prov_jiffies(prov)                      ((prov)->msg_info.jiffies)
+
+#define provenance_taint_merge(dest, src) dest = (dest) | (src)
+
+struct node_identifier {
+	uint64_t type;
+	uint64_t id;
+	uint32_t boot_id;
+	uint32_t machine_id;
+	uint32_t version;
+};
+
+struct relation_identifier {
+	uint64_t type;
+	uint64_t id;
+	uint32_t boot_id;
+	uint32_t machine_id;
+};
+
+struct packet_identifier {
+	uint64_t type;
+	uint16_t id;
+	uint32_t snd_ip;
+	uint32_t rcv_ip;
+	uint16_t snd_port;
+	uint16_t rcv_port;
+	uint8_t protocol;
+	uint32_t seq;
+};
+
+#define PROV_IDENTIFIER_BUFFER_LENGTH    sizeof(struct node_identifier)
+
+union prov_identifier {
+	struct node_identifier node_id;
+	struct relation_identifier relation_id;
+	struct packet_identifier packet_id;
+	uint8_t buffer[PROV_IDENTIFIER_BUFFER_LENGTH];
+};
+
+#define prov_set_flag(node, nbit)               (prov_flag(node) |= 1 << nbit)
+#define prov_clear_flag(node, nbit)             (prov_flag(node) &= ~(1 << nbit))
+#define prov_check_flag(node, nbit)             ((prov_flag(node) & (1 << nbit)) == (1 << nbit))
+
+#define TRACKED_BIT             0
+#define set_tracked(node)                       prov_set_flag(node, TRACKED_BIT)
+#define clear_tracked(node)                     prov_clear_flag(node, TRACKED_BIT)
+#define provenance_is_tracked(node)             prov_check_flag(node, TRACKED_BIT)
+
+#define OPAQUE_BIT              1
+#define set_opaque(node)                        prov_set_flag(node, OPAQUE_BIT)
+#define clear_opaque(node)                      prov_clear_flag(node, OPAQUE_BIT)
+#define provenance_is_opaque(node)              prov_check_flag(node, OPAQUE_BIT)
+
+#define PROPAGATE_BIT           2
+#define set_propagate(node)                     prov_set_flag(node, PROPAGATE_BIT)
+#define clear_propagate(node)                   prov_clear_flag(node, PROPAGATE_BIT)
+#define provenance_does_propagate(node)         prov_check_flag(node, PROPAGATE_BIT)
+
+#define RECORD_PACKET_BIT       3
+#define set_record_packet(node)                 prov_set_flag(node, RECORD_PACKET_BIT)
+#define clear_record_packet(node)               prov_clear_flag(node, RECORD_PACKET_BIT)
+#define should_record_packet_content(node)      prov_check_flag(node, RECORD_PACKET_BIT)
+
+#define OUTGOING_BIT            4
+#define set_has_outgoing(node)                  prov_set_flag(node, OUTGOING_BIT)
+#define clear_has_outgoing(node)                prov_clear_flag(node, OUTGOING_BIT)
+#define provenance_has_outgoing(node)           prov_check_flag(node, OUTGOING_BIT)
+
+#define INITIALIZED_BIT         5
+#define set_initialized(node)                   prov_set_flag(node, INITIALIZED_BIT)
+#define clear_initialized(node)                 prov_clear_flag(node, INITIALIZED_BIT)
+#define provenance_is_initialized(node)         prov_check_flag(node, INITIALIZED_BIT)
+
+#define SAVED_BIT               6
+#define set_saved(node)                         prov_set_flag(node, SAVED_BIT)
+#define clear_saved(node)                       prov_clear_flag(node, SAVED_BIT)
+#define provenance_is_saved(node)               prov_check_flag(node, SAVED_BIT)
+
+
+
+#define basic_elements          union prov_identifier identifier; uint32_t epoch; uint32_t nepoch; uint32_t internal_flag; uint64_t jiffies; uint64_t taint
+#define shared_node_elements    uint64_t previous_id; uint32_t previous_version; uint64_t previous_type; uint32_t k_version; uint32_t secid; uint32_t uid; uint32_t gid; void *var_ptr
+
+struct msg_struct {
+	basic_elements;
+};
+
+#define FILE_INFO_SET           0x01
+
+struct relation_struct {
+	basic_elements;
+	uint8_t allowed;
+	union prov_identifier snd;
+	union prov_identifier rcv;
+	uint8_t set;
+	int64_t offset;
+	uint64_t flags;
+	uint64_t task_id;
+};
+
+struct node_struct {
+	basic_elements;
+	shared_node_elements;
+};
+
+struct proc_prov_struct {
+	basic_elements;
+	shared_node_elements;
+	uint32_t tgid;
+};
+
+struct task_prov_struct {
+	basic_elements;
+	shared_node_elements;
+	uint32_t pid;
+	uint32_t vpid;
+	/* usec */
+	uint64_t utime;
+	uint64_t stime;
+	/* KB */
+	uint64_t vm;
+	uint64_t rss;
+	uint64_t hw_vm;
+	uint64_t hw_rss;
+	uint64_t rbytes;
+	uint64_t wbytes;
+	uint64_t cancel_wbytes;
+	/* namespaces */
+	uint32_t utsns;
+	uint32_t ipcns;
+	uint32_t mntns;
+	uint32_t pidns;
+	uint32_t netns;
+	uint32_t cgroupns;
+	union long_prov_elt *disc;
+};
+
+#define PROV_SBUUID_LEN 16
+struct inode_prov_struct {
+	basic_elements;
+	shared_node_elements;
+	uint64_t ino;
+	uint16_t mode;
+	uint8_t sb_uuid[PROV_SBUUID_LEN];
+};
+
+struct iattr_prov_struct {
+	basic_elements;
+	shared_node_elements;
+	uint32_t valid;
+	uint16_t mode;
+	int64_t size;
+	int64_t atime;
+	int64_t ctime;
+	int64_t mtime;
+};
+
+struct msg_msg_struct {
+	basic_elements;
+	shared_node_elements;
+	long type;
+};
+
+struct shm_struct {
+	basic_elements;
+	shared_node_elements;
+	uint16_t mode;
+};
+
+struct sb_struct {
+	basic_elements;
+	shared_node_elements;
+	uint8_t uuid[16];
+};
+
+struct pck_struct {
+	basic_elements;
+	shared_node_elements;
+	uint16_t len;
+};
+
+union prov_elt {
+	struct msg_struct msg_info;
+	struct relation_struct relation_info;
+	struct node_struct node_info;
+	struct proc_prov_struct proc_info;
+	struct task_prov_struct task_info;
+	struct inode_prov_struct inode_info;
+	struct msg_msg_struct msg_msg_info;
+	struct shm_struct shm_info;
+	struct sb_struct sb_info;
+	struct pck_struct pck_info;
+	struct iattr_prov_struct iattr_info;
+};
+
+struct str_struct {
+	basic_elements;
+	shared_node_elements;
+	char str[PATH_MAX];
+	size_t length;
+};
+
+struct file_name_struct {
+	basic_elements;
+	shared_node_elements;
+	char name[PATH_MAX];
+	size_t length;
+};
+
+struct address_struct {
+	basic_elements;
+	shared_node_elements;
+	size_t length;
+	struct sockaddr_storage addr;
+};
+
+#define PROV_TRUNCATED    1
+struct pckcnt_struct {
+	basic_elements;
+	shared_node_elements;
+	uint8_t content[PATH_MAX];
+	size_t length;
+	uint8_t truncated;
+};
+
+struct arg_struct {
+	basic_elements;
+	shared_node_elements;
+	char value[PATH_MAX];
+	size_t length;
+	uint8_t truncated;
+};
+
+struct disc_node_struct {
+	basic_elements;
+	shared_node_elements;
+	size_t length;
+	char content[PATH_MAX];
+	union prov_identifier parent;
+};
+
+#define PROV_XATTR_NAME_SIZE            256
+#define PROV_XATTR_VALUE_SIZE           (PATH_MAX - PROV_XATTR_NAME_SIZE)
+struct xattr_prov_struct {
+	basic_elements;
+	shared_node_elements;
+	char name[PROV_XATTR_NAME_SIZE];
+	uint8_t value[PROV_XATTR_VALUE_SIZE];
+	size_t size;
+};
+
+#define PROV_COMMIT_MAX_LENGTH 256
+struct machine_struct {
+	basic_elements;
+	shared_node_elements;
+	uint8_t cam_major;
+	uint8_t cam_minor;
+	uint8_t cam_patch;
+	struct new_utsname utsname;
+	char commit[PROV_COMMIT_MAX_LENGTH];
+};
+
+union long_prov_elt {
+	struct msg_struct msg_info;
+	struct relation_struct relation_info;
+	struct node_struct node_info;
+	struct proc_prov_struct proc_info;
+	struct task_prov_struct task_info;
+	struct inode_prov_struct inode_info;
+	struct msg_msg_struct msg_msg_info;
+	struct shm_struct shm_info;
+	struct sb_struct sb_info;
+	struct pck_struct pck_info;
+	struct iattr_prov_struct iattr_info;
+	struct str_struct str_info;
+	struct file_name_struct file_name_info;
+	struct arg_struct arg_info;
+	struct address_struct address_info;
+	struct pckcnt_struct pckcnt_info;
+	struct disc_node_struct disc_node_info;
+	struct xattr_prov_struct xattr_info;
+	struct machine_struct machine_info;
+};
+
+typedef union long_prov_elt prov_entry_t;
+#endif
diff --git a/include/uapi/linux/provenance_fs.h b/include/uapi/linux/provenance_fs.h
new file mode 100644
index 000000000..8fb0f4e9a
--- /dev/null
+++ b/include/uapi/linux/provenance_fs.h
@@ -0,0 +1,129 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2020 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+#ifndef _UAPI_LINUX_PROVENANCE_FS_H
+#define _UAPI_LINUX_PROVENANCE_FS_H
+
+#include <linux/provenance.h>
+
+ #define PROV_SEC_PATH                           "/sys/kernel/security/provenance/"
+ #define PROV_ENABLE_FILE                        "/sys/kernel/security/provenance/enable"
+ #define PROV_ALL_FILE                           "/sys/kernel/security/provenance/all"
+ #define PROV_WRITTEN_FILE                       "/sys/kernel/security/provenance/written"
+ #define PROV_COMPRESS_NODE_FILE                 "/sys/kernel/security/provenance/compress_node"
+ #define PROV_COMPRESS_EDGE_FILE                 "/sys/kernel/security/provenance/compress_edge"
+ #define PROV_NODE_FILE                          "/sys/kernel/security/provenance/node"
+ #define PROV_RELATION_FILE                      "/sys/kernel/security/provenance/relation"
+ #define PROV_SELF_FILE                          "/sys/kernel/security/provenance/self"
+ #define PROV_MACHINE_ID_FILE                    "/sys/kernel/security/provenance/machine_id"
+ #define PROV_BOOT_ID_FILE                       "/sys/kernel/security/provenance/boot_id"
+ #define PROV_NODE_FILTER_FILE                   "/sys/kernel/security/provenance/node_filter"
+ #define PROV_DERIVED_FILTER_FILE                "/sys/kernel/security/provenance/derived_filter"
+ #define PROV_GENERATED_FILTER_FILE              "/sys/kernel/security/provenance/generated_filter"
+ #define PROV_USED_FILTER_FILE                   "/sys/kernel/security/provenance/used_filter"
+ #define PROV_INFORMED_FILTER_FILE               "/sys/kernel/security/provenance/informed_filter"
+ #define PROV_PROPAGATE_NODE_FILTER_FILE         "/sys/kernel/security/provenance/propagate_node_filter"
+ #define PROV_PROPAGATE_DERIVED_FILTER_FILE      "/sys/kernel/security/provenance/propagate_derived_filter"
+ #define PROV_PROPAGATE_GENERATED_FILTER_FILE    "/sys/kernel/security/provenance/propagate_generated_filter"
+ #define PROV_PROPAGATE_USED_FILTER_FILE         "/sys/kernel/security/provenance/propagate_used_filter"
+ #define PROV_PROPAGATE_INFORMED_FILTER_FILE     "/sys/kernel/security/provenance/propagate_informed_filter"
+ #define PROV_FLUSH_FILE                         "/sys/kernel/security/provenance/flush"
+ #define PROV_PROCESS_FILE                       "/sys/kernel/security/provenance/process"
+ #define PROV_IPV4_INGRESS_FILE                  "/sys/kernel/security/provenance/ipv4_ingress"
+ #define PROV_IPV4_EGRESS_FILE                   "/sys/kernel/security/provenance/ipv4_egress"
+ #define PROV_SECCTX                             "/sys/kernel/security/provenance/secctx"
+ #define PROV_SECCTX_FILTER                      "/sys/kernel/security/provenance/secctx_filter"
+ #define PROV_NS_FILTER                          "/sys/kernel/security/provenance/ns"
+ #define PROV_LOG_FILE                           "/sys/kernel/security/provenance/log"
+ #define PROV_LOGP_FILE                          "/sys/kernel/security/provenance/logp"
+ #define PROV_POLICY_HASH_FILE                   "/sys/kernel/security/provenance/policy_hash"
+ #define PROV_UID_FILTER                         "/sys/kernel/security/provenance/uid"
+ #define PROV_GID_FILTER                         "/sys/kernel/security/provenance/gid"
+ #define PROV_TYPE                               "/sys/kernel/security/provenance/type"
+ #define PROV_VERSION                            "/sys/kernel/security/provenance/version"
+ #define PROV_COMMIT                             "/sys/kernel/security/provenance/commit"
+ #define PROV_DUPLICATE_FILE                     "/sys/kernel/security/provenance/duplicate"
+ #define PROV_EPOCH_FILE                         "/sys/kernel/security/provenance/epoch"
+ #define PROV_DROPPED_FILE                       "/sys/kernel/security/provenance/dropped"
+
+ #define PROV_RELAY_NAME                         "/sys/kernel/debug/provenance"
+ #define PROV_LONG_RELAY_NAME                    "/sys/kernel/debug/long_provenance"
+ #define PROV_CHANNEL_ROOT                       "/sys/kernel/debug/"
+
+struct prov_filter {
+	uint64_t filter;
+	uint64_t mask;
+	uint8_t add;
+};
+
+ #define PROV_SET_TRACKED        0x01
+ #define PROV_SET_OPAQUE         0x02
+ #define PROV_SET_PROPAGATE      0x04
+ #define PROV_SET_TAINT          0x08
+ #define PROV_SET_DELETE         0x10
+ #define PROV_SET_RECORD         0x20
+
+struct prov_process_config {
+	union prov_elt prov;
+	uint8_t op;
+	uint32_t vpid;
+};
+
+struct prov_ipv4_filter {
+	uint32_t ip;
+	uint32_t mask;
+	uint16_t port;
+	uint8_t op;
+	uint64_t taint;
+};
+
+struct secinfo {
+	uint32_t secid;
+	char secctx[PATH_MAX];
+	uint32_t len;
+	uint8_t op;
+	uint64_t taint;
+};
+
+struct userinfo {
+	uint32_t uid;
+	uint8_t op;
+	uint64_t taint;
+};
+
+struct groupinfo {
+	uint32_t gid;
+	uint8_t op;
+	uint64_t taint;
+};
+
+ #define IGNORE_NS    0
+
+struct nsinfo {
+	uint32_t utsns;
+	uint32_t ipcns;
+	uint32_t mntns;
+	uint32_t pidns;
+	uint32_t netns;
+	uint32_t cgroupns;
+	uint8_t op;
+	uint64_t taint;
+};
+
+struct dropped {
+	uint64_t s;
+};
+
+#endif
diff --git a/include/uapi/linux/provenance_types.h b/include/uapi/linux/provenance_types.h
new file mode 100644
index 000000000..b81b320a6
--- /dev/null
+++ b/include/uapi/linux/provenance_types.h
@@ -0,0 +1,284 @@
+/* SPDX-License-Identifier: GPL-2.0 WITH Linux-syscall-note */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2020 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+#ifndef _UAPI_LINUX_PROVENANCE_TYPES_H
+#define _UAPI_LINUX_PROVENANCE_TYPES_H
+
+#ifndef __KERNEL__
+#include <stdint.h>
+#include <stdbool.h>
+#endif
+
+
+#define TYPE_MASK                               0xFFFF000000000000UL
+#define SUBTYPE_MASK                            0x0000FFFFFFFFFFFFUL
+
+#define W3C_TYPE(type)          (type & TYPE_MASK)
+#define SUBTYPE(type)           (type & SUBTYPE_MASK)
+
+/* W3C PROV TYPES */
+#define DM_RELATION                             0x8000000000000000UL
+#define DM_ACTIVITY                             0x4000000000000000UL
+#define DM_ENTITY                               0x2000000000000000UL
+#define DM_AGENT                                0x1000000000000000UL
+/* NODE IS LONG*/
+#define ND_LONG                                                   0x0400000000000000UL
+/* ALLOWED/DISALLOWED */
+#define RL_ALLOWED                              0x0200000000000000UL
+#define RL_DISALLOWED                           0x0100000000000000UL
+/* SUBTYPES */
+/* RELATIONS W3C TYPE*/
+#define RL_DERIVED                              (DM_RELATION | 0x0080000000000000ULL)
+#define RL_GENERATED                            (DM_RELATION | 0x0040000000000000ULL)
+#define RL_USED                                 (DM_RELATION | 0x0020000000000000ULL)
+#define RL_INFORMED                             (DM_RELATION | 0x0010000000000000ULL)
+#define RL_INFLUENCED                           (DM_RELATION | 0x0008000000000000ULL)
+#define RL_ASSOCIATED                           (DM_RELATION | 0x0004000000000000ULL)
+
+/* DERIVED SUBTYPES */
+#define RL_NAMED                                (RL_DERIVED   | (0x0000000000000001ULL))
+#define RL_VERSION                              (RL_DERIVED   | (0x0000000000000001ULL << 1))
+#define RL_SND_PACKET                           (RL_DERIVED   | (0x0000000000000001ULL << 2))
+#define RL_SND_UNIX                             (RL_DERIVED   | (0x0000000000000001ULL << 3))
+#define RL_RCV_PACKET                           (RL_DERIVED   | (0x0000000000000001ULL << 4))
+#define RL_RCV_UNIX                             (RL_DERIVED   | (0x0000000000000001ULL << 5))
+#define RL_FREED                                (RL_DERIVED   | (0x0000000000000001ULL << 6))
+#define RL_SETATTR_INODE                        (RL_DERIVED   | (0x0000000000000001ULL << 7))
+#define RL_ACCEPT_SOCKET                        (RL_DERIVED   | (0x0000000000000001ULL << 8))
+#define RL_GETXATTR_INODE                       (RL_DERIVED   | (0x0000000000000001ULL << 9))
+#define RL_SETXATTR_INODE                       (RL_DERIVED   | (0x0000000000000001ULL << 10))
+#define RL_RMVXATTR_INODE                       (RL_DERIVED   | (0x0000000000000001ULL << 11))
+#define RL_EXEC                                 (RL_DERIVED   | (0x0000000000000001ULL << 12))
+#define RL_TERMINATE_PROC                       (RL_DERIVED   | (0x0000000000000001ULL << 13))
+#define RL_ARG                                  (RL_DERIVED   | (0x0000000000000001ULL << 14))
+#define RL_ENV                                  (RL_DERIVED   | (0x0000000000000001ULL << 15))
+#define RL_SH_READ                              (RL_DERIVED   | (0x0000000000000001ULL << 16))
+#define RL_SH_WRITE                             (RL_DERIVED   | (0x0000000000000001ULL << 17))
+#define RL_PCK_CNT                              (RL_DERIVED   | (0x0000000000000001ULL << 18))
+#define RL_ADDRESSED                            (RL_DERIVED   | (0x0000000000000001ULL << 19))
+#define RL_DERIVED_DISC                         (RL_DERIVED   | (0x0000000000000001ULL << 20))
+/* no more than 51!!!! */
+
+/* GENERATED SUBTYPES */
+#define RL_CLONE_MEM                            (RL_GENERATED | (0x0000000000000001ULL))
+#define RL_MSG_CREATE                           (RL_GENERATED | (0x0000000000000001ULL << 1))
+#define RL_SOCKET_CREATE                        (RL_GENERATED | (0x0000000000000001ULL << 2))
+#define RL_SOCKET_PAIR_CREATE                   (RL_GENERATED | (0x0000000000000001ULL << 3))
+#define RL_INODE_CREATE                         (RL_GENERATED | (0x0000000000000001ULL << 4))
+#define RL_WRITE                                (RL_GENERATED | (0x0000000000000001ULL << 5))
+#define RL_WRITE_IOCTL                          (RL_GENERATED | (0x0000000000000001ULL << 6))
+#define RL_PROC_WRITE                           (RL_GENERATED | (0x0000000000000001ULL << 7))
+#define RL_CONNECT                              (RL_GENERATED | (0x0000000000000001ULL << 8))
+#define RL_CONNECT_UNIX_STREAM                  (RL_GENERATED | (0x0000000000000001ULL << 9))
+#define RL_LISTEN                               (RL_GENERATED | (0x0000000000000001ULL << 10))
+#define RL_BIND                                 (RL_GENERATED | (0x0000000000000001ULL << 11))
+#define RL_SND                                  (RL_GENERATED | (0x0000000000000001ULL << 12))
+#define RL_SND_MSG                              (RL_GENERATED | (0x0000000000000001ULL << 13))
+#define RL_SND_MSG_Q                            (RL_GENERATED | (0x0000000000000001ULL << 14))
+#define RL_LINK                                 (RL_GENERATED | (0x0000000000000001ULL << 15))
+#define RL_RENAME                               (RL_GENERATED | (0x0000000000000001ULL << 16))
+#define RL_UNLINK                               (RL_GENERATED | (0x0000000000000001ULL << 17))
+#define RL_SYMLINK                              (RL_GENERATED | (0x0000000000000001ULL << 18))
+#define RL_SETATTR                              (RL_GENERATED | (0x0000000000000001ULL << 19))
+#define RL_SETXATTR                             (RL_GENERATED | (0x0000000000000001ULL << 20))
+#define RL_RMVXATTR                             (RL_GENERATED | (0x0000000000000001ULL << 21))
+#define RL_SHMDT                                (RL_GENERATED | (0x0000000000000001ULL << 22))
+#define RL_SETUID                               (RL_GENERATED | (0x0000000000000001ULL << 23))
+#define RL_SETGID                               (RL_GENERATED | (0x0000000000000001ULL << 24))
+#define RL_SH_ATTACH                            (RL_GENERATED | (0x0000000000000001ULL << 25))
+#define RL_SH_CREATE                            (RL_GENERATED | (0x0000000000000001ULL << 26))
+#define RL_FILE_LOCK                            (RL_GENERATED | (0x0000000000000001ULL << 27))
+#define RL_MUNMAP                               (RL_GENERATED | (0x0000000000000001ULL << 28))
+#define RL_SPLICE_OUT                           (RL_GENERATED | (0x0000000000000001ULL << 29))
+#define RL_EXEC_TASK                            (RL_GENERATED | (0x0000000000000001ULL << 30))
+#define RL_PTRACE_ATTACH                        (RL_GENERATED | (0x0000000000000001ULL << 31))
+#define RL_GENERATED_DISC                       (RL_GENERATED | (0x0000000000000001ULL << 32))
+/* no more than 51!!!! */
+
+/* USED SUBTYPES */
+#define RL_READ                                 (RL_USED        | (0x0000000000000001ULL))
+#define RL_READ_IOCTL                           (RL_USED        | (0x0000000000000001ULL << 1))
+#define RL_PROC_READ                            (RL_USED        | (0x0000000000000001ULL << 2))
+#define RL_ACCEPT                               (RL_USED        | (0x0000000000000001ULL << 3))
+#define RL_RCV                                  (RL_USED        | (0x0000000000000001ULL << 4))
+#define RL_RCV_MSG                              (RL_USED        | (0x0000000000000001ULL << 5))
+#define RL_RCV_MSG_Q                            (RL_USED        | (0x0000000000000001ULL << 6))
+#define RL_OPEN                                 (RL_USED        | (0x0000000000000001ULL << 7))
+#define RL_FILE_RCV                             (RL_USED        | (0x0000000000000001ULL << 8))
+#define RL_FILE_SIGIO                           (RL_USED        | (0x0000000000000001ULL << 9))
+#define RL_SEARCH                               (RL_USED        | (0x0000000000000001ULL << 10))
+#define RL_GETATTR                              (RL_USED        | (0x0000000000000001ULL << 11))
+#define RL_READ_LINK                            (RL_USED        | (0x0000000000000001ULL << 12))
+#define RL_GETXATTR                             (RL_USED        | (0x0000000000000001ULL << 13))
+#define RL_LSTXATTR                             (RL_USED        | (0x0000000000000001ULL << 14))
+#define RL_LOG                                  (RL_USED        | (0x0000000000000001ULL << 15))
+#define RL_PERM                                 (RL_USED        | (0x0000000000000001ULL << 16))
+#define RL_GETGID                               (RL_USED        | (0x0000000000000001ULL << 17))
+#define RL_SPLICE_IN                            (RL_USED        | (0x0000000000000001ULL << 18))
+#define RL_MMAP                                 (RL_USED        | (0x0000000000000001ULL << 19))
+#define RL_MMAP_PRIVATE                                         (RL_USED        | (0x0000000000000001ULL << 20))
+#define RL_LOAD_FILE                            (RL_USED        | (0x0000000000000001ULL << 21))
+#define RL_PTRACE_READ                          (RL_USED        | (0x0000000000000001ULL << 22))
+#define RL_USED_DISC                            (RL_USED        | (0x0000000000000001ULL << 23))
+/* no more than 51!!!! */
+
+/* INFORMED SUBTYPES */
+#define RL_CLONE                                (RL_INFORMED  | (0x0000000000000001ULL))
+#define RL_VERSION_TASK                         (RL_INFORMED  | (0x0000000000000001ULL << 1))
+#define RL_TERMINATE_TASK                       (RL_INFORMED  | (0x0000000000000001ULL << 2))
+#define RL_PTRACE_ATTACH_TASK                   (RL_INFORMED  | (0x0000000000000001ULL << 3))
+#define RL_PTRACE_READ_TASK                     (RL_INFORMED  | (0x0000000000000001ULL << 4))
+#define RL_PTRACE_TRACEME                       (RL_INFORMED  | (0x0000000000000001ULL << 5))
+#define RL_INFORMED_DISC                        (RL_INFORMED  | (0x0000000000000001ULL << 6))
+/* no more than 51!!!! */
+
+/* INFLUENCED  SUBTYPES */
+#define RL_LOAD_UNKNOWN                         (RL_INFLUENCED | (0x0000000000000001ULL))
+#define RL_LOAD_FIRMWARE                        (RL_INFLUENCED | (0x0000000000000001ULL << 1))
+#define RL_LOAD_MODULE                          (RL_INFLUENCED | (0x0000000000000001ULL << 2))
+#define RL_LOAD_KEXEC_IMAGE                     (RL_INFLUENCED | (0x0000000000000001ULL << 3))
+#define RL_LOAD_KEXEC_INITRAMFS                 (RL_INFLUENCED | (0x0000000000000001ULL << 4))
+#define RL_LOAD_POLICY                          (RL_INFLUENCED | (0x0000000000000001ULL << 5))
+#define RL_LOAD_CERTIFICATE                     (RL_INFLUENCED | (0x0000000000000001ULL << 6))
+#define RL_LOAD_UNDEFINED                       (RL_INFLUENCED | (0x0000000000000001ULL << 7))
+#define RL_INFLUENCED_DISC                      (RL_INFLUENCED | (0x0000000000000001ULL << 8))
+
+/* ASSOCIATED  SUBTYPES */
+#define RL_RAN_ON                               (RL_ASSOCIATED | (0x0000000000000001ULL))
+#define RL_ASSOCIATED_DISC                      (RL_ASSOCIATED | (0x0000000000000001ULL << 1))
+
+/* ACTIVITY SUBTYPES */
+#define ACT_TASK                                (DM_ACTIVITY  | 0x0000000000000001ULL)
+
+/* LONG NODE */
+/* DISCLOSED TYPE */
+#define ACT_DISC                                (DM_ACTIVITY | ND_LONG | (0x0000000000000001ULL << 1))
+
+/* AGENT SUBTYPES */
+#define AGT_USR                                 (DM_AGENT       | (0x0000000000000001ULL << 2))
+#define AGT_GRP                                 (DM_AGENT       | (0x0000000000000001ULL << 3))
+
+/* LONG NODE */
+#define AGT_MACHINE                             (DM_AGENT | ND_LONG | (0x0000000000000001ULL << 4))
+/* DISCLOSED TYPE */
+#define AGT_DISC                                (DM_AGENT | ND_LONG | (0x0000000000000001ULL << 5))
+
+/* ENTITY SUBTYPES */
+#define ENT_INODE_UNKNOWN                       (DM_ENTITY    | (0x0000000000000001ULL << 6))
+#define ENT_INODE_LINK                          (DM_ENTITY    | (0x0000000000000001ULL << 7))
+#define ENT_INODE_FILE                          (DM_ENTITY    | (0x0000000000000001ULL << 8))
+#define ENT_INODE_DIRECTORY                     (DM_ENTITY    | (0x0000000000000001ULL << 9))
+#define ENT_INODE_CHAR                          (DM_ENTITY    | (0x0000000000000001ULL << 10))
+#define ENT_INODE_BLOCK                         (DM_ENTITY    | (0x0000000000000001ULL << 11))
+#define ENT_INODE_PIPE                          (DM_ENTITY    | (0x0000000000000001ULL << 12))
+#define ENT_INODE_SOCKET                        (DM_ENTITY    | (0x0000000000000001ULL << 13))
+#define ENT_MSG                                 (DM_ENTITY    | (0x0000000000000001ULL << 14))
+#define ENT_SHM                                 (DM_ENTITY    | (0x0000000000000001ULL << 15))
+#define ENT_SBLCK                               (DM_ENTITY    | (0x0000000000000001ULL << 16))
+#define ENT_PACKET                              (DM_ENTITY    | (0x0000000000000001ULL << 17))
+#define ENT_IATTR                               (DM_ENTITY    | (0x0000000000000001ULL << 18))
+#define ENT_PROC                                (DM_ENTITY    | (0x0000000000000001ULL << 19))
+
+/* LONG NODE */
+#define ENT_STR                                 (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 20))
+#define ENT_ADDR                                (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 21))
+#define ENT_PATH                                (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 22))
+#define ENT_XATTR                               (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 23))
+#define ENT_PCKCNT                              (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 24))
+#define ENT_ARG                                 (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 25))
+#define ENT_ENV                                 (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 26))
+/* DISCLOSED TYPE */
+#define ENT_DISC                                (DM_ENTITY | ND_LONG | (0x0000000000000001ULL << 27))
+
+#define prov_type(prov)                 ((prov)->node_info.identifier.node_id.type)
+#define node_type(node)                 prov_type(node)
+#define edge_type(edge)                 prov_type(edge)
+#define prov_is_relation(prov)          ((relation_identifier(prov).type & DM_RELATION) != 0)
+#define prov_is_node(prov)              ((node_identifier(prov).type & DM_RELATION) == 0)
+#define prov_is_packet(prov)            (node_type(prov) == ENT_PACKET)
+
+#define prov_is_type(val, type)         ((val & type) == type)
+#define prov_type_is_relation(val)      prov_is_type(val, DM_RELATION)
+#define prov_type_is_node(val)          (!prov_is_type(val, DM_RELATION))
+#define prov_type_is_long(val)          (prov_is_type(val, ND_LONG) && prov_type_is_node(val))
+#define prov_is_used(val)               prov_is_type(val, RL_USED)
+#define prov_is_informed(val)           prov_is_type(val, RL_INFORMED)
+#define prov_is_influenced(val)         prov_is_type(val, RL_INFLUENCED)
+#define prov_is_associated(val)         prov_is_type(val, RL_ASSOCIATED)
+#define prov_is_generated(val)          prov_is_type(val, RL_GENERATED)
+#define prov_is_derived(val)            prov_is_type(val, RL_DERIVED)
+
+#define prov_is_close(val)              (val == RL_TERMINATE_TASK    \
+					 || val == RL_TERMINATE_PROC \
+					 || val == RL_FREED)
+
+static inline bool prov_has_uidgid(uint64_t type)
+{
+	switch (type) {
+	case ENT_PROC:
+	case ENT_INODE_UNKNOWN:
+	case ENT_INODE_LINK:
+	case ENT_INODE_FILE:
+	case ENT_INODE_DIRECTORY:
+	case ENT_INODE_CHAR:
+	case ENT_INODE_BLOCK:
+	case ENT_INODE_PIPE:
+	case ENT_INODE_SOCKET:
+		return true;
+	default: return false;
+	}
+}
+
+static inline bool prov_is_inode(uint64_t type)
+{
+	switch (type) {
+	case ENT_INODE_UNKNOWN:
+	case ENT_INODE_LINK:
+	case ENT_INODE_FILE:
+	case ENT_INODE_DIRECTORY:
+	case ENT_INODE_CHAR:
+	case ENT_INODE_BLOCK:
+	case ENT_INODE_PIPE:
+	case ENT_INODE_SOCKET:
+		return true;
+	default: return false;
+	}
+}
+
+static inline bool prov_has_secid(uint64_t type)
+{
+	switch (type) {
+	case ENT_PROC:
+	case ENT_INODE_UNKNOWN:
+	case ENT_INODE_LINK:
+	case ENT_INODE_FILE:
+	case ENT_INODE_DIRECTORY:
+	case ENT_INODE_CHAR:
+	case ENT_INODE_BLOCK:
+	case ENT_INODE_PIPE:
+	case ENT_INODE_SOCKET:
+		return true;
+	default: return false;
+	}
+}
+
+#define PROV_TYPE_STR_MAX_LEN 256
+struct prov_type {
+	uint64_t id;
+	char str[PROV_TYPE_STR_MAX_LEN];
+	uint8_t is_relation;
+};
+
+#endif /* _UAPI_LINUX_PROVENANCE_TYPES_H */
diff --git a/security/Kconfig b/security/Kconfig
index 462b851d4..fe6c0395f 100644
--- a/security/Kconfig
+++ b/security/Kconfig
@@ -233,14 +233,6 @@ config STATIC_USERMODEHELPER_PATH
 	  If you wish for all usermode helper programs to be disabled,
 	  specify an empty string here (i.e. "").
 
-config SECURITY_FLOW_FRIENDLY
-	bool "Security hooks for information flow mechanisms."
-	default y
-	help
-		This option adds hooks to support information flow mechanisms. Some
-		information flow are not captured by LSM as it was designed for access
-		control.
-
 source "security/selinux/Kconfig"
 source "security/smack/Kconfig"
 source "security/tomoyo/Kconfig"
@@ -304,3 +296,4 @@ config LSM
 source "security/Kconfig.hardening"
 
 endmenu
+
diff --git a/security/_Kconfig b/security/_Kconfig
new file mode 100644
index 000000000..858b684d6
--- /dev/null
+++ b/security/_Kconfig
@@ -0,0 +1,307 @@
+# SPDX-License-Identifier: GPL-2.0-only
+#
+# Security configuration
+#
+
+menu "Security options"
+
+source "security/keys/Kconfig"
+
+config SECURITY_DMESG_RESTRICT
+	bool "Restrict unprivileged access to the kernel syslog"
+	default n
+	help
+	  This enforces restrictions on unprivileged users reading the kernel
+	  syslog via dmesg(8).
+
+	  If this option is not selected, no restrictions will be enforced
+	  unless the dmesg_restrict sysctl is explicitly set to (1).
+
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY
+	bool "Enable different security models"
+	depends on SYSFS
+	depends on MULTIUSER
+	help
+	  This allows you to choose different security modules to be
+	  configured into your kernel.
+
+	  If this option is not selected, the default Linux security
+	  model will be used.
+
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY_WRITABLE_HOOKS
+	depends on SECURITY
+	bool
+	default n
+
+config SECURITYFS
+	bool "Enable the securityfs filesystem"
+	help
+	  This will build the securityfs filesystem.  It is currently used by
+	  various security modules (AppArmor, IMA, SafeSetID, TOMOYO, TPM).
+
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY_NETWORK
+	bool "Socket and Networking Security Hooks"
+	depends on SECURITY
+	help
+	  This enables the socket and networking security hooks.
+	  If enabled, a security module can use these hooks to
+	  implement socket and networking access controls.
+	  If you are unsure how to answer this question, answer N.
+
+config PAGE_TABLE_ISOLATION
+	bool "Remove the kernel mapping in user mode"
+	default y
+	depends on (X86_64 || X86_PAE) && !UML
+	help
+	  This feature reduces the number of hardware side channels by
+	  ensuring that the majority of kernel addresses are not mapped
+	  into userspace.
+
+	  See Documentation/x86/pti.rst for more details.
+
+config SECURITY_INFINIBAND
+	bool "Infiniband Security Hooks"
+	depends on SECURITY && INFINIBAND
+	help
+	  This enables the Infiniband security hooks.
+	  If enabled, a security module can use these hooks to
+	  implement Infiniband access controls.
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY_NETWORK_XFRM
+	bool "XFRM (IPSec) Networking Security Hooks"
+	depends on XFRM && SECURITY_NETWORK
+	help
+	  This enables the XFRM (IPSec) networking security hooks.
+	  If enabled, a security module can use these hooks to
+	  implement per-packet access controls based on labels
+	  derived from IPSec policy.  Non-IPSec communications are
+	  designated as unlabelled, and only sockets authorized
+	  to communicate unlabelled data can send without using
+	  IPSec.
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY_PATH
+	bool "Security hooks for pathname based access control"
+	depends on SECURITY
+	help
+	  This enables the security hooks for pathname based access control.
+	  If enabled, a security module can use these hooks to
+	  implement pathname based access controls.
+	  If you are unsure how to answer this question, answer N.
+
+config INTEL_TXT
+	bool "Enable Intel(R) Trusted Execution Technology (Intel(R) TXT)"
+	depends on HAVE_INTEL_TXT
+	help
+	  This option enables support for booting the kernel with the
+	  Trusted Boot (tboot) module. This will utilize
+	  Intel(R) Trusted Execution Technology to perform a measured launch
+	  of the kernel. If the system does not support Intel(R) TXT, this
+	  will have no effect.
+
+	  Intel TXT will provide higher assurance of system configuration and
+	  initial state as well as data reset protection.  This is used to
+	  create a robust initial kernel measurement and verification, which
+	  helps to ensure that kernel security mechanisms are functioning
+	  correctly. This level of protection requires a root of trust outside
+	  of the kernel itself.
+
+	  Intel TXT also helps solve real end user concerns about having
+	  confidence that their hardware is running the VMM or kernel that
+	  it was configured with, especially since they may be responsible for
+	  providing such assurances to VMs and services running on it.
+
+	  See <https://www.intel.com/technology/security/> for more information
+	  about Intel(R) TXT.
+	  See <http://tboot.sourceforge.net> for more information about tboot.
+	  See Documentation/x86/intel_txt.rst for a description of how to enable
+	  Intel TXT support in a kernel boot.
+
+	  If you are unsure as to whether this is required, answer N.
+
+config LSM_MMAP_MIN_ADDR
+	int "Low address space for LSM to protect from user allocation"
+	depends on SECURITY && SECURITY_SELINUX
+	default 32768 if ARM || (ARM64 && COMPAT)
+	default 65536
+	help
+	  This is the portion of low virtual memory which should be protected
+	  from userspace allocation.  Keeping a user from writing to low pages
+	  can help reduce the impact of kernel NULL pointer bugs.
+
+	  For most ia64, ppc64 and x86 users with lots of address space
+	  a value of 65536 is reasonable and should cause no problems.
+	  On arm and other archs it should not be higher than 32768.
+	  Programs which use vm86 functionality or have some need to map
+	  this low address space will need the permission specific to the
+	  systems running LSM.
+
+config HAVE_HARDENED_USERCOPY_ALLOCATOR
+	bool
+	help
+	  The heap allocator implements __check_heap_object() for
+	  validating memory ranges against heap object sizes in
+	  support of CONFIG_HARDENED_USERCOPY.
+
+config HARDENED_USERCOPY
+	bool "Harden memory copies between kernel and userspace"
+	depends on HAVE_HARDENED_USERCOPY_ALLOCATOR
+	imply STRICT_DEVMEM
+	help
+	  This option checks for obviously wrong memory regions when
+	  copying memory to/from the kernel (via copy_to_user() and
+	  copy_from_user() functions) by rejecting memory ranges that
+	  are larger than the specified heap object, span multiple
+	  separately allocated pages, are not on the process stack,
+	  or are part of the kernel text. This kills entire classes
+	  of heap overflow exploits and similar kernel memory exposures.
+
+config HARDENED_USERCOPY_FALLBACK
+	bool "Allow usercopy whitelist violations to fallback to object size"
+	depends on HARDENED_USERCOPY
+	default y
+	help
+	  This is a temporary option that allows missing usercopy whitelists
+	  to be discovered via a WARN() to the kernel log, instead of
+	  rejecting the copy, falling back to non-whitelisted hardened
+	  usercopy that checks the slab allocation size instead of the
+	  whitelist size. This option will be removed once it seems like
+	  all missing usercopy whitelists have been identified and fixed.
+	  Booting with "slab_common.usercopy_fallback=Y/N" can change
+	  this setting.
+
+config HARDENED_USERCOPY_PAGESPAN
+	bool "Refuse to copy allocations that span multiple pages"
+	depends on HARDENED_USERCOPY
+	depends on EXPERT
+	help
+	  When a multi-page allocation is done without __GFP_COMP,
+	  hardened usercopy will reject attempts to copy it. There are,
+	  however, several cases of this in the kernel that have not all
+	  been removed. This config is intended to be used only while
+	  trying to find such users.
+
+config FORTIFY_SOURCE
+	bool "Harden common str/mem functions against buffer overflows"
+	depends on ARCH_HAS_FORTIFY_SOURCE
+	# https://bugs.llvm.org/show_bug.cgi?id=50322
+	# https://bugs.llvm.org/show_bug.cgi?id=41459
+	depends on !CC_IS_CLANG
+	help
+	  Detect overflows of buffers in common string and memory functions
+	  where the compiler can determine and validate the buffer sizes.
+
+config STATIC_USERMODEHELPER
+	bool "Force all usermode helper calls through a single binary"
+	help
+	  By default, the kernel can call many different userspace
+	  binary programs through the "usermode helper" kernel
+	  interface.  Some of these binaries are statically defined
+	  either in the kernel code itself, or as a kernel configuration
+	  option.  However, some of these are dynamically created at
+	  runtime, or can be modified after the kernel has started up.
+	  To provide an additional layer of security, route all of these
+	  calls through a single executable that can not have its name
+	  changed.
+
+	  Note, it is up to this single binary to then call the relevant
+	  "real" usermode helper binary, based on the first argument
+	  passed to it.  If desired, this program can filter and pick
+	  and choose what real programs are called.
+
+	  If you wish for all usermode helper programs are to be
+	  disabled, choose this option and then set
+	  STATIC_USERMODEHELPER_PATH to an empty string.
+
+config STATIC_USERMODEHELPER_PATH
+	string "Path to the static usermode helper binary"
+	depends on STATIC_USERMODEHELPER
+	default "/sbin/usermode-helper"
+	help
+	  The binary called by the kernel when any usermode helper
+	  program is wish to be run.  The "real" application's name will
+	  be in the first argument passed to this program on the command
+	  line.
+
+	  If you wish for all usermode helper programs to be disabled,
+	  specify an empty string here (i.e. "").
+
+config SECURITY_FLOW_FRIENDLY
+	bool "Security hooks for information flow mechanisms."
+	default y
+	help
+		This option adds hooks to support information flow mechanisms. Some
+		information flow are not captured by LSM as it was designed for access
+		control.
+
+source "security/selinux/Kconfig"
+source "security/smack/Kconfig"
+source "security/tomoyo/Kconfig"
+source "security/apparmor/Kconfig"
+source "security/loadpin/Kconfig"
+source "security/yama/Kconfig"
+source "security/safesetid/Kconfig"
+source "security/lockdown/Kconfig"
+source "security/landlock/Kconfig"
+source "security/provenance/Kconfig"
+
+source "security/integrity/Kconfig"
+
+choice
+	prompt "First legacy 'major LSM' to be initialized"
+	default DEFAULT_SECURITY_SELINUX if SECURITY_SELINUX
+	default DEFAULT_SECURITY_SMACK if SECURITY_SMACK
+	default DEFAULT_SECURITY_TOMOYO if SECURITY_TOMOYO
+	default DEFAULT_SECURITY_APPARMOR if SECURITY_APPARMOR
+	default DEFAULT_SECURITY_DAC
+
+	help
+	  This choice is there only for converting CONFIG_DEFAULT_SECURITY
+	  in old kernel configs to CONFIG_LSM in new kernel configs. Don't
+	  change this choice unless you are creating a fresh kernel config,
+	  for this choice will be ignored after CONFIG_LSM has been set.
+
+	  Selects the legacy "major security module" that will be
+	  initialized first. Overridden by non-default CONFIG_LSM.
+
+	config DEFAULT_SECURITY_SELINUX
+		bool "SELinux" if SECURITY_SELINUX=y
+
+	config DEFAULT_SECURITY_SMACK
+		bool "Simplified Mandatory Access Control" if SECURITY_SMACK=y
+
+	config DEFAULT_SECURITY_TOMOYO
+		bool "TOMOYO" if SECURITY_TOMOYO=y
+
+	config DEFAULT_SECURITY_APPARMOR
+		bool "AppArmor" if SECURITY_APPARMOR=y
+
+	config DEFAULT_SECURITY_DAC
+		bool "Unix Discretionary Access Controls"
+
+endchoice
+
+config LSM
+	string "Ordered list of enabled LSMs"
+	default "landlock,lockdown,yama,loadpin,safesetid,integrity,smack,selinux,tomoyo,apparmor,bpf,provenance" if DEFAULT_SECURITY_SMACK
+	default "landlock,lockdown,yama,loadpin,safesetid,integrity,apparmor,selinux,smack,tomoyo,bpf,provenance" if DEFAULT_SECURITY_APPARMOR
+	default "landlock,lockdown,yama,loadpin,safesetid,integrity,tomoyo,bpf,provenance" if DEFAULT_SECURITY_TOMOYO
+	default "landlock,lockdown,yama,loadpin,safesetid,integrity,bpf,provenance" if DEFAULT_SECURITY_DAC
+	default "landlock,lockdown,yama,loadpin,safesetid,integrity,selinux,smack,tomoyo,apparmor,bpf,provenance"
+	help
+	  A comma-separated list of LSMs, in initialization order.
+	  Any LSMs left off this list will be ignored. This can be
+	  controlled at boot with the "lsm=" parameter.
+
+	  If unsure, leave this as the default.
+
+source "security/Kconfig.hardening"
+
+endmenu
diff --git a/security/_Makefile b/security/_Makefile
new file mode 100644
index 000000000..3abdec068
--- /dev/null
+++ b/security/_Makefile
@@ -0,0 +1,30 @@
+# SPDX-License-Identifier: GPL-2.0
+#
+# Makefile for the kernel security code
+#
+
+obj-$(CONFIG_KEYS)			+= keys/
+
+# always enable default capabilities
+obj-y					+= commoncap.o
+obj-$(CONFIG_MMU)			+= min_addr.o
+
+# Object file lists
+obj-$(CONFIG_SECURITY)			+= security.o
+obj-$(CONFIG_SECURITYFS)		+= inode.o
+obj-$(CONFIG_SECURITY_SELINUX)		+= selinux/
+obj-$(CONFIG_SECURITY_SMACK)		+= smack/
+obj-$(CONFIG_SECURITY)			+= lsm_audit.o
+obj-$(CONFIG_SECURITY_TOMOYO)		+= tomoyo/
+obj-$(CONFIG_SECURITY_APPARMOR)		+= apparmor/
+obj-$(CONFIG_SECURITY_YAMA)		+= yama/
+obj-$(CONFIG_SECURITY_LOADPIN)		+= loadpin/
+obj-$(CONFIG_SECURITY_SAFESETID)       += safesetid/
+obj-$(CONFIG_SECURITY_LOCKDOWN_LSM)	+= lockdown/
+obj-$(CONFIG_CGROUPS)			+= device_cgroup.o
+obj-$(CONFIG_BPF_LSM)			+= bpf/
+obj-$(CONFIG_SECURITY_LANDLOCK)		+= landlock/
+obj-$(CONFIG_SECURITY_PROVENANCE)	+= provenance/
+
+# Object integrity file lists
+obj-$(CONFIG_INTEGRITY)			+= integrity/
diff --git a/security/provenance/Kconfig b/security/provenance/Kconfig
new file mode 100644
index 000000000..bdb342701
--- /dev/null
+++ b/security/provenance/Kconfig
@@ -0,0 +1,32 @@
+config SECURITY_PROVENANCE
+         bool "CamFlow - Provenance"
+         depends on SECURITY
+         depends on NET
+         depends on INET
+         select RELAY
+         select SECURITY_NETWORK
+         select SECURITYFS
+         select NETFILTER
+         select CRYPTO_SHA256
+         default y
+         help
+          This selects CamFlow provenance modules. It captures provenance through
+          a Linux Security Module.
+
+config SECURITY_PROVENANCE_WHOLE_SYSTEM
+	bool "CamFlow - Whole system provenance"
+	depends on SECURITY_PROVENANCE
+	default n
+	help
+	  This option activate whole system provenance capture from boot.
+
+	  If you are unsure how to answer this question, answer N.
+
+config SECURITY_PROVENANCE_PERSISTENCE
+	bool "CamFlow - Persistence"
+	depends on SECURITY_PROVENANCE
+	default n
+	help
+	  This option persist inode provenance state across reboot.
+
+	  If you are unsure how to answer this question, answer N.
diff --git a/security/provenance/Makefile b/security/provenance/Makefile
new file mode 100644
index 000000000..4a5709eeb
--- /dev/null
+++ b/security/provenance/Makefile
@@ -0,0 +1,8 @@
+#
+# Makefile for Provenance LSM
+#
+obj-$(CONFIG_SECURITY_PROVENANCE) := provenance.o
+
+provenance-y := relay.o hooks.o query.o fs.o netfilter.o propagate.o type.o machine.o memcpy_ss.o
+
+ccflags-y := -I$(srctree)/security/provenance/include
diff --git a/security/provenance/fs.c b/security/provenance/fs.c
new file mode 100644
index 000000000..8a5e26901
--- /dev/null
+++ b/security/provenance/fs.c
@@ -0,0 +1,1159 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+
+/*!
+ * This file creates securityfs for provenance capture.
+ * @todo We will document this file if needed in the future.
+ *
+ */
+#include <linux/security.h>
+#include <linux/provenance_types.h>
+#include <crypto/hash.h>
+
+#include "provenance.h"
+#include "provenance_record.h"
+#include "provenance_inode.h"
+#include "provenance_net.h"
+#include "provenance_task.h"
+#include "provenance_machine.h"
+#include "memcpy_ss.h"
+
+#define TMPBUFLEN    12
+
+#define declare_file_operations(ops_name, write_op, read_op) \
+	static const struct file_operations ops_name = {     \
+		.write = write_op,			     \
+		.read = read_op,			     \
+		.llseek = generic_file_llseek,		     \
+	}
+
+static ssize_t no_read(struct file *filp,
+		       char __user *buf,
+		       size_t count,
+		       loff_t *ppos)
+{
+	return -EPERM; // write only
+}
+
+static ssize_t no_write(struct file *file, const char __user *buf,
+			size_t count, loff_t *ppos)
+{
+	return -EPERM; // read only
+}
+
+static inline ssize_t __write_flag(struct file *file, const char __user *buf,
+				   size_t count, loff_t *ppos, bool *flag)
+{
+	char *str;
+	ssize_t rc;
+	uint32_t tmp;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	str = memdup_user(buf, count);
+	if (IS_ERR(str))
+		return PTR_ERR(str);
+
+	rc = kstrtouint(str, 2, &tmp);
+	if (rc)
+		goto out;
+
+	(*flag) = tmp;
+out:
+	kfree(str);
+	return rc;
+}
+
+static ssize_t __read_flag(struct file *filp, char __user *buf,
+			   size_t count, loff_t *ppos, bool flag)
+{
+	if (flag)
+		return simple_read_from_buffer(buf, count, ppos, "1", 2);
+	else
+		return simple_read_from_buffer(buf, count, ppos, "0", 2);
+}
+
+#define declare_write_flag_fcn(fcn_name, flag)			    \
+	static ssize_t fcn_name(struct file *file,		    \
+				const char __user * buf,	    \
+				size_t count,			    \
+				loff_t * ppos)			    \
+	{							    \
+		return __write_flag(file, buf, count, ppos, &flag); \
+	}
+
+#define declare_read_flag_fcn(fcn_name, flag)			  \
+	static ssize_t fcn_name(struct file *filp,		  \
+				char __user * buf,		  \
+				size_t count,			  \
+				loff_t * ppos)			  \
+	{							  \
+		return __read_flag(filp, buf, count, ppos, flag); \
+	}
+
+declare_write_flag_fcn(prov_write_enable, prov_policy.prov_enabled);
+declare_read_flag_fcn(prov_read_enable, prov_policy.prov_enabled);
+declare_file_operations(prov_enable_ops, prov_write_enable, prov_read_enable);
+
+declare_write_flag_fcn(prov_write_all, prov_policy.prov_all);
+declare_read_flag_fcn(prov_read_all, prov_policy.prov_all);
+declare_file_operations(prov_all_ops, prov_write_all, prov_read_all);
+
+declare_read_flag_fcn(prov_read_written, prov_written);
+declare_file_operations(prov_written_ops, no_write, prov_read_written);
+
+declare_write_flag_fcn(prov_write_compress_node,
+		       prov_policy.should_compress_node);
+declare_read_flag_fcn(prov_read_compress_node,
+		      prov_policy.should_compress_node);
+declare_file_operations(prov_compress_node_ops,
+			prov_write_compress_node,
+			prov_read_compress_node);
+
+declare_write_flag_fcn(prov_write_compress_edge,
+		       prov_policy.should_compress_edge);
+declare_read_flag_fcn(prov_read_compress_edge,
+		      prov_policy.should_compress_edge);
+declare_file_operations(prov_compress_edge_ops,
+			prov_write_compress_edge,
+			prov_read_compress_edge);
+
+declare_write_flag_fcn(prov_write_duplicate, prov_policy.should_duplicate);
+declare_read_flag_fcn(prov_read_duplicate, prov_policy.should_duplicate);
+declare_file_operations(prov_duplicate_ops,
+			prov_write_duplicate,
+			prov_read_duplicate);
+
+static ssize_t prov_write_machine_id(struct file *file, const char __user *buf,
+				     size_t count, loff_t *ppos)
+{
+	if (prov_machine_id != 0)   // it has already been set
+		return -EPERM;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	if (count < sizeof(uint32_t))
+		return -ENOMEM;
+
+	if (copy_from_user(&prov_machine_id, buf, sizeof(uint32_t)))
+		return -EAGAIN;
+
+	if (prov_machine_id == 0)
+		return -EINVAL;
+
+	pr_info("Provenance: machine ID %d\n", prov_machine_id);
+	write_boot_buffer();
+	return count; // read only
+}
+
+static ssize_t prov_read_machine_id(struct file *filp, char __user *buf,
+				    size_t count, loff_t *ppos)
+{
+	if (count < sizeof(uint32_t))
+		return -ENOMEM;
+
+	if (copy_to_user(buf, &prov_machine_id, sizeof(uint32_t)))
+		return -EAGAIN;
+
+	return count;
+}
+declare_file_operations(prov_machine_id_ops,
+			prov_write_machine_id,
+			prov_read_machine_id);
+
+static ssize_t prov_write_boot_id(struct file *file, const char __user *buf,
+				  size_t count, loff_t *ppos)
+{
+	if (prov_boot_id != 0)   // it has already been set
+		return -EPERM;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	if (count < sizeof(uint32_t))
+		return -ENOMEM;
+
+	if (copy_from_user(&prov_boot_id, buf, sizeof(uint32_t)))
+		return -EAGAIN;
+
+	if (prov_boot_id == 0)
+		return -EINVAL;
+
+	pr_info("Provenance: boot ID %d\n", prov_boot_id);
+	write_boot_buffer();
+	return count; // read only
+}
+
+static ssize_t prov_read_boot_id(struct file *filp, char __user *buf,
+				 size_t count, loff_t *ppos)
+{
+	if (count < sizeof(uint32_t))
+		return -ENOMEM;
+
+	if (copy_to_user(buf, &prov_boot_id, sizeof(uint32_t)))
+		return -EAGAIN;
+
+	return count;
+}
+declare_file_operations(prov_boot_id_ops,
+			prov_write_boot_id,
+			prov_read_boot_id);
+
+
+static ssize_t prov_write_node(struct file *file, const char __user *buf,
+			       size_t count, loff_t *ppos)
+
+{
+	struct provenance *tprov = provenance_task(current);
+	union long_prov_elt *node;
+
+	if (count < sizeof(struct disc_node_struct))
+		return -ENOMEM;
+
+	node = memdup_user(buf, sizeof(struct disc_node_struct));
+	if (IS_ERR(node))
+		return PTR_ERR(node);
+
+	if (prov_type(node) == ENT_DISC ||
+	    prov_type(node) == ACT_DISC ||
+	    prov_type(node) == AGT_DISC) {
+		spin_lock(prov_lock(tprov));
+		// TODO redo
+		__write_node(prov_entry(tprov));
+		__memcpy_ss(&node->disc_node_info.parent,
+			    sizeof(union prov_identifier),
+			    &prov_elt(tprov)->node_info.identifier,
+			    sizeof(union prov_identifier));
+		spin_unlock(prov_lock(tprov));
+		node_identifier(node).id = prov_next_node_id();
+		node_identifier(node).boot_id = prov_boot_id;
+		node_identifier(node).machine_id = prov_machine_id;
+		__write_node(node);
+	} else { // the node is not of disclosed type
+		count = -EINVAL;
+		goto out;
+	}
+out:
+	kfree(prov_elt(tprov)->task_info.disc);
+	prov_elt(tprov)->task_info.disc = node;
+	return count;
+}
+
+static ssize_t prov_read_node(struct file *filp, char __user *buf,
+			      size_t count, loff_t *ppos)
+{
+	struct provenance *tprov = provenance_task(current);
+
+	if (count < sizeof(struct disc_node_struct))
+		return -ENOMEM;
+	if (!prov_elt(tprov)->task_info.disc)
+		return -EINVAL;
+	if (copy_to_user(buf, prov_elt(tprov)->task_info.disc,
+			 sizeof(struct disc_node_struct)))
+		return -ENOMEM;
+	return sizeof(struct disc_node_struct);
+}
+declare_file_operations(prov_node_ops, prov_write_node, prov_read_node);
+
+static ssize_t prov_write_relation(struct file *file, const char __user *buf,
+				   size_t count, loff_t *ppos)
+{
+	union prov_elt relation;
+
+	if (count < sizeof(struct relation_struct))
+		return -ENOMEM;
+
+	if (copy_from_user(&relation, buf, sizeof(struct relation_struct)))
+		return -ENOMEM;
+	relation_identifier(&relation).id = prov_next_relation_id();
+	relation_identifier(&relation).boot_id = prov_boot_id;
+	relation_identifier(&relation).machine_id = prov_machine_id;
+	prov_write(&relation, sizeof(union prov_elt));
+	return count;
+}
+declare_file_operations(prov_relation_ops, prov_write_relation, no_read);
+
+static inline void update_prov_config(union prov_elt *setting,
+				      uint8_t op,
+				      struct provenance *prov)
+{
+	if ((op & PROV_SET_TRACKED) != 0) {
+		if (provenance_is_tracked(setting))
+			set_tracked(prov_elt(prov));
+		else
+			clear_tracked(prov_elt(prov));
+	}
+
+	if ((op & PROV_SET_OPAQUE) != 0) {
+		if (provenance_is_opaque(setting))
+			set_opaque(prov_elt(prov));
+		else
+			clear_opaque(prov_elt(prov));
+	}
+
+	if ((op & PROV_SET_PROPAGATE) != 0) {
+		if (provenance_does_propagate(setting))
+			set_propagate(prov_elt(prov));
+		else
+			clear_propagate(prov_elt(prov));
+	}
+
+	if ((op & PROV_SET_TAINT) != 0)
+		provenance_taint_merge(prov_taint(prov_elt(prov)),
+				       prov_taint(setting));
+}
+
+static ssize_t prov_write_self(struct file *file, const char __user *buf,
+			       size_t count, loff_t *ppos)
+{
+	struct prov_process_config msg;
+	struct provenance *prov = provenance_cred_from_task(current);
+
+	if (!prov)
+		return -EINVAL;
+
+	if (count < sizeof(struct prov_process_config))
+		return -EINVAL;
+
+	if (copy_from_user(&msg, buf, sizeof(struct prov_process_config)))
+		return -ENOMEM;
+
+	update_prov_config(&(msg.prov), msg.op, prov);
+	return sizeof(struct prov_process_config);
+}
+
+static ssize_t prov_read_self(struct file *filp, char __user *buf,
+			      size_t count, loff_t *ppos)
+{
+	struct provenance *cprov = provenance_cred_from_task(current);
+
+	if (count < sizeof(struct task_prov_struct))
+		return -ENOMEM;
+
+	spin_lock(prov_lock(cprov));
+	if (copy_to_user(buf, prov_elt(cprov), sizeof(union prov_elt)))
+		count = -EAGAIN;
+	spin_unlock(prov_lock(cprov));
+	return count; // write only
+}
+declare_file_operations(prov_self_ops, prov_write_self, prov_read_self);
+
+static inline ssize_t __write_filter(struct file *file, const char __user *buf,
+				     size_t count, uint64_t *filter)
+{
+	struct prov_filter setting;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	if (count < sizeof(struct prov_filter))
+		return -ENOMEM;
+
+	if (copy_from_user(&setting, buf, sizeof(struct prov_filter)))
+		return -ENOMEM;
+
+	if (setting.add != 0)
+		(*filter) |= setting.filter & setting.mask;
+	else
+		(*filter) &=  ~(setting.filter & setting.mask);
+
+	return count;
+}
+
+static inline ssize_t __read_filter(struct file *filp, char __user *buf,
+				    size_t count, uint64_t filter)
+{
+	if (count < sizeof(uint64_t))
+		return -ENOMEM;
+
+	if (copy_to_user(buf, &filter, sizeof(uint64_t)))
+		return -EAGAIN;
+
+	return count;
+}
+
+#define declare_write_filter_fcn(fcn_name, filter)		  \
+	static ssize_t fcn_name(struct file *file,		  \
+				const char __user * buf,	  \
+				size_t count,			  \
+				loff_t * ppos)			  \
+	{							  \
+		return __write_filter(file, buf, count, &filter); \
+	}
+
+#define declare_read_filter_fcn(fcn_name, filter)		\
+	static ssize_t fcn_name(struct file *filp,		\
+				char __user * buf,		\
+				size_t count,			\
+				loff_t * ppos)			\
+	{							\
+		return __read_filter(filp, buf, count, filter);	\
+	}
+
+declare_write_filter_fcn(prov_write_node_filter, prov_policy.prov_node_filter);
+declare_read_filter_fcn(prov_read_node_filter, prov_policy.prov_node_filter);
+declare_file_operations(prov_node_filter_ops,
+			prov_write_node_filter,
+			prov_read_node_filter);
+
+declare_write_filter_fcn(prov_write_derived_filter,
+			 prov_policy.prov_derived_filter);
+declare_read_filter_fcn(prov_read_derived_filter,
+			prov_policy.prov_derived_filter);
+declare_file_operations(prov_derived_filter_ops,
+			prov_write_derived_filter,
+			prov_read_derived_filter);
+
+declare_write_filter_fcn(prov_write_generated_filter,
+			 prov_policy.prov_generated_filter);
+declare_read_filter_fcn(prov_read_generated_filter,
+			prov_policy.prov_generated_filter);
+declare_file_operations(prov_generated_filter_ops,
+			prov_write_generated_filter,
+			prov_read_generated_filter);
+
+declare_write_filter_fcn(prov_write_used_filter, prov_policy.prov_used_filter);
+declare_read_filter_fcn(prov_read_used_filter, prov_policy.prov_used_filter);
+declare_file_operations(prov_used_filter_ops,
+			prov_write_used_filter,
+			prov_read_used_filter);
+
+declare_write_filter_fcn(prov_write_informed_filter,
+			 prov_policy.prov_informed_filter);
+declare_read_filter_fcn(prov_read_informed_filter,
+			prov_policy.prov_informed_filter);
+declare_file_operations(prov_informed_filter_ops,
+			prov_write_informed_filter,
+			prov_read_informed_filter);
+
+declare_write_filter_fcn(prov_write_propagate_node_filter,
+			 prov_policy.prov_propagate_node_filter);
+declare_read_filter_fcn(prov_read_propagate_node_filter,
+			prov_policy.prov_propagate_node_filter);
+declare_file_operations(prov_propagate_node_filter_ops,
+			prov_write_propagate_node_filter,
+			prov_read_propagate_node_filter);
+
+declare_write_filter_fcn(prov_write_propagate_derived_filter,
+			 prov_policy.prov_propagate_derived_filter);
+declare_read_filter_fcn(prov_read_propagate_derived_filter,
+			prov_policy.prov_propagate_derived_filter);
+declare_file_operations(prov_propagate_derived_filter_ops,
+			prov_write_propagate_derived_filter,
+			prov_read_propagate_derived_filter);
+
+declare_write_filter_fcn(prov_write_propagate_generated_filter,
+			 prov_policy.prov_propagate_generated_filter);
+declare_read_filter_fcn(prov_read_propagate_generated_filter,
+			prov_policy.prov_propagate_generated_filter);
+declare_file_operations(prov_propagate_generated_filter_ops,
+			prov_write_propagate_generated_filter,
+			prov_read_propagate_generated_filter);
+
+declare_write_filter_fcn(prov_write_propagate_used_filter,
+			 prov_policy.prov_propagate_used_filter);
+declare_read_filter_fcn(prov_read_propagate_used_filter,
+			prov_policy.prov_propagate_used_filter);
+declare_file_operations(prov_propagate_used_filter_ops,
+			prov_write_propagate_used_filter,
+			prov_read_propagate_used_filter);
+
+declare_write_filter_fcn(prov_write_propagate_informed_filter,
+			 prov_policy.prov_propagate_informed_filter);
+declare_read_filter_fcn(prov_read_propagate_informed_filter,
+			prov_policy.prov_propagate_informed_filter);
+declare_file_operations(prov_propagate_informed_filter_ops,
+			prov_write_propagate_informed_filter,
+			prov_read_propagate_informed_filter);
+
+static ssize_t prov_write_flush(struct file *file, const char __user *buf,
+				size_t count, loff_t *ppos)
+
+{
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	prov_flush();
+	return 0;
+}
+declare_file_operations(prov_flush_ops, prov_write_flush, no_read);
+
+static ssize_t prov_write_process(struct file *file, const char __user *buf,
+				  size_t count, loff_t *ppos)
+{
+	struct prov_process_config msg;
+	struct provenance *prov;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+
+	if (count < sizeof(struct prov_process_config))
+		return -EINVAL;
+
+	if (copy_from_user(&msg, buf, sizeof(struct prov_process_config)))
+		return -ENOMEM;
+
+	prov = prov_from_vpid(msg.vpid);
+	if (!prov)
+		return -EINVAL;
+
+	update_prov_config(&(msg.prov), msg.op, prov);
+	return sizeof(struct prov_process_config);
+}
+
+static ssize_t prov_read_process(struct file *filp, char __user *buf,
+				 size_t count, loff_t *ppos)
+{
+	struct prov_process_config *msg;
+	struct provenance *prov;
+	int rtn = sizeof(struct prov_process_config);
+
+	if (count < sizeof(struct prov_process_config))
+		return -EINVAL;
+
+	msg = memdup_user(buf, sizeof(struct prov_process_config));
+	if (IS_ERR(msg))
+		return PTR_ERR(msg);
+
+	prov = prov_from_vpid(msg->vpid);
+	if (!prov) {
+		rtn = -EINVAL;
+		goto out;
+	}
+
+	spin_lock(prov_lock(prov));
+	__memcpy_ss(&msg->prov, sizeof(union prov_elt),
+		    prov_elt(prov), sizeof(union prov_elt));
+	spin_unlock(prov_lock(prov));
+
+	if (copy_to_user(buf, msg, sizeof(struct prov_process_config)))
+		rtn = -ENOMEM;
+out:
+	kfree(msg);
+	return rtn;
+}
+declare_file_operations(prov_process_ops,
+			prov_write_process,
+			prov_read_process);
+
+static ssize_t __write_ipv4_filter(struct file *file, const char __user *buf,
+				   size_t count, struct list_head *filters)
+{
+	struct ipv4_filters *f;
+
+	if (!capable(CAP_AUDIT_CONTROL))
+		return -EPERM;
+	if (count < sizeof(struct prov_ipv4_filter))
+		return -ENOMEM;
+	f = kzalloc(sizeof(struct ipv4_filters), GFP_KERNEL);
+	if (!f)
+		return -ENOMEM;
+	if (copy_from_user(&(f->filter), buf, sizeof(struct prov_ipv4_filter))) {
+		kfree(f);
+		return -EAGAIN;
+	}
+	f->filter.ip = f->filter.ip & f->filter.mask;
+	// we are not trying to delete something
+	if ((f->filter.op & PROV_SET_DELETE) != PROV_SET_DELETE)
+		prov_ipv4_add_or_update(filters, f);
+	else
+		prov_ipv4_delete(filters, f);
+	return sizeof(struct prov_ipv4_filter);
+}
+
+static ssize_t __read_ipv4_filter(struct file *filp, char __user *buf,
+				  size_t count, struct list_head *filters)
+{
+	struct list_head *listentry, *listtmp;
+	struct ipv4_filters *tmp;
+	size_t pos = 0;
+
+	if (count < sizeof(struct prov_ipv4_filter))
+		return -ENOMEM;
+
+	list_for_each_safe(listentry, listtmp, filters) {
+		tmp = list_entry(listentry, struct ipv4_filters, list);
+		if (count < pos + sizeof(struct prov_ipv4_filter))
+			return -ENOMEM;
+
+		if (copy_to_user(buf + pos, &(tmp->filter),
+				 sizeof(struct prov_ipv4_filter)))
+			return -EAGAIN;
+
+		pos += sizeof(struct prov_ipv4_filter);
+	}
+	return pos;
+}
+
+#define declare_write_ipv4_filter_fcn(fcn_name, filter)		       \
+	static ssize_t fcn_name(struct file *file,		       \
+				const char __user * buf,	       \
+				size_t count,			       \
+				loff_t * ppos)			       \
+	{							       \
+		return __write_ipv4_filter(file, buf, count, &filter); \
+	}
+
+#define declare_reader_ipv4_filter_fcn(fcn_name, filter)	      \
+	static ssize_t fcn_name(struct file *filp,		      \
+				char __user * buf,		      \
+				size_t count,			      \
+				loff_t * ppos)			      \
+	{							      \
+		return __read_ipv4_filter(filp, buf, count, &filter); \
+	}
+
+declare_write_ipv4_filter_fcn(prov_write_ipv4_ingress_filter,
+			      ingress_ipv4filters);
+declare_reader_ipv4_filter_fcn(prov_read_ipv4_ingress_filter,
+			       ingress_ipv4filters);
+declare_file_operations(prov_ipv4_ingress_filter_ops,
+			prov_write_ipv4_ingress_filter,
+			prov_read_ipv4_ingress_filter);
+
+declare_write_ipv4_filter_fcn(prov_write_ipv4_egress_filter,
+			      egress_ipv4filters);
+declare_reader_ipv4_filter_fcn(prov_read_ipv4_egress_filter,
+			       egress_ipv4filters);
+declare_file_operations(prov_ipv4_egress_filter_ops,
+			prov_write_ipv4_egress_filter,
+			prov_read_ipv4_egress_filter);
+
+static ssize_t prov_read_secctx(struct file *filp, char __user *buf,
+				size_t count, loff_t *ppos)
+{
+	char *ctx = NULL;
+	uint32_t len;
+	struct secinfo *data;
+	int rtn = 0;
+
+	if (count < sizeof(struct secinfo))
+		return -ENOMEM;
+
+	data = memdup_user(buf, sizeof(struct secinfo));
+	if (IS_ERR(data))
+		return PTR_ERR(data);
+	// in case US does not check returned value
+	data->secctx[0] = '\0';
+	data->len = 0;
+
+	rtn = security_secid_to_secctx(data->secid, &ctx, &len); // read secctx
+	if (rtn < 0)
+		goto out;
+	if (len >= PATH_MAX) {
+		rtn = -ENOMEM;
+		goto out;
+	}
+	__memcpy_ss(data->secctx, PATH_MAX, ctx, len);
+	data->len = len;
+out:
+	security_release_secctx(ctx, len); // security module dealloc
+	if (copy_to_user(buf, data, sizeof(struct secinfo)))
+		rtn = -EAGAIN;
+	kfree(data);
+	return rtn;
+}
+declare_file_operations(prov_secctx_ops, no_write, prov_read_secctx);
+
+#define declare_generic_filter_write(function_name, filters, info, add_function, delete_function) \
+	static ssize_t function_name(struct file *file,						  \
+				     const char __user * buf,					  \
+				     size_t count,						  \
+				     loff_t * ppos)						  \
+	{											  \
+		struct filters *s;								  \
+		if (count < sizeof(struct info))						  \
+		return -ENOMEM;									  \
+		s = kzalloc(sizeof(struct filters), GFP_KERNEL);				  \
+		if (!s)										  \
+		return -ENOMEM;									  \
+		if (copy_from_user(&s->filter, buf, sizeof(struct info))) {			  \
+			kfree(s);								  \
+			return -EAGAIN;								  \
+		}										  \
+		if ((s->filter.op & PROV_SET_DELETE) != PROV_SET_DELETE) {			  \
+			add_function(s);							  \
+		} else {									  \
+			delete_function(s);							  \
+		} return sizeof(struct filters);						  \
+	}
+
+#define declare_generic_filter_read(function_name, filters, info)			    \
+	static ssize_t function_name(struct file *filp,					    \
+				     char __user * buf,					    \
+				     size_t count,					    \
+				     loff_t * ppos)					    \
+	{										    \
+		struct list_head *listentry, *listtmp;					    \
+		struct filters *tmp;							    \
+		size_t pos = 0;								    \
+		if (count < sizeof(struct info)) {					    \
+			return -ENOMEM; }						    \
+		list_for_each_safe(listentry, listtmp, &filters) {			    \
+			tmp = list_entry(listentry, struct filters, list);		    \
+			if (count < pos + sizeof(struct info)) {			    \
+				return -ENOMEM; }					    \
+			if (copy_to_user(buf + pos, &(tmp->filter), sizeof(struct info))) { \
+				return -EAGAIN; }					    \
+			pos += sizeof(struct info);					    \
+		}									    \
+		return pos;								    \
+	}
+
+static ssize_t prov_write_secctx_filter(struct file *file,
+					const char __user *buf,
+					size_t count,
+					loff_t *ppos)
+{
+	struct secctx_filters *s;
+
+	if (count < sizeof(struct secinfo))
+		return -ENOMEM;
+
+	s = kzalloc(sizeof(struct secctx_filters), GFP_KERNEL);
+	if (!s)
+		return -ENOMEM;
+
+	if (copy_from_user(&s->filter, buf, sizeof(struct secinfo))) {
+		kfree(s);
+		return -EAGAIN;
+	}
+
+	security_secctx_to_secid(s->filter.secctx,
+				 s->filter.len,
+				 &s->filter.secid);
+	if ((s->filter.op & PROV_SET_DELETE) != PROV_SET_DELETE)
+		prov_secctx_add_or_update(s);
+	else
+		prov_secctx_delete(s);
+	return sizeof(struct secinfo);
+}
+
+declare_generic_filter_read(prov_read_secctx_filter, secctx_filters, secinfo);
+declare_file_operations(prov_secctx_filter_ops,
+			prov_write_secctx_filter,
+			prov_read_secctx_filter);
+
+declare_generic_filter_write(prov_write_uid_filter,
+			     user_filters, userinfo,
+			     prov_uid_add_or_update,
+			     prov_uid_delete);
+declare_generic_filter_read(prov_read_uid_filter, user_filters, userinfo);
+declare_file_operations(prov_uid_filter_ops,
+			prov_write_uid_filter,
+			prov_read_uid_filter);
+
+declare_generic_filter_write(prov_write_gid_filter,
+			     group_filters,
+			     groupinfo,
+			     prov_gid_add_or_update,
+			     prov_gid_delete);
+declare_generic_filter_read(prov_read_gid_filter, group_filters, groupinfo);
+declare_file_operations(prov_gid_filter_ops,
+			prov_write_gid_filter,
+			prov_read_gid_filter);
+
+static ssize_t prov_write_ns_filter(struct file *file, const char __user *buf,
+				    size_t count, loff_t *ppos)
+{
+	struct ns_filters *s;
+
+	if (count < sizeof(struct nsinfo))
+		return -ENOMEM;
+
+	s = kzalloc(sizeof(struct ns_filters), GFP_KERNEL);
+	if (!s)
+		return -ENOMEM;
+
+	if (copy_from_user(&s->filter, buf, sizeof(struct nsinfo))) {
+		kfree(s);
+		return -EAGAIN;
+	}
+
+	if ((s->filter.op & PROV_SET_DELETE) != PROV_SET_DELETE)
+		prov_ns_add_or_update(s);
+	else
+		prov_ns_delete(s);
+	return sizeof(struct nsinfo);
+}
+
+static ssize_t prov_read_ns_filter(struct file *filp, char __user *buf,
+				   size_t count, loff_t *ppos)
+{
+	struct list_head *listentry, *listtmp;
+	struct ns_filters *tmp;
+	size_t pos = 0;
+
+	if (count < sizeof(struct nsinfo))
+		return -ENOMEM;
+
+	list_for_each_safe(listentry, listtmp, &ns_filters) {
+		tmp = list_entry(listentry, struct ns_filters, list);
+		if (count < pos + sizeof(struct nsinfo))
+			return -ENOMEM;
+		if (copy_to_user(buf + pos, &(tmp->filter),
+				 sizeof(struct nsinfo)))
+			return -EAGAIN;
+		pos += sizeof(struct nsinfo);
+	}
+	return pos;
+}
+declare_file_operations(prov_ns_filter_ops,
+			prov_write_ns_filter,
+			prov_read_ns_filter);
+
+/*!
+ * @brief This function records a relation between a provenance node and a user
+ * supplied data, which is a transient node.
+ *
+ * This function allows the user to attach an annotation node to a provenance
+ * node.
+ * The relation between the two nodes is RL_LOG and the node of the
+ * user-supplied log is of type ENT_STR.
+ * ENT_STR node is transient and should not have further use.
+ * Therefore, once we have recorded the node, we will free the memory allocated
+ * for it.
+ * @param cprov Provenance node to be annotated by the user.
+ * @param buf Userspace buffer where user annotation locates.
+ * @param count Number of bytes copied from the user buffer.
+ * @return Number of bytes copied. -ENOMEM if no memory can be allocated for
+ * the transient long provenance node. -EAGAIN if copying from userspace
+ * failed. Other error codes unknown.
+ *
+ */
+static inline int record_log(union prov_elt *tprov,
+			     const char __user *buf,
+			     size_t count)
+{
+	union long_prov_elt *str;
+	int rc = 0;
+
+	str = alloc_long_provenance(ENT_STR, 0);
+	if (!str)
+		return -ENOMEM;
+	if (copy_from_user(str->str_info.str, buf, count)) {
+		rc = -EAGAIN;
+		goto out;
+	}
+	// Make sure the string is null terminated.
+	str->str_info.str[count] = '\0';
+	str->str_info.length = count;
+
+	rc = __write_relation(RL_LOG, str, tprov, NULL, 0);
+out:
+	free_long_provenance(str);
+	if (rc < 0)
+		return rc;
+	return count;
+}
+
+static ssize_t prov_write_log(struct file *file, const char __user *buf,
+			      size_t count, loff_t *ppos)
+{
+	struct provenance *tprov = get_task_provenance(false);
+
+	if (count <= 0 || count >= PATH_MAX)
+		return -ENOMEM;
+	set_tracked(prov_elt(tprov));
+	return record_log(prov_elt(tprov), buf, count);
+}
+declare_file_operations(prov_log_ops, prov_write_log, no_read);
+
+static ssize_t prov_write_logp(struct file *file, const char __user *buf,
+			       size_t count, loff_t *ppos)
+{
+	struct provenance *tprov = get_task_provenance(false);
+
+	if (count <= 0 || count >= PATH_MAX)
+		return -ENOMEM;
+	set_tracked(prov_elt(tprov));
+	set_propagate(prov_elt(tprov));
+	return record_log(prov_elt(tprov), buf, count);
+}
+declare_file_operations(prov_logp_ops, prov_write_logp, no_read);
+
+#define hash_filters(filters, filters_type, tmp, tmp_type)						 \
+	do {												 \
+		list_for_each_safe(listentry, listtmp, &filters) {					 \
+			tmp = list_entry(listentry, struct filters_type, list);				 \
+			rc = crypto_shash_update(hashdesc, (u8 *)&tmp->filter, sizeof(struct tmp_type)); \
+			if (rc) {									 \
+				pr_err("Provenance: error updating hash.");				 \
+				pos = -EAGAIN;								 \
+				goto out;								 \
+			}										 \
+		}											 \
+	} while (0)
+
+static ssize_t prov_read_policy_hash(struct file *filp, char __user *buf,
+				     size_t count, loff_t *ppos)
+{
+	size_t pos = 0;
+	size_t size;
+	int rc;
+	struct crypto_shash *policy_shash_tfm;
+	struct shash_desc *hashdesc = NULL;
+	uint8_t *buff = NULL;
+	struct list_head *listentry, *listtmp;
+	struct ipv4_filters *ipv4_tmp;
+	struct ns_filters *ns_tmp;
+	struct secctx_filters *secctx_tmp;
+	struct user_filters *user_tmp;
+	struct group_filters *group_tmp;
+
+	policy_shash_tfm = crypto_alloc_shash(PROVENANCE_HASH, 0, 0);
+	if (IS_ERR(policy_shash_tfm))
+		return -ENOMEM;
+	pos = crypto_shash_digestsize(policy_shash_tfm);
+	if (count < pos) {
+		pos = -ENOMEM;
+		goto out_shash;
+	}
+	size = sizeof(struct shash_desc) +
+	       crypto_shash_descsize(policy_shash_tfm);
+	hashdesc = kzalloc(size, GFP_KERNEL);
+	if (!hashdesc) {
+		pos = -ENOMEM;
+		goto out_shash;
+	}
+	buff = kzalloc(pos, GFP_KERNEL);
+	if (!buff) {
+		pos = -ENOMEM;
+		goto out_hashdesc;
+	}
+	hashdesc->tfm = policy_shash_tfm;
+	rc = crypto_shash_init(hashdesc);
+	if (rc) {
+		pos = -EAGAIN;
+		goto out;
+	}
+	/* LSM version */
+	rc = crypto_shash_update(hashdesc, (u8 *)CAMFLOW_VERSION_STR,
+				 strnlen(CAMFLOW_VERSION_STR, 32));
+	if (rc) {
+		pos = -EAGAIN;
+		goto out;
+	}
+	/* commit */
+	rc = crypto_shash_update(hashdesc,
+				 (u8 *)CAMFLOW_COMMIT,
+				 strnlen(CAMFLOW_COMMIT,
+					 PROV_COMMIT_MAX_LENGTH));
+	if (rc) {
+		pos = -EAGAIN;
+		goto out;
+	}
+	/* general policy */
+	rc = crypto_shash_update(hashdesc, (u8 *)&prov_policy,
+				 sizeof(struct capture_policy));
+	if (rc) {
+		pos = -EAGAIN;
+		goto out;
+	}
+	/* ingress network policy */
+	hash_filters(ingress_ipv4filters, ipv4_filters, ipv4_tmp, prov_ipv4_filter);
+	/* egress network policy */
+	hash_filters(egress_ipv4filters, ipv4_filters, ipv4_tmp, prov_ipv4_filter);
+	/* namespace policy */
+	hash_filters(ns_filters, ns_filters, ns_tmp, ns_filters);
+	/* secctx policy */
+	hash_filters(secctx_filters, secctx_filters, secctx_tmp, secinfo);
+	/* userid policy */
+	hash_filters(user_filters, user_filters, user_tmp, userinfo);
+	/* groupid policy */
+	hash_filters(group_filters, group_filters, group_tmp, groupinfo);
+
+	rc = crypto_shash_final(hashdesc, buff);
+	if (rc) {
+		pos = -EAGAIN;
+		goto out;
+	}
+	if (copy_to_user(buf, buff, pos))
+		pos = -EAGAIN;
+out:
+	kfree(buff);
+out_hashdesc:
+	kfree(hashdesc);
+out_shash:
+	crypto_free_shash(policy_shash_tfm);
+	return pos;
+}
+declare_file_operations(prov_policy_hash_ops, no_write, prov_read_policy_hash);
+
+static ssize_t prov_read_prov_type(struct file *filp, char __user *buf,
+				   size_t count, loff_t *ppos)
+{
+	struct prov_type *type_info;
+	ssize_t rc = sizeof(struct prov_type);
+
+	if (count < sizeof(struct prov_type))
+		return -ENOMEM;
+
+	type_info = memdup_user(buf, sizeof(struct prov_type));
+	if (IS_ERR(type_info))
+		return PTR_ERR(type_info);
+
+	if (type_info->is_relation) {
+		if (type_info->id)
+			strscpy(type_info->str, relation_str(type_info->id),
+				PROV_TYPE_STR_MAX_LEN);
+		else
+			type_info->id = relation_id(type_info->str);
+	} else {
+		if (type_info->id)
+			strscpy(type_info->str,
+				node_str(type_info->id),
+				PROV_TYPE_STR_MAX_LEN);
+		else
+			type_info->id = node_id(type_info->str);
+	}
+	if (copy_to_user(buf, type_info, sizeof(struct prov_type)))
+		rc = -EAGAIN;
+	kfree(type_info);
+	return rc;
+}
+declare_file_operations(prov_type_ops, no_write, prov_read_prov_type);
+
+static ssize_t prov_read_version(struct file *filp, char __user *buf,
+				 size_t count, loff_t *ppos)
+{
+	size_t len = strnlen(CAMFLOW_VERSION_STR, 32);
+
+	if (count < len)
+		return -ENOMEM;
+	if (copy_to_user(buf, CAMFLOW_VERSION_STR, len))
+		return -EAGAIN;
+	return len;
+}
+declare_file_operations(prov_version, no_write, prov_read_version);
+
+static ssize_t prov_read_commit(struct file *filp, char __user *buf,
+				size_t count, loff_t *ppos)
+{
+	size_t len = strnlen(CAMFLOW_COMMIT, PROV_COMMIT_MAX_LENGTH);
+
+	if (count < len)
+		return -ENOMEM;
+	if (copy_to_user(buf, CAMFLOW_COMMIT, len))
+		return -EAGAIN;
+	return len;
+}
+declare_file_operations(prov_commit, no_write, prov_read_commit);
+
+
+spinlock_t lock_epoch;
+
+static ssize_t prov_write_epoch(struct file *file, const char __user *buf,
+				size_t count, loff_t *ppos)
+{
+	uint32_t *old_epoch;
+	uint32_t *new_epoch;
+
+	new_epoch = kmalloc(sizeof(uint32_t), GFP_KERNEL);
+
+	spin_lock(&lock_epoch);
+	old_epoch = rcu_dereference_protected(epoch, lockdep_is_held(&lock_epoch));
+	*new_epoch = *old_epoch + 1;
+	rcu_assign_pointer(epoch, new_epoch);
+	spin_unlock(&lock_epoch);
+	synchronize_rcu();
+
+	kfree(old_epoch);
+
+	pr_info("Provenance: epoch changed to %d.", *new_epoch);
+	return count;
+}
+declare_file_operations(prov_epoch_ops, prov_write_epoch, no_read);
+
+static ssize_t prov_read_dropped(struct file *filp, char __user *buf,
+				 size_t count, loff_t *ppos)
+{
+	struct dropped drop;
+
+	if (count < sizeof(struct dropped))
+		return -ENOMEM;
+
+	drop.s = atomic64_read(&prov_drop);
+
+	if (copy_to_user(buf, &drop, sizeof(struct dropped)))
+		return -EAGAIN;
+	return sizeof(struct dropped);
+}
+declare_file_operations(prov_dropped, no_write, prov_read_dropped);
+
+#define prov_create_file(name, perm, fun_ptr)					      \
+	do {									      \
+		dentry = securityfs_create_file(name, perm, prov_dir, NULL, fun_ptr); \
+		provenance_mark_as_opaque_dentry(dentry);			      \
+	} while (0)
+
+static int __init init_prov_fs(void)
+{
+	struct dentry *prov_dir;
+	struct dentry *dentry;
+
+
+	spin_lock_init(&lock_epoch);
+
+	prov_dir = securityfs_create_dir("provenance", NULL);
+	prov_create_file("enable", 0644, &prov_enable_ops);
+	prov_create_file("all", 0644, &prov_all_ops);
+	prov_create_file("written", 0444, &prov_written_ops);
+	prov_create_file("compress_node", 0644, &prov_compress_node_ops);
+	prov_create_file("compress_edge", 0644, &prov_compress_edge_ops);
+	prov_create_file("node", 0666, &prov_node_ops);
+	prov_create_file("relation", 0666, &prov_relation_ops);
+	prov_create_file("self", 0666, &prov_self_ops);
+	prov_create_file("machine_id", 0444, &prov_machine_id_ops);
+	prov_create_file("boot_id", 0444, &prov_boot_id_ops);
+	prov_create_file("node_filter", 0644, &prov_node_filter_ops);
+	prov_create_file("derived_filter", 0644, &prov_derived_filter_ops);
+	prov_create_file("generated_filter", 0644, &prov_generated_filter_ops);
+	prov_create_file("used_filter", 0644, &prov_used_filter_ops);
+	prov_create_file("informed_filter", 0644, &prov_informed_filter_ops);
+	prov_create_file("propagate_node_filter", 0644,
+			 &prov_propagate_node_filter_ops);
+	prov_create_file("propagate_derived_filter", 0644,
+			 &prov_propagate_derived_filter_ops);
+	prov_create_file("propagate_generated_filter", 0644,
+			 &prov_propagate_generated_filter_ops);
+	prov_create_file("propagate_used_filter", 0644,
+			 &prov_propagate_used_filter_ops);
+	prov_create_file("propagate_informed_filter", 0644,
+			 &prov_propagate_informed_filter_ops);
+	prov_create_file("flush", 0600, &prov_flush_ops);
+	prov_create_file("process", 0644, &prov_process_ops);
+	prov_create_file("ipv4_ingress", 0644, &prov_ipv4_ingress_filter_ops);
+	prov_create_file("ipv4_egress", 0644, &prov_ipv4_egress_filter_ops);
+	prov_create_file("secctx", 0644, &prov_secctx_ops);
+	prov_create_file("secctx_filter", 0644, &prov_secctx_filter_ops);
+	prov_create_file("ns", 0644, &prov_ns_filter_ops);
+	prov_create_file("log", 0666, &prov_log_ops);
+	prov_create_file("logp", 0666, &prov_logp_ops);
+	prov_create_file("policy_hash", 0444, &prov_policy_hash_ops);
+	prov_create_file("uid", 0644, &prov_uid_filter_ops);
+	prov_create_file("gid", 0644, &prov_gid_filter_ops);
+	prov_create_file("type", 0444, &prov_type_ops);
+	prov_create_file("version", 0444, &prov_version);
+	prov_create_file("commit", 0444, &prov_commit);
+	prov_create_file("duplicate", 0644, &prov_duplicate_ops);
+	prov_create_file("epoch", 0644, &prov_epoch_ops);
+	prov_create_file("dropped", 0444, &prov_dropped);
+	pr_info("Provenance: fs ready.\n");
+	return 0;
+}
+fs_initcall(init_prov_fs);
diff --git a/security/provenance/hooks.c b/security/provenance/hooks.c
new file mode 100644
index 000000000..30f567a76
--- /dev/null
+++ b/security/provenance/hooks.c
@@ -0,0 +1,3237 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <linux/slab.h>
+#include <linux/lsm_hooks.h>
+#include <linux/msg.h>
+#include <net/sock.h>
+#include <net/af_unix.h>
+#include <linux/binfmts.h>
+#include <linux/random.h>
+#include <linux/xattr.h>
+#include <linux/file.h>
+#include <linux/ptrace.h>
+#include <linux/workqueue.h>
+
+#include "provenance.h"
+#include "provenance_record.h"
+#include "provenance_net.h"
+#include "provenance_inode.h"
+#include "provenance_task.h"
+#include "provenance_machine.h"
+#include "memcpy_ss.h"
+
+#ifdef CONFIG_SECURITY_PROVENANCE_PERSISTENCE
+// If provenance is set to be persistant (saved between reboots).
+struct save_work {
+	struct work_struct work;
+	struct dentry *dentry;
+};
+
+/*!
+ * @brief Helper function for queue_save_provenance function.
+ *
+ * Calls save_provenance function to persist provenance.
+ *
+ */
+static void __do_prov_save(struct work_struct *pwork)
+{
+	struct save_work *w = container_of(pwork, struct save_work, work);
+	struct dentry *dentry = w->dentry;
+
+	if (!dentry)
+		goto free_work;
+	save_provenance(dentry);
+free_work:
+	kfree(w);
+}
+
+static struct workqueue_struct *provq __ro_after_init;
+
+/*!
+ * @brief Create workqueue to persist provenance.
+ */
+static inline void queue_save_provenance(struct provenance *provenance,
+					 struct dentry *dentry)
+{
+	struct save_work *work;
+
+	if (!provq)
+		return;
+	if (!provenance_is_initialized(prov_elt(provenance))
+	    || provenance_is_saved(prov_elt(provenance)))
+		return;
+	work = kmalloc(sizeof(struct save_work), GFP_ATOMIC);
+	if (!work)
+		return;
+	work->dentry = dentry;
+	INIT_WORK(&work->work, __do_prov_save);
+	queue_work(provq, &work->work);
+}
+#else
+static inline void queue_save_provenance(struct provenance *provenance,
+					 struct dentry *dentry)
+{
+}
+#endif
+
+/*!
+ * @brief Record provenance when task_alloc is triggered.
+ *
+ * Record provenance relation RL_PROC_READ (by calling "uses_two" function)
+ * and RL_CLONE (by calling "informs" function).
+ * We create a ACT_TASK node for the newly allocated task.
+ * Since @cred is shared by all threads, we use @cred to save process's
+ * provenance, and @task to save provenance of each thread.
+ * @param task The task being allocated.
+ * @param clone_flags The flags indicating what should be shared.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static int provenance_task_alloc(struct task_struct *task,
+				 unsigned long clone_flags)
+{
+	struct provenance *ntprov = provenance_task(task);
+	struct cred *cred;
+	struct task_struct *t = current;
+	struct provenance *tprov;
+	struct provenance *cprov;
+
+	init_provenance_struct(ACT_TASK, ntprov);
+	update_task_namespaces(task, ntprov);
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	if (t != NULL) {
+		cred = (__force struct cred *)t->real_cred;
+		tprov = provenance_task(t);
+		if (cred != NULL) {
+			cprov = provenance_cred(cred);
+			if (tprov != NULL &&  cprov != NULL) {
+				record_task_name(current, cprov);
+				uses_two(RL_PROC_READ, cprov, tprov, NULL, clone_flags);
+				informs(RL_CLONE, tprov, ntprov, NULL, clone_flags);
+			}
+		}
+	}
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when task_free hook is triggered.
+ *
+ * Record provenance relation RL_TERMINATE_TASK by calling function
+ * "record_terminate".
+ * @param task The task in question (i.e., to be free).
+ *
+ */
+static void provenance_task_free(struct task_struct *task)
+{
+	struct provenance *tprov;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	tprov = provenance_task(task);
+
+	if (tprov)
+		record_terminate(RL_TERMINATE_TASK, tprov);
+}
+
+/*!
+ * @brief Initialize the security for the initial task.
+ *
+ * This is the initial task when provenance capture is initialized.
+ * We create a ENT_PROC provenance node, and set the UID and GID of the
+ * provenance node information from the current process's credential.
+ * Current process's cred struct's provenance pointer now points to
+ * the provenance node.
+ *
+ */
+static void task_init_provenance(void)
+{
+	struct cred *cred = (__force struct cred *)current->real_cred;
+	struct provenance *cprov = provenance_cred(cred);
+	struct provenance *tprov = provenance_task(current);
+
+	if (!cprov || !tprov)
+		panic("Provenance:  Failed to initialize initial task.\n");
+	node_uid(prov_elt(cprov)) = __kuid_val(cred->euid);
+	node_gid(prov_elt(cprov)) = __kgid_val(cred->egid);
+
+	prov_elt(tprov)->task_info.pid = task_pid_nr(current);
+	prov_elt(tprov)->task_info.vpid = task_pid_vnr(current);
+}
+
+static int provenance_ptrace_access_check(struct task_struct *child,
+					  unsigned int mode)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *ccprov;
+	struct provenance *ctprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(false);
+	ccprov = provenance_cred_from_task(child);
+	ctprov = provenance_task(child);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	if (mode & PTRACE_MODE_READ) {
+		rc = informs(RL_PTRACE_READ_TASK, ctprov, tprov, NULL, mode);
+		if (rc < 0)
+			goto out;
+		if (ccprov != cprov) { // if it is too sepearate processes
+			rc = uses(RL_PTRACE_READ, ccprov, tprov, cprov, NULL, 0);
+			if (rc < 0)
+				goto out;
+		}
+	}
+	if (mode & PTRACE_MODE_ATTACH) {
+		if (ccprov != cprov) { // if it is too sepearate processes
+			rc = generates(RL_PTRACE_ATTACH, cprov, tprov, ccprov, NULL, 0);
+			if (rc < 0)
+				goto out;
+		}
+		rc = informs(RL_PTRACE_ATTACH_TASK, tprov, ctprov, NULL, mode);
+	}
+
+out:
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+static int provenance_ptrace_traceme(struct task_struct *parent)
+{
+	struct provenance *tprov = get_task_provenance(false);
+	struct provenance *ptprov = provenance_task(parent);
+
+	return informs(RL_PTRACE_TRACEME, tprov, ptprov, NULL, 0);
+}
+
+/*!
+ * @brief Record provenance when cred_alloc_blank hook is triggered.
+ *
+ * This hook is triggered when allocating sufficient memory and attaching to
+ * @cred such that cred_transfer() will not get ENOMEM.
+ * Therefore, no information flow occurred.
+ * We simply create a ENT_PROC provenance node and associate the provenance
+ * entry to the newly allocated @cred.
+ * Set the proper UID and GID of the node based on the information from @cred.
+ * @param cred Points to the new credentials.
+ * @param gfp Indicates the atomicity of any memory allocations.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated for
+ * the new provenance entry. Other error codes unknown.\
+ *
+ */
+static int provenance_cred_alloc_blank(struct cred *cred, gfp_t gfp)
+{
+	struct provenance *prov = provenance_cred(cred);
+
+	if (!prov)
+		return -ENOMEM;
+
+	node_uid(prov_elt(prov)) = __kuid_val(cred->euid);
+	node_gid(prov_elt(prov)) = __kgid_val(cred->egid);
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when cred_free hook is triggered.
+ *
+ * This hook is triggered when deallocating and clearing the cred->security
+ * field in a set of credentials. Record provenance relation RL_TERMINATE_PROC
+ * by calling "record_terminate" function.
+ * @param cred Points to the credentials to be freed.
+ *
+ */
+static void provenance_cred_free(struct cred *cred)
+{
+	struct provenance *cprov;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	cprov = provenance_cred(cred);
+
+	if (cprov)
+		record_terminate(RL_TERMINATE_PROC, cprov);
+}
+
+/*!
+ * @brief Record provenance when cred_prepare hook is triggered.
+ *
+ * This hook is triggered when preparing a new set of credentials by copying
+ * the data from the old set.
+ * Record provenance relation RL_CLONE_MEM by calling "generates" function.
+ * We create a new ENT_PROC provenance entry for the new cred.
+ * Information flows from old cred to the process that is preparing the new
+ * cred.
+ * @param new Points to the new credentials.
+ * @param old Points to the original credentials.
+ * @param gfp Indicates the atomicity of any memory allocations.
+ * @return 0 if no error occured. Other error codes unknown.
+ *
+ */
+static int provenance_cred_prepare(struct cred *new,
+				   const struct cred *old,
+				   gfp_t gfp)
+{
+	struct provenance *old_prov = provenance_cred(old);
+	struct provenance *nprov = provenance_cred(new);
+	struct provenance *tprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!nprov)
+		return -ENOMEM;
+	init_provenance_struct(ENT_PROC, nprov);
+	node_uid(prov_elt(nprov)) = __kuid_val(new->euid);
+	node_gid(prov_elt(nprov)) = __kgid_val(new->egid);
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	spin_lock_irqsave_nested(prov_lock(old_prov), irqflags, PROVENANCE_LOCK_PROC);
+	if (current != NULL) {
+		tprov = provenance_task(current);
+		if (tprov != NULL)
+			rc = generates(RL_CLONE_MEM, old_prov, tprov, nprov, NULL, 0);
+	}
+	spin_unlock_irqrestore(prov_lock(old_prov), irqflags);
+	record_task_name(current, nprov);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when cred_transfer hook is triggered.
+ *
+ * This hook is triggered when transfering data from original creds to new creds.
+ * We simply update the new creds provenance entry to that of the old creds.
+ * Information flow between cred's is captured when provenance_cred_prepare
+ * function is called.
+ * @param new Points to the new credentials.
+ * @param old Points to the original credentials.
+ *
+ */
+static void provenance_cred_transfer(struct cred *new, const struct cred *old)
+{
+	// this is like this in SELinux, looks weird with 5.1.x changes,
+	// but let it be for now
+	const struct provenance *old_prov = provenance_cred(old);
+	struct provenance *cprov = provenance_cred(new);
+
+	*cprov =  *old_prov;
+}
+
+/*!
+ * @brief Record provenance when task_fix_setuid hook is triggered.
+ *
+ * This hook is triggered when updating the module's state after setting one or
+ * more of the user
+ * identity attributes of the current process.
+ * The @flags parameter indicates which of the set*uid system calls invoked this
+ * hook.
+ * If @new is the set of credentials that will be installed,
+ * modifications should be made to this rather than to @current->cred.
+ * Information flows from @old to current process and then eventually flows to
+ * @new (since modification should be made to @new instead of @current->cred).
+ * Record provenance relation RL_SETUID by calling "generates" function.
+ * @param old The set of credentials that are being replaced.
+ * @param flags One of the LSM_SETID_* values.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static int provenance_task_fix_setuid(struct cred *new,
+				      const struct cred *old,
+				      int flags)
+{
+	struct provenance *old_prov;
+	struct provenance *nprov;
+	struct provenance *tprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	old_prov = provenance_cred(old);
+	nprov = provenance_cred(new);
+	tprov = get_task_provenance(true);
+
+	spin_lock_irqsave_nested(prov_lock(old_prov), irqflags, PROVENANCE_LOCK_PROC);
+	rc = generates(RL_SETUID, old_prov, tprov, nprov, NULL, flags);
+	spin_unlock_irqrestore(prov_lock(old_prov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when task_setpgid hook is triggered.
+ *
+ * This hooks is triggered when checking permission before setting the process
+ * group identifier of the process @p to @pgid.
+ * @cprov is the cred provenance of the @current process, and @tprov is the
+ * task provenance of the @current process.
+ * During "get_cred_provenance" and "get_task_provenance" functions, their
+ * provenances are updated too.
+ * We update process @p's cred provenance's pgid info as required by the trigger
+ * of the hook.
+ * Record provenance relation RL_SETGID by calling "generates" function.
+ * Information flows from cred of the @current process, which sets the @pgid,
+ * to the current process, and eventually to the process @p whose @pgid is
+ * updated.
+ * @param p The task_struct for process being modified.
+ * @param pgid The new pgid.
+ * @return 0 if permission is granted. Other error codes unknown.
+ *
+ */
+static int provenance_task_setpgid(struct task_struct *p, pid_t pgid)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *nprov;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	nprov = provenance_cred_from_task(p);
+
+	prov_elt(nprov)->proc_info.gid = pgid;
+	rc = generates(RL_SETGID, cprov, tprov, nprov, NULL, 0);
+	return rc;
+}
+
+static int provenance_task_getpgid(struct task_struct *p)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *nprov;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	nprov = provenance_cred_from_task(p);
+
+	rc = uses(RL_GETGID, nprov, tprov, cprov, NULL, 0);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when task_kill hook is triggered.
+ *
+ * This hook is triggered when checking permission before sending signal @sig
+ * to @p.
+ * @info can be NULL, the constant 1, or a pointer to a siginfo structure.
+ * If @info is 1 or SI_FROMKERNEL(info) is true, then the signal should be
+ * viewed as coming from the kernel and should typically be permitted.
+ * SIGIO signals are handled separately by the send_sigiotask hook in
+ * file_security_ops.
+ * No information flow happens in this case. Simply return 0.
+ * @param p The task_struct for process.
+ * @param info The signal information.
+ * @param sig The signal value.
+ * @param secid The sid of the process where the signal originated.
+ * @return 0 if permission is granted.
+ *
+ */
+static int provenance_task_kill(struct task_struct *p, struct kernel_siginfo *info,
+				int sig, const struct cred *cred)
+{
+	// TODO
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when inode_alloc_security hook is triggered.
+ *
+ * This hook is triggered when allocating and attaching a security structure to
+ * @inode->i_security.
+ * The i_security field is initialized to NULL when the inode structure is
+ * allocated.
+ * When i_security field is initialized, we also initialize i_provenance field
+ * of the inode.
+ * Therefore, we create a new ENT_INODE_UNKNOWN provenance entry.
+ * UUID information from @i_sb (superblock) is copied to the new inode's
+ * provenance entry.
+ * We then call function "refresh_inode_provenance" to obtain more information
+ * about the inode.
+ * No information flow occurs.
+ * @param inode The inode structure.
+ * @return 0 if operation was successful; -ENOMEM if no memory can be allocated
+ * for the new inode provenance entry. Other error codes unknown.
+ *
+ */
+static int provenance_inode_alloc_security(struct inode *inode)
+{
+	struct provenance *iprov = provenance_inode(inode);
+	struct provenance *sprov;
+
+	if (unlikely(!iprov))
+		return -ENOMEM;
+	init_provenance_struct(ENT_INODE_UNKNOWN, iprov);
+	sprov = provenance_superblock(inode->i_sb);
+	__memcpy_ss(prov_elt(iprov)->inode_info.sb_uuid, PROV_SBUUID_LEN,
+		    prov_elt(sprov)->sb_info.uuid, 16 * sizeof(uint8_t));
+	refresh_inode_provenance(inode, iprov);
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when inode_free_security hook is triggered.
+ *
+ * This hook is triggered when deallocating the inode security structure and
+ * set @inode->i_security to NULL.
+ * Record provenance relation RL_FREED by calling "record_terminate" function.
+ * Free kernel memory allocated for provenance entry of the inode in question.
+ * Set the provenance pointer in @inode to NULL.
+ * @param inode The inode structure whose security is to be freed.
+ *
+ */
+static void provenance_inode_free_security(struct inode *inode)
+{
+	struct provenance *iprov;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	iprov = provenance_inode(inode);
+
+	if (iprov)
+		record_terminate(RL_FREED, iprov);
+}
+
+/*!
+ * @brief Record provenance when inode_create hook is triggered.
+ *
+ * This hook is trigger when checking permission to create a regular file.
+ * Record provenance relation RL_INODE_CREATE by calling "generates" function.
+ * Information flows from current process's cred's to the process, and
+ * eventually to the parent's inode.
+ * @param dir Inode structure of the parent of the new file.
+ * @param dentry The dentry structure for the file to be created.
+ * @param mode The file mode of the file to be created.
+ * @return 0 if permission is granted; -ENOMEM if parent's inode's provenance
+ * entry is NULL. Other error codes unknown.
+ *
+ */
+static int provenance_inode_create(struct inode *dir,
+				   struct dentry *dentry,
+				   umode_t mode)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_inode_provenance(dir, true);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_DIR);
+	rc = generates(RL_INODE_CREATE, cprov, tprov, iprov, NULL, mode);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_permission hook is triggered.
+ *
+ * This hook is triggered when checking permission before accessing an inode.
+ * This hook is called by the existing Linux permission function,
+ * so a security module can use it to provide additional checking for existing
+ * Linux permission checks.
+ * Notice that this hook is called when a file is opened (as well as many other
+ * operations),
+ * whereas the file_security_ops permission hook is called when the actual
+ * read/write operations are performed.
+ * Depending on the permission specified in @mask,
+ * Zero or more relation may be recorded during this permission check.
+ * Note that "uses" function also generates provenance relation RL_PROC_WRITE.
+ * Information flows from @inode's provenance to the current process that
+ * attempts to access the inode, and eventually to the cred of the task.
+ * Provenance relation is not recorded if the inode to be access is private
+ * or if the inode's provenance entry does not exist.
+ * @param inode The inode structure to check.
+ * @param mask The permission mask.
+ * @return 0 if permission is granted; -ENOMEM if @inode's provenance does not
+ * exist. Other error codes unknown.
+ *
+ * @todo We ignore inode that are PRIVATE (i.e., IS_PRIVATE is true). Private
+ * inodes are FS internals and we ignore for now.
+ *
+ */
+static int provenance_inode_permission(struct inode *inode, int mask)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	if (!mask)
+		return 0;
+	if (unlikely(IS_PRIVATE(inode)))
+		return 0;
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_inode_provenance(inode, false);
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_PERM, iprov, tprov, cprov, NULL, mask);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_link hook is triggered.
+ *
+ * This hook is triggered when checking permission before creating a new hard
+ * link to a file.
+ * We obtain the provenance of current process and its cred, as well as
+ * provenance of inode or parent directory of new link.
+ * We also get the provenance of existing link to the file.
+ * Record two provenance relations RL_LINK by calling "generates" function.
+ * Information flows:
+ * 1. From cred of the current process to the process, and eventually to the
+ * inode of parent directory of new link, and,
+ * 2. From cred of the current process to the process, and eventually to the
+ * dentry of the existing link to the file, and
+ * 3. From the inode of parent directory of new link to the dentry of the
+ * existing link to the file.
+ * @param old_dentry The dentry structure for an existing link to the file.
+ * @parm dir The inode structure of the parent directory of the new link.
+ * @param new_dentry The dentry structure for the new link.
+ * @return 0 if permission is granted; -ENOMEM if either the dentry provenance
+ * of the existing link to the file or the inode provenance of the new parent
+ * directory of new link does not exist.
+ *
+ * @todo The information flow relations captured here is a bit weird. We need
+ * to double check the correctness.
+ */
+
+static int provenance_inode_link(struct dentry *old_dentry,
+				 struct inode *dir,
+				 struct dentry *new_dentry)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(old_dentry, true);
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_LINK, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	record_inode_name_from_dentry(new_dentry, iprov, true);
+	return rc;
+}
+
+/*
+ *	Check the permission to remove a hard link to a file.
+ *	@dir contains the inode structure of parent directory of the file.
+ *	@dentry contains the dentry structure for file to be unlinked.
+ *	Return 0 if permission is granted.
+ */
+static int provenance_inode_unlink(struct inode *dir, struct dentry *dentry)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_UNLINK, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*
+ * @inode_symlink:
+ *	Check the permission to create a symbolic link to a file.
+ *	@dir contains the inode structure of parent directory of the symbolic link.
+ *	@dentry contains the dentry structure of the symbolic link.
+ *	@old_name contains the pathname of file.
+ *	Return 0 if permission is granted.
+ */
+static int provenance_inode_symlink(struct inode *dir,
+				    struct dentry *dentry,
+				    const char *name)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+	if (!iprov)
+		return 0;  // do not touch!
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_SYMLINK, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	record_node_name(iprov, name, true);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_rename hook is triggered.
+ *
+ * This hook is triggered when checking for permission to rename a file or
+ * directory.
+ * Information flow is the same as in the "provenance_inode_link" function so
+ * we call this function.
+ * @param old_dir The inode structure for parent of the old link.
+ * @param old_dentry The dentry structure of the old link.
+ * @param new_dir The inode structure for parent of the new link.
+ * @param new_dentry The dentry structure of the new link.
+ * @return Error code is the same as in "provenance_inode_link" function.
+ *
+ */
+static int provenance_inode_rename(struct inode *old_dir,
+				   struct dentry *old_dentry,
+				   struct inode *new_dir,
+				   struct dentry *new_dentry)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(old_dentry, true);
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_RENAME, cprov, tprov, iprov, NULL, 0);
+	clear_name_recorded(prov_elt(iprov));
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	record_inode_name_from_dentry(new_dentry, iprov, true);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_setattr hook is triggered.
+ *
+ * This hooks is triggered when checking permission before setting file
+ * attributes.
+ * Note that the kernel call to notify_change is performed from several
+ * locations, whenever file attributes change (such as when a file is truncated,
+ * chown/chmod operations transferring disk quotas, etc).
+ * We create a new provenance node ENT_IATTR, and update its information based
+ * on @iattr.
+ * Record provenance relation RL_SETATTR by calling "generates" function.
+ * Record provenance relation RL_SETATTR_INODE by calling "derives" function.
+ * Information flows from cred of the current process to the process, and
+ * eventually to the inode attribute to set the attributes.
+ * Information also flows from inode attribute to the inode whose attributes
+ * are to be set.
+ * After relation is recorded, iattr provenance entry is freed (i.e., memory
+ * deallocated).
+ * We also persistant the inode's provenance.
+ * @param dentry The dentry structure for the file.
+ * @param attr The iattr structure containing the new file attributes.
+ * @return 0 if permission is granted; -ENOMEM if inode provenance of the file
+ * is NULL; -ENOMEM if no memory can be allocated for a new ENT_IATTR provenance
+ * entry. Other error codes unknown.
+ *
+ */
+static int provenance_inode_setattr(struct dentry *dentry, struct iattr *iattr)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	struct provenance *iattrprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+	if (!iprov)
+		return -ENOMEM;
+	iattrprov = alloc_provenance(ENT_IATTR, GFP_KERNEL);
+	if (!iattrprov)
+		return -ENOMEM;
+
+	prov_elt(iattrprov)->iattr_info.valid = iattr->ia_valid;
+	prov_elt(iattrprov)->iattr_info.mode = iattr->ia_mode;
+	node_uid(prov_elt(iattrprov)) = __kuid_val(iattr->ia_uid);
+	node_gid(prov_elt(iattrprov)) = __kgid_val(iattr->ia_gid);
+	prov_elt(iattrprov)->iattr_info.size = iattr->ia_size;
+	prov_elt(iattrprov)->iattr_info.atime = iattr->ia_atime.tv_sec;
+	prov_elt(iattrprov)->iattr_info.mtime = iattr->ia_mtime.tv_sec;
+	prov_elt(iattrprov)->iattr_info.ctime = iattr->ia_ctime.tv_sec;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_SETATTR, cprov, tprov, iattrprov, NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = derives(RL_SETATTR_INODE, iattrprov, iprov, NULL, 0);
+out:
+	queue_save_provenance(iprov, dentry);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	free_provenance(iattrprov);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_getattr hook is triggered.
+ *
+ * This hook is triggered when checking permission before obtaining file
+ * attributes.
+ * Record provenance relation RL_GETATTR by calling "uses" function.
+ * Information flows from the inode of the file to the calling process, and
+ * eventually to the process's cred.
+ * @param path The path structure for the file.
+ * @return 0 if permission is granted; -ENOMEM if the provenance entry of the
+ * file is NULL. Other error codes unknown.
+ *
+ */
+static int provenance_inode_getattr(const struct path *path)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(path->dentry, true);
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_GETATTR, iprov, tprov, cprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_readlink hook is triggered.
+ *
+ * This hook is triggered when checking the permission to read the symbolic
+ * link.
+ * Record provenance relation RL_READ_LINK by calling "uses" function.
+ * Information flows from the link file to the calling process, and eventually
+ * to its cred.
+ * @param dentry The dentry structure for the file link.
+ * @return 0 if permission is granted; -ENOMEM if the link file's provenance
+ * entry is NULL. Other error codes unknown.
+ *
+ */
+static int provenance_inode_readlink(struct dentry *dentry)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_READ_LINK, iprov, tprov, cprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Setting provenance extended attribute for an inode.
+
+ * The provenance extended attributes are set for an inode only if the @name of
+ * xattr is matched to be XATTR_NAME_PROVENANCE.
+ * @param dentry The dentry struct whose inode's provenance xattr is to be set.
+ * @param name Must be XATTR_NAME_PROVENANCE to set the xattr.
+ * @param value Setting of the provenance xattr.
+ * @param size Must be the size of provenance entry.
+ * @param flags The operational flags.
+ * @return 0 if no error occurred; -ENOMEM if size does not match. Other error
+ * codes unknown.
+ *
+ */
+static int provenance_inode_setxattr(struct user_namespace *mnt_userns,
+				     struct dentry *dentry,
+				     const char *name,
+				     const void *value,
+				     size_t size,
+				     int flags)
+{
+	struct provenance *prov;
+	union prov_elt *setting;
+
+	if (strcmp(name, XATTR_NAME_PROVENANCE) == 0) { // Provenance xattr
+		if (size != sizeof(union prov_elt))
+			return -ENOMEM;
+		prov = get_dentry_provenance(dentry, false);
+		setting = (union prov_elt *)value;
+
+		if (provenance_is_tracked(setting))
+			set_tracked(prov_elt(prov));
+		else
+			clear_tracked(prov_elt(prov));
+
+		if (provenance_is_opaque(setting))
+			set_opaque(prov_elt(prov));
+		else
+			clear_opaque(prov_elt(prov));
+
+		if (provenance_does_propagate(setting))
+			set_propagate(prov_elt(prov));
+		else
+			clear_propagate(prov_elt(prov));
+
+		provenance_taint_merge(prov_taint(prov_elt(prov)), prov_taint(setting));
+	}
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when inode_post_setxattr hook is triggered.
+ *
+ * This hook is triggered when updating inode security field after successful
+ * setxattr operation.
+ * The relations are recorded through "record_write_xattr" function defined in
+ * provenance_inode.h file.
+ * RL_SETXATTR is one of the relations to be recorded.
+ * The relations may not be recorded for the following reasons:
+ * 1. The name of the extended attribute is provenance (do not capture
+ * provenance of CamFlow provenance ops), or
+ * 2. inode provenance entry is NULL.
+ * @param dentry The dentry structure for the file.
+ * @param name The name of the extended attribute.
+ * @param value The value of that attribute.
+ * @param size The size of the value.
+ * @param flags The operational flags.
+ *
+ */
+static void provenance_inode_post_setxattr(struct dentry *dentry,
+					   const char *name,
+					   const void *value,
+					   size_t size,
+					   int flags)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	if (strcmp(name, XATTR_NAME_PROVENANCE) == 0)
+		return;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+	if (!iprov)
+		return;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	record_write_xattr(RL_SETXATTR, iprov, tprov, cprov, name, value, size, flags);
+	queue_save_provenance(iprov, dentry);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+}
+
+/*!
+ * @brief Record provenance when inode_getxattr hook is triggered.
+ *
+ * This hook is triggered when checking permission before obtaining the extended
+ * attributes.
+ * The relations are recorded through "record_read_xattr" function defined in
+ * provenance_inode.h file.
+ * The relations may not be recorded for the following reasons:
+ * 1. The name of the extended attribute is provenance (do not capture
+ * provenance of CamFlow provenance ops), or
+ * 2. inode provenance entry is NULL.
+ * @param dentry The dentry structure for the file.
+ * @param name The name of the extended attribute.
+ * @return 0 if no error occurred; -ENOMEM if inode provenance is NULL; other
+ * error codes inherited from "record_read_xattr" function.
+ *
+ */
+static int provenance_inode_getxattr(struct dentry *dentry, const char *name)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	int rc = 0;
+	unsigned long irqflags;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	if (strcmp(name, XATTR_NAME_PROVENANCE) == 0)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = record_read_xattr(cprov, tprov, iprov, name);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_listxattr hook is triggered.
+ *
+ * This hook is triggered when checking permission before obtaining the list of
+ * extended attribute names for @dentry.
+ * Record provenance relation RL_LSTXATTR by calling "uses" function.
+ * Information flows from inode (whose xattrs are of interests) to calling task
+ * process, and eventually to its cred.
+ * The relation may not be recorded if inode provenance entry is NULL.
+ * @param dentry The dentry structure for the file.
+ * @return 0 if no error occurred; -ENOMEM if inode provenance is NULL; other
+ * error codes inherited from "uses" function.
+ *
+ */
+static int provenance_inode_listxattr(struct dentry *dentry)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_LSTXATTR, iprov, tprov, cprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when inode_removexattr hook is triggered.
+ *
+ * This hook is triggered when checking permission before removing the extended
+ * attribute identified by @name for @dentry.
+ * The relations are recorded through "record_write_xattr" function defined in
+ * provenance_inode.h file.
+ * RL_RMVXATTR is one of the relations to be recorded.
+ * The relations may not be recorded for the following reasons:
+ * 1. The name of the extended attribute is provenance (do not capture
+ * provenance of CamFlow provenance ops), or
+ * 2. inode provenance entry is NULL.
+ * @param dentry The dentry structure for the file.
+ * @param name The name of the extended attribute.
+ *
+ */
+static int provenance_inode_removexattr(struct user_namespace *mnt_userns,
+					struct dentry *dentry, const char *name)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_dentry_provenance(dentry, true);
+
+	if (strcmp(name, XATTR_NAME_PROVENANCE) == 0)
+		return -EPERM;
+
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = record_write_xattr(RL_RMVXATTR, iprov, tprov, cprov, name, NULL, 0, 0);
+	queue_save_provenance(iprov, dentry);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Enabling checking provenance of an inode from user space.
+ *
+ * This hook allows us to retrieve a copy of the extended attribute
+ * representation of the security label
+ * associated with @name for @inode via @buffer.
+ * Note that @name is the remainder of the attribute name after the security
+ * prefix has been removed.
+ * The provenance of the inode, if exists, is stored in @buffer.
+ * @param inode The inode whose provenance is to be retrieved.
+ * @param name The name of extended attribute, which must be provenance
+ * (or an error will be thrown).
+ * @param buffer The buffer to hold the provenance of the inode.
+ * @param alloc Specify if the call should return a value via the buffer or just
+ * the value length.
+ * @return Size of the buffer on success, which in this case is the size of the
+ * provenance entry; -ENOMEM if inode provenance is NULL; -EOPNOTSUPP if name of
+ * the attribute is not provenance.
+ *
+ */
+static int provenance_inode_getsecurity(struct user_namespace *mnt_userns,
+					struct inode *inode,
+					const char *name,
+					void **buffer,
+					bool alloc)
+{
+	struct provenance *iprov = get_inode_provenance(inode, false);
+
+	if (unlikely(!iprov))
+		return -ENOMEM;
+	if (strcmp(name, XATTR_PROVENANCE_SUFFIX))
+		return -EOPNOTSUPP;
+	if (!alloc)
+		goto out;
+	*buffer = kmalloc(sizeof(union prov_elt), GFP_KERNEL);
+	__memcpy_ss(*buffer, sizeof(union prov_elt),
+		    prov_elt(iprov), sizeof(union prov_elt));
+out:
+	return sizeof(union prov_elt);
+}
+
+/*!
+ * @brief Copy the name of the provenance extended attribute to buffer.
+ *
+ * This function copies the extended attribute of provenance associated with
+ * @inode into @buffer.
+ * The maximum size of @buffer is specified by @buffer_size.
+ * @buffer may be NULL to request the size of the buffer required.
+ * If @buffer is not NULL and the length of the provenance attribute name is
+ * smaller than @buffer_size,
+ * then the buffer will contain the name of the provenance attribute.
+ * @param inode The inode whose provenance extended attribute is to be
+ * retrieved.
+ * @param buffer The buffer that holds that attribute name.
+ * @param buffer_size The maximum size of the buffer.
+ * @returns Number of bytes used/required on success.
+ *
+ */
+static int provenance_inode_listsecurity(struct inode *inode,
+					 char *buffer,
+					 size_t buffer_size)
+{
+	const int len = sizeof(XATTR_NAME_PROVENANCE);
+
+	if (buffer && len <= buffer_size)
+		__memcpy_ss(buffer, buffer_size, XATTR_NAME_PROVENANCE, len);
+	return len;
+}
+
+/*!
+ * @brief Record provenance when file_permission hook is triggered.
+ *
+ * This hook is triggered when checking file permissions before accessing an
+ * open file.
+ * This hook is called by various operations that read or write files.
+ * A security module can use this hook to perform additional checking on these
+ * operations,
+ * e.g., to revalidate permissions on use to support privilege bracketing or
+ * policy changes.
+ * Notice that this hook is used when the actual read/write operations are
+ * performed, whereas the inode_security_ops hook is called when a file is
+ * opened (as well as many other operations).
+ * Caveat:
+ * Although this hook can be used to revalidate permissions for various system
+ * call operations that read or write files,
+ * it does not address the revalidation of permissions for memory-mapped files.
+ * Security modules must handle this separately if they need such revalidation.
+ * Depending on the type of the @file (e.g., a regular file or a directory),
+ * and the requested permission from @mask,
+ * record various provenance relations, including:
+ * RL_WRITE, RL_READ, RL_SEARCH, RL_SND, RL_RCV, RL_EXEC.
+ * @param file The file structure being accessed.
+ * @param mask The requested permissions.
+ * @return 0 if permission is granted; -ENOMEM if inode provenance is NULL.
+ * Other error codes unknown.
+ *
+ */
+static int provenance_file_permission(struct file *file, int mask)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	struct inode *inode;
+	uint32_t perms;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+
+	if (!iprov)
+		return -ENOMEM;
+
+	inode = file_inode(file);
+	perms = file_mask_to_perms(inode->i_mode, mask);
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	if (is_inode_dir(inode)) {
+		if ((perms & (DIR__WRITE)) != 0) {
+			rc = generates(RL_WRITE, cprov, tprov, iprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+		if ((perms & (DIR__READ)) != 0) {
+			rc = uses(RL_READ, iprov, tprov, cprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+		if ((perms & (DIR__SEARCH)) != 0) {
+			rc = uses(RL_SEARCH, iprov, tprov, cprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+	} else if (is_inode_socket(inode)) {
+		if ((perms & (FILE__WRITE | FILE__APPEND)) != 0) {
+			rc = generates(RL_SND, cprov, tprov, iprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+		if ((perms & (FILE__READ)) != 0) {
+			rc = uses(RL_RCV, iprov, tprov, cprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+	} else {
+		if ((perms & (FILE__WRITE | FILE__APPEND)) != 0) {
+			rc = generates(RL_WRITE, cprov, tprov, iprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+		if ((perms & (FILE__READ)) != 0) {
+			rc = uses(RL_READ, iprov, tprov, cprov, file, mask);
+			if (rc < 0)
+				goto out;
+		}
+		if ((perms & (FILE__EXECUTE)) != 0) {
+			if (provenance_is_opaque(prov_elt(iprov)))
+				set_opaque(prov_elt(cprov));
+			else
+				rc = derives(RL_EXEC, iprov, cprov, file, mask);
+		}
+	}
+out:
+	queue_save_provenance(iprov, file_dentry(file));
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+/*!
+ * @brief Record provenance when file_splice_pipe_to_pipe hook is triggered
+ * (splice system call).
+ *
+ * Record provenance relation RL_SPLICE by calling "derives" function.
+ * Information flows from one pipe @in to another pipe @out.
+ * Fail if either file inode provenance does not exist.
+ * @param in Information source file.
+ * @param out Information drain file.
+ * @return 0 if no error occurred; -ENOMEM if either end of the file provenance
+ * entry is NULL; Other error code inherited from derives function.
+ *
+ */
+static int provenance_file_splice_pipe_to_pipe(struct file *in,
+					       struct file *out)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *inprov;
+	struct provenance *outprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	inprov = get_file_provenance(in, true);
+	outprov = get_file_provenance(out, true);
+
+	if (!inprov || !outprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(inprov), irqflags, PROVENANCE_LOCK_INODE);
+	spin_lock_nested(prov_lock(outprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_SPLICE_IN, inprov, tprov, cprov, NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = generates(RL_SPLICE_OUT, cprov, tprov, outprov, NULL, 0);
+out:
+	spin_unlock(prov_lock(outprov));
+	spin_unlock_irqrestore(prov_lock(inprov), irqflags);
+	return rc;
+}
+#endif
+
+static int provenance_kernel_read_file(struct file *file,
+				       enum kernel_read_file_id id,
+				       bool contents)
+{
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+
+	if (!iprov)   // not sure it could happen, ignore it for now
+		return 0;
+
+	spin_lock_irqsave_nested(prov_lock(iprov), irqflags, PROVENANCE_LOCK_INODE);
+	switch (id) {
+	case READING_UNKNOWN:
+		rc = record_influences_kernel(RL_LOAD_UNKNOWN, iprov, tprov, file);
+		break;
+	case READING_FIRMWARE:
+		rc = record_influences_kernel(RL_LOAD_FIRMWARE, iprov, tprov, file);
+		break;
+	case READING_MODULE:
+		rc = record_influences_kernel(RL_LOAD_MODULE, iprov, tprov, file);
+		break;
+	case READING_KEXEC_IMAGE:
+		rc = record_influences_kernel(RL_LOAD_KEXEC_IMAGE, iprov, tprov, file);
+		break;
+	case READING_KEXEC_INITRAMFS:
+		rc = record_influences_kernel(RL_LOAD_KEXEC_INITRAMFS, iprov, tprov, file);
+		break;
+	case READING_POLICY:
+		rc = record_influences_kernel(RL_LOAD_POLICY, iprov, tprov, file);
+		break;
+	case READING_X509_CERTIFICATE:
+		rc = record_influences_kernel(RL_LOAD_CERTIFICATE, iprov, tprov, file);
+		break;
+	default: // should not happen
+		rc = record_influences_kernel(RL_LOAD_UNDEFINED, iprov, tprov, file);
+		break;
+	}
+	spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when file_open hook is triggered.
+ *
+ * This hook is triggered when saving open-time permission checking state for
+ * later use upon file_permission,
+ * and rechecking access if anything has changed since inode_permission.
+ * Record provenance relation RL_OPEN by calling "uses" function.
+ * Information flows from inode of the file to be opened to the calling process,
+ * and eventually to its cred.
+ * @param file The file to be opened.
+ * @param cred Unused parameter.
+ * @return 0 if no error occurred; -ENOMEM if the file inode provenance entry is
+ * NULL; other error code inherited from uses function.
+ *
+ */
+static int provenance_file_open(struct file *file)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_OPEN, iprov, tprov, cprov, file, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when file_receive hook is triggered.
+ *
+ * This hook allows security modules to control the ability of a process to
+ * receive an open file descriptor via socket IPC.
+ * Record provenance relation RL_FILE_RCV by calling "uses" function.
+ * Information flows from inode of the file being received to the calling
+ * process, and eventually to its cred.
+ * @param file The file structure being received.
+ * @return 0 if permission is granted, no error occurred; -ENOMEM if the
+ * file inode provenance entry is NULL; Other error code inherited from uses
+ * function.
+ *
+ */
+static int provenance_file_receive(struct file *file)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_FILE_RCV, iprov, tprov, cprov, file, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*
+ *	Check permission before performing file locking operations.
+ *	Note: this hook mediates both flock and fcntl style locks.
+ *	@file contains the file structure.
+ *	@cmd contains the posix-translated lock operation to perform
+ *	(e.g. F_RDLCK, F_WRLCK).
+ *	Return 0 if permission is granted.
+ */
+static int provenance_file_lock(struct file *file, unsigned int cmd)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, false);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_FILE_LOCK, cprov, tprov, iprov, file, cmd);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*
+ *	process @tsk.  Note that this hook is sometimes called from interrupt.
+ *	Note that the fown_struct, @fown, is never outside the context of a
+ *	struct file, so the file structure (and associated security information)
+ *	can always be obtained:
+ *		container_of(fown, struct file, f_owner)
+ *	@tsk contains the structure of task receiving signal.
+ *	@fown contains the file owner information.
+ *	@sig is the signal that will be sent.  When 0, kernel sends SIGIO.
+ *	Return 0 if permission is granted.
+ */
+static int provenance_file_send_sigiotask(struct task_struct *task,
+					  struct fown_struct *fown, int signum)
+{
+	struct file *file;
+	struct provenance *iprov;
+	struct provenance *tprov;
+	struct provenance *cprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	file = container_of(fown, struct file, f_owner);
+	iprov = get_file_provenance(file, false);
+	tprov = provenance_task(task);
+	cprov = provenance_cred_from_task(task);
+
+	if (!iprov)
+		return -ENOMEM;
+	if (!signum)
+		signum = SIGIO;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = uses(RL_FILE_SIGIO, iprov, tprov, cprov, file, signum);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when mmap_file hook is triggered.
+ *
+ * This hook is triggered when checking permissions for a mmap operation.
+ * The @file may be NULL, e.g., if mapping anonymous memory.
+ * Provenance relation will not be recorded if:
+ * 1. The file is NULL, or
+ * 2. Failure occurred.
+ * If the mmap is shared (flag: MAP_SHARED or MAP_SHARED_VALIDATE),
+ * depending on the action allowed by the kernel,
+ * record provenance relation RL_MMAP.
+ * Information flows between the mmap file and calling process and its cred.
+ * The direction of the information flow depends on the action allowed.
+ * If the mmap is private (flag: MAP_PRIVATE)..
+ * @param file The file structure for file to map (may be NULL).
+ * @param reqprot The protection requested by the application.
+ * @param prot The protection that will be applied by the kernel.
+ * @param flags The operational flags.
+ * @return 0 if permission is granted and no error occurred; -ENOMEM if the
+ * original file inode provenance entry is NULL; Other error codes inherited
+ * from derives function.
+ *
+ */
+static int provenance_mmap_file(struct file *file,
+				unsigned long reqprot,
+				unsigned long prot,
+				unsigned long flags)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	if (unlikely(!file))
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	if (provenance_is_opaque(prov_elt(cprov)))
+		goto out;
+	if ((flags & MAP_TYPE) == MAP_SHARED
+	    || (flags & MAP_TYPE) == MAP_SHARED_VALIDATE)
+		rc = uses(RL_MMAP, iprov, tprov, cprov, file, prot);
+	else
+		rc = uses(RL_MMAP_PRIVATE, iprov, tprov, cprov, file, prot);
+out:
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+/*!
+ * @brief Record provenance when mmap_munmap hook is triggered.
+ *
+ * This hook is triggered when a file is unmmap'ed.
+ * We obtain the provenance entry of the mmap'ed file, and if it shows that the
+ * mmap'ed file is shared based on the flags,
+ * record provenance relation RL_MUNMAP by calling "derives" function.
+ * Information flows from cred of the process that unmmaps the file to the
+ * mmap'ed file.
+ * Note that if the file to be unmmap'ed is private, the provenance of the
+ * mmap'ed file is short-lived and thus no longer exists.
+ * @param mm Unused parameter.
+ * @param vma Virtual memory of the calling process.
+ * @param start Unused parameter.
+ * @param end Unused parameter.
+ *
+ */
+static void provenance_mmap_munmap(struct mm_struct *mm,
+				   struct vm_area_struct *vma,
+				   unsigned long start,
+				   unsigned long end)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	struct file *mmapf;
+	unsigned long irqflags;
+	vm_flags_t flags = vma->vm_flags;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	if (vm_mayshare(flags)) {       // It is a shared mmap.
+		mmapf = vma->vm_file;
+		if (mmapf) {
+			cprov = get_cred_provenance();
+			tprov = get_task_provenance(true);
+			iprov = get_file_provenance(mmapf, false);
+			spin_lock_irqsave_nested(prov_lock(cprov),
+						 irqflags, PROVENANCE_LOCK_PROC);
+			spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+			generates(RL_MUNMAP, cprov, tprov, iprov, mmapf, flags);
+			spin_unlock(prov_lock(iprov));
+			spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+		}
+	}
+}
+#endif
+
+/*!
+ * @brief Record provenance when file_ioctl hook is triggered.
+ *
+ * This hook is triggered when checking permission for an ioctl operation on
+ * @file.
+ * Note that @arg sometimes represents a user space pointer; in other cases, it
+ * may be a simple integer value.
+ * When @arg represents a user space pointer, it should never be used by the
+ * security module.
+ * Record provenance relation RL_WRITE_IOCTL by calling "generates" function
+ * and RL_READ_IOCTL by calling "uses" function.
+ * Information flows between the file and the calling process and its cred.
+ * At the end, we save @iprov provenance.
+ * @param file The file structure.
+ * @param cmd The operation to perform.
+ * @param arg The operational arguments.
+ * @return 0 if permission is granted or no error occurred; -ENOMEM if the file
+ * inode provenance entry is NULL; Other error code inherited from
+ * generates/uses function.
+ *
+ */
+static int provenance_file_ioctl(struct file *file,
+				 unsigned int cmd,
+				 unsigned long arg)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_file_provenance(file, true);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_WRITE_IOCTL, cprov, tprov, iprov, NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = uses(RL_READ_IOCTL, iprov, tprov, cprov, NULL, 0);
+out:
+	queue_save_provenance(iprov, file_dentry(file));
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/* msg */
+
+/*!
+ * @brief Record provenance when msg_msg_alloc_security hook is triggered.
+ *
+ * This hooks allocates and attaches a security structure to the msg->security
+ * field.
+ * The security field is initialized to NULL when the structure is first
+ * created.
+ * This function initializes and attaches a new provenance entry to the
+ * msg->provenance field.
+ * We create a new provenance node ENT_MSG and update the information in the
+ * provenance entry from @msg.
+ * Record provenance relation RL_MSG_CREATE by calling "generates" function.
+ * Information flows from cred of the calling process to the task, and
+ * eventually to the newly created msg node.
+ * @param msg The message structure to be modified.
+ * @return 0 if operation was successful and permission is granted; -ENOMEM if
+ * no memory can be allocated for the new provenance entry; other error codes
+ * inherited from generates function.
+ *
+ */
+static int provenance_msg_msg_alloc_security(struct msg_msg *msg)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *mprov = provenance_msg_msg(msg);
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!mprov)
+		return -ENOMEM;
+	init_provenance_struct(ENT_MSG, mprov);
+	prov_elt(mprov)->msg_msg_info.type = msg->m_type;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	rc = generates(RL_MSG_CREATE, cprov, tprov, mprov, NULL, 0);
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when msg_msg_free_security hook is triggered.
+ *
+ * This hook is triggered when deallocating the security structure for this
+ * message.
+ * Free msg provenance entry when security structure for this message is
+ * deallocated.
+ * If the msg has a valid provenance entry pointer (i.e., non-NULL), free the
+ * memory and set the pointer to NULL.
+ * @param msg The message structure whose security structure to be freed.
+ *
+ */
+static void provenance_msg_msg_free_security(struct msg_msg *msg)
+{
+	struct provenance *mprov;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	mprov = provenance_msg_msg(msg);
+
+	if (mprov)
+		record_terminate(RL_FREED, mprov);
+}
+
+/*!
+ * @brief Helper function for two security hooks: msg_queue_msgsnd and
+ * mq_timedsend.
+ *
+ * Record provenance relation RL_SND_MSG_Q by calling "generates" function.
+ * Information flows from calling process's cred to the process, and eventually
+ * to msg.
+ * @param msg The message structure.
+ * @return 0 if no error occurred; Other error codes inherited from generates
+ * function.
+ *
+ */
+static inline int __mq_msgsnd(struct msg_msg *msg)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *mprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	mprov = provenance_msg_msg(msg);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(mprov), PROVENANCE_LOCK_MSG);
+	rc = generates(RL_SND_MSG_Q, cprov, tprov, mprov, NULL, 0);
+	spin_unlock(prov_lock(mprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when msg_queue_msgsnd hook is triggered.
+ *
+ * This hook is trigger when checking permission before a message, @msg,
+ * is enqueued on the message queue, @msq.
+ * This function simply calls the helper function __mq_msgsnd.
+ * @param msq The message queue to send message to.
+ * @param msg The message to be enqueued.
+ * @param msqflg The operational flags.
+ * @return 0 if permission is granted. Other error codes inherited from
+ * __mq_msgsnd function.
+ *
+ */
+static int provenance_msg_queue_msgsnd(struct kern_ipc_perm *msq,
+				       struct msg_msg *msg,
+				       int msqflg)
+{
+	if (!prov_policy.prov_enabled)
+		return 0;
+	return __mq_msgsnd(msg);
+}
+
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+
+/*!
+ * @brief Record provenance when mq_timedsend hook is triggered.
+ *
+ * This function simply calls the helper function __mq_msgsnd.
+ * @param inode Unused parameter.
+ * @param msg The message to be enqueued.
+ * @param ts Unused parameter.
+ * @return 0 if permission is granted. Other error codes inherited from
+ * __mq_msgsnd function.
+ *
+ */
+static int provenance_mq_timedsend(struct inode *inode, struct msg_msg *msg,
+				   struct timespec64 *ts)
+{
+	if (!prov_policy.prov_enabled)
+		return 0;
+	return __mq_msgsnd(msg);
+}
+#endif
+
+/*!
+ * @brief Helper function for two security hooks: msg_queue_msgrcv and
+ * mq_timedreceive.
+ *
+ * Record provenance relation RL_RCV_MSG_Q by calling "uses" function.
+ * Information flows from msg to the calling process, and eventually to its
+ * cred.
+ * @param cprov The calling process's cred provenance entry pointer.
+ * @param msg The message structure.
+ * @return 0 if no error occurred; Other error codes inherited from uses
+ * function.
+ *
+ */
+static inline int __mq_msgrcv(struct provenance *cprov,
+			      struct provenance *tprov,
+			      struct msg_msg *msg)
+{
+	struct provenance *mprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	mprov = provenance_msg_msg(msg);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(mprov), PROVENANCE_LOCK_MSG);
+	rc = uses(RL_RCV_MSG_Q, mprov, tprov, cprov, NULL, 0);
+	spin_unlock(prov_lock(mprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when msg_queue_msgrcv hook is triggered.
+ *
+ * This hook is triggered when checking permission before a message, @msg, is
+ * removed from the message queue, @msq.
+ * The @target task structure contains a pointer to the process that will be
+ * receiving the message (not equal to the current process when inline receives
+ * are being performed).
+ * Since it is the receiving task that receives the msg,
+ * we first obtain the receiving task's cred provenance entry pointer,
+ * and then simply calls the helper function __mq_msgrcv to record the
+ * information flow.
+ * @param msq The message queue to retrieve message from.
+ * @param msg The message destination.
+ * @param target The task structure for recipient process.
+ * @param type The type of message requested.
+ * @param mode The operational flags.
+ * @return 0 if permission is granted. Other error codes inherited from
+ * __mq_msgrcv function.
+ *
+ */
+static int provenance_msg_queue_msgrcv(struct kern_ipc_perm *msq,
+				       struct msg_msg *msg,
+				       struct task_struct *target,
+				       long type,
+				       int mode)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = provenance_cred_from_task(target);
+	tprov = provenance_task(target);
+
+	return __mq_msgrcv(cprov, tprov, msg);
+}
+
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+
+/*!
+ * @brief Record provenance when mq_timedreceive hook is triggered.
+ *
+ * Current process will be receiving the message.
+ * We simply calls the helper function __mq_msgrcv to record the information
+ * flow.
+ * @param inode Unused parameter.
+ * @param msg The message destination.
+ * @param ts Unused parameter.
+ * @return 0 if permission is granted. Other error codes inherited from
+ * __mq_msgrcv function.
+ *
+ */
+static int provenance_mq_timedreceive(struct inode *inode, struct msg_msg *msg,
+				      struct timespec64 *ts)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(false);
+
+	return __mq_msgrcv(cprov, tprov, msg);
+}
+#endif
+
+/*!
+ * @brief Record provenance when shm_alloc_security hook is triggered.
+ *
+ * This hunk is triggered when allocating and attaching a security structure to
+ * the shp->shm_perm.security field.
+ * The security field is initialized to NULL when the structure is first
+ * created.
+ * This function allocates and attaches a provenance entry to the
+ * shp->shm_perm.provenance field.
+ * That is, it creates a new provenance node ENT_SHM.
+ * It also fills in some provenance information based on the information
+ * contained in @shp.
+ * Record provenance relation RL_SH_CREATE_READ by calling "uses" function.
+ * For read, information flows from shared memory to the calling process, and
+ * eventually to its cred.
+ * Record provenance relation RL_SH_CREATE_WRITE by calling "uses" function.
+ * For write, information flows from the calling process's cree to the process,
+ * and eventually to shared memory.
+ * @param shp The shared memory structure to be modified.
+ * @return 0 if operation was successful and permission is granted, no error
+ * occurred. -ENOMEM if no memory can be allocated to create a new ENT_SHM
+ * provenance entry. Other error code inherited from uses and generates function
+ *.
+ *
+ */
+static int provenance_shm_alloc_security(struct kern_ipc_perm *shp)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *sprov = provenance_ipc(shp);
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!sprov)
+		return -ENOMEM;
+	init_provenance_struct(ENT_SHM, sprov);
+	prov_elt(sprov)->shm_info.mode = shp->mode;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	rc = generates(RL_SH_CREATE, cprov, tprov, sprov, NULL, 0);
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when shm_free_security hook is triggered.
+ *
+ * This hook is triggered when deallocating the security struct for this memory
+ * segment.
+ * We simply free the memory of the allocated provenance entry if it exists, and
+ * set the pointer to NULL.
+ * @param shp The shared memory structure to be modified.
+ *
+ */
+static void provenance_shm_free_security(struct kern_ipc_perm *shp)
+{
+	struct provenance *sprov;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	sprov = provenance_ipc(shp);
+
+	if (sprov)
+		record_terminate(RL_FREED, sprov);
+}
+
+/*!
+ * @brief Record provenance when shm_shmat hook is triggered.
+ *
+ * This hook is triggered when checking permissions prior to allowing the shmat
+ * system call to attach the
+ * shared memory segment @shp to the data segment of the calling process.
+ * The attaching address is specified by @shmaddr.
+ * If @shmflg is SHM_RDONLY (readable only), then:
+ * Record provenance relation RL_SH_ATTACH_READ by calling "uses" function.
+ * Information flows from shared memory to the calling process, and then
+ * eventually to its cred.
+ * Otherwise, shared memory is both readable and writable, then:
+ * Record provenance relation RL_SH_ATTACH_READ by calling "uses" function and
+ * RL_SH_ATTACH_WRITE by calling "uses" function.
+ * Information can flow both ways.
+ * @param shp The shared memory structure to be modified.
+ * @param shmaddr The address to attach memory region to.
+ * @param shmflg The operational flags.
+ * @return 0 if permission is granted and no error occurred; -ENOMEM if shared
+ * memory provenance entry does not exist. Other error codes inherited from uses
+ * and generates function.
+ *
+ */
+static int provenance_shm_shmat(struct kern_ipc_perm *shp, char __user *shmaddr, int shmflg)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *sprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	sprov = provenance_ipc(shp);
+
+	if (!sprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(sprov), PROVENANCE_LOCK_SHM);
+	rc = generates(RL_SH_ATTACH, cprov, tprov, sprov, NULL, shmflg);
+	spin_unlock(prov_lock(sprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+/*!
+ * @brief Record provenance when shm_shmdt hook is triggered.
+ *
+ * This hook is triggered when detaching the shared memory segment from the
+ * address space of the calling process.
+ * The to-be-detached segment must be currently attached with shmaddr equal to
+ * the value returned by the attaching shmat() call.
+ * Record provenance relation RL_SHMDT by calling "generates" function.
+ * Information flows from the calling process's cred to the process, and
+ * eventually to the shared memory.
+ * @param shp The shared memory structure to be modified.
+ *
+ */
+static void provenance_shm_shmdt(struct kern_ipc_perm *shp)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *sprov;
+	unsigned long irqflags;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	sprov = provenance_ipc(shp);
+
+	if (!sprov)
+		return;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(sprov), PROVENANCE_LOCK_SHM);
+	generates(RL_SHMDT, cprov, tprov, sprov, NULL, 0);
+	spin_unlock(prov_lock(sprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+}
+#endif
+
+/*!
+ * @brief Record provenance when sk_alloc_security hook is triggered.
+ *
+ * This hook is triggered when allocating and attaching a security structure to
+ * the sk->sk_security field,
+ * which is used to copy security attributes between local stream sockets.
+ * This function therefore allocates and attaches @sk_provenance structure to
+ * @sk.
+ * The provenance of the local stream socket is the same as the cred provenance
+ * of the calling process.
+ * @param sk The sock structure to be modified.
+ * @param family The protocol family. Unused parameter.
+ * @param priority Memory allocation operation flag.
+ * @return 0 if success and no error occurred; -ENOMEM if calling process's
+ * cred structure does not exist. Other error codes unknown.
+ *
+ */
+static int provenance_sk_alloc_security(struct sock *sk,
+					int family,
+					gfp_t priority)
+{
+	struct provenance *skprov = provenance_task(current);
+
+	if (!skprov)
+		return -ENOMEM;
+	sk->sk_provenance = skprov;
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when socket_post_create hook is triggered.
+ *
+ * This hook allows a module to update or allocate a per-socket security
+ * structure.
+ * Note that the security field was not added directly to the socket structure,
+ * but rather, the socket security information is stored in the associated
+ * inode.
+ * Typically, the inode alloc_security hook will allocate and attach
+ * security information to sock->inode->i_security.
+ * This hook may be used to update the sock->inode->i_security field
+ * with additional information that wasn't available when the inode was
+ * allocated.
+ * Record provenance relation RL_SOCKET_CREATE by calling "generates" function.
+ * Information flows from the calling process's cred to the process, and
+ * eventually to the socket that is being created.
+ * If @kern is 1 (kernal socket), no provenance relation is recorded.
+ * This is becasuse kernel socket is a form of communication between kernel and
+ * userspace.
+ * We do not capture kernel's provenance for now.
+ * @param sock The newly created socket structure.
+ * @param family The requested protocol family.
+ * @param type The requested communications type.
+ * @param protocol The requested protocol.
+ * @param kern Set to 1 if it is a kernel socket.
+ * @return 0 if no error occurred; -ENOMEM if inode provenance entry does not
+ * exist. Other error codes inherited from generates function.
+ *
+ * @todo Maybe support kernel socket in a future release.
+ */
+static int provenance_socket_post_create(struct socket *sock,
+					 int family,
+					 int type,
+					 int protocol,
+					 int kern)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+
+	if (kern)
+		return 0;
+	if (!iprov)
+		return -ENOMEM;
+
+	if (provenance_is_tracked(prov_elt(cprov))
+	    || provenance_is_tracked(prov_elt(tprov)))
+		set_tracked(prov_elt(iprov));
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_SOCKET_CREATE, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+static int provenance_socket_socketpair(struct socket *socka,
+					struct socket *sockb)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprova;
+	struct provenance *iprovb;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprova = get_socket_inode_provenance(socka);
+	iprovb = get_socket_inode_provenance(sockb);
+
+	if (!iprova)
+		return -ENOMEM;
+	if (!iprovb)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprova), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_SOCKET_PAIR_CREATE, cprov, tprov, iprova, NULL, 0);
+	spin_unlock(prov_lock(iprova));
+	if (rc < 0)
+		goto out;
+	spin_lock_nested(prov_lock(iprovb), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_SOCKET_PAIR_CREATE, cprov, tprov, iprovb, NULL, 0);
+	spin_unlock(prov_lock(iprovb));
+out:
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_bind hook is triggered.
+ *
+ * This hook is triggered when checking permission before socket protocol layer
+ * bind operation is performed, and the socket @sock is bound to the address
+ * specified in the @address parameter.
+ * The function records the provenance relations if the calling process is not
+ * set to be opaque (i.e., should be recorded).
+ * The relation between the socket and its address is recorded first,
+ * then record provenance relation RL_BIND by calling "generates" function.
+ * Information flows from the cred of the calling process to the process itself,
+ * and eventually to the socket.
+ * If the address family is PF_INET (we only support IPv4 for now), we check if
+ * we should record the packet from the socket,
+ * and track and propagate recording from the socket and the calling process.
+ * Note that usually server binds the socket to its local address.
+ * @param sock The socket structure.
+ * @param address The address to bind to.
+ * @param addrlen The length of address.
+ * @return 0 if permission is granted and no error occurred; -EINVAL if socket
+ * address is longer than @addrlen; -ENOMEM if socket inode provenance entry
+ * does not exist. Other error codes inherited.
+ *
+ */
+static int provenance_socket_bind(struct socket *sock,
+				  struct sockaddr *address,
+				  int addrlen)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+
+	if (!iprov)
+		return -ENOMEM;
+	// We perform a check here so that we won't accidentally
+	// start tracking/propagating @iprov and @cprov
+	if (provenance_is_opaque(prov_elt(cprov)))
+		return 0;
+	rc = check_track_socket(address, addrlen, &ingress_ipv4filters, cprov, iprov);
+	if (rc < 0)
+		return rc;
+	rc = record_address(address, addrlen, iprov);
+	if (rc < 0)
+		return rc;
+	rc = generates(RL_BIND, cprov, tprov, iprov, NULL, 0);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_connect hook is triggered.
+ *
+ * This hook is triggered when checking permission before socket protocol layer
+ * connect operation attempts to connect socket @sock to a remote address,
+ * @address.
+ * This function is similar to the above provenance_socket_bind function, except
+ * that we record provenance relation RL_CONNECT by calling "generates"
+ * function.
+ * @param sock The socket structure.
+ * @param address The address of remote endpoint.
+ * @param addrlen The length of address.
+ * @return 0 if permission is granted and no error occurred; -EINVAL if socket
+ * address is longer than @addrlen; -ENOMEM if socket inode provenance entry
+ * does not exist. Other error codes inherited.
+ *
+ */
+static int provenance_socket_connect(struct socket *sock,
+				     struct sockaddr *address,
+				     int addrlen)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+
+	if (!iprov)
+		return -ENOMEM;
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	if (provenance_is_opaque(prov_elt(cprov)))
+		goto out;
+	rc = check_track_socket(address, addrlen, &egress_ipv4filters, cprov, iprov);
+	if (rc < 0)
+		goto out;
+	rc = record_address(address, addrlen, iprov);
+	if (rc < 0)
+		goto out;
+	rc = generates(RL_CONNECT, cprov, tprov, iprov, NULL, 0);
+out:
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_listen hook is triggered.
+ *
+ * This hook is triggered when checking permission before socket protocol layer
+ * listen operation.
+ * Record provenance relation RL_LISTEN by calling "generates" function.
+ * @param sock The socket structure.
+ * @param backlog The maximum length for the pending connection queue.
+ * @return 0 if no error occurred; -ENOMEM if socket inode provenance entry does
+ * not exist. Other error codes inherited from generates function.
+ *
+ */
+static int provenance_socket_listen(struct socket *sock, int backlog)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+
+	if (!iprov)
+		return -ENOMEM;
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_LISTEN, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_accept hook is triggered.
+ *
+ * This hook is triggered when checking permission before accepting a new
+ * connection.
+ * Note that the new socket, @newsock, has been created and some information
+ * copied to it,
+ * but the accept operation has not actually been performed.
+ * Since a new socket has been created after aceepting a new connection,
+ * record provenance relation RL_ACCEPT_SOCKET by calling "derives" function.
+ * Information flows from the old socket to the new socket.
+ * Then record provenance relation RL_ACCEPT by calling "uses" function,
+ * since the calling process accepts the connection.
+ * Information flows from the new socket to the calling process, and eventually
+ * to its cred.
+ * @param sock The listening socket structure.
+ * @param newsock The newly created server socket for connection.
+ * @return 0 if permission is granted and no error occurred; Other error codes
+ * inherited from derives and uses function.
+ *
+ */
+static int provenance_socket_accept(struct socket *sock, struct socket *newsock)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	struct provenance *niprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+	niprov = get_socket_inode_provenance(newsock);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = derives(RL_ACCEPT_SOCKET, iprov, niprov, NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = uses(RL_ACCEPT, niprov, tprov, cprov, NULL, 0);
+out:
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_sendmsg_always/socket_sendmsg hook is
+ * triggered.
+ *
+ * This hook is triggered when checking permission before transmitting a message
+ * to another socket.
+ * Record provenance relation RL_SND_MSG by calling "generates" function.
+ * Information flows from the calling process's cred to the calling process, and
+ * eventually to the sending socket.
+ * If sk_family is PF_UNIX (or any local communication) and sk_type is not
+ * SOCK_DGRAM, we obtain the @peer receiving socket and its provenance,
+ * and if the provenance is not NULL,
+ * record provenance relation RL_RCV_UNIX by calling "derives" function.
+ * Information flows from the sending socket to the receiving peer socket.
+ * @param sock The socket structure.
+ * @param msg The message to be transmitted.
+ * @param size The size of message.
+ * @return 0 if permission is granted and no error occurred; -ENOMEM if the
+ * sending socket's provenance entry does not exist; Other error codes inherited
+ * from generates and derives function.
+ *
+ */
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+static int provenance_socket_sendmsg_always(struct socket *sock,
+					    struct msghdr *msg,
+					    int size)
+#else
+static int provenance_socket_sendmsg(struct socket *sock,
+				     struct msghdr *msg,
+				     int size)
+#endif /* CONFIG_SECURITY_FLOW_FRIENDLY */
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprova;
+	struct provenance *iprovb = NULL;
+	struct sock *peer = NULL;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprova = get_socket_inode_provenance(sock);
+
+	if (!iprova)
+		return -ENOMEM;
+	// Datagram handled by unix_may_send hook.
+	if (sock->sk->sk_family == PF_UNIX &&
+	    sock->sk->sk_type != SOCK_DGRAM) {
+		peer = unix_peer_get(sock->sk);
+		if (peer) {
+			iprovb = get_sk_inode_provenance(peer);
+			if (iprovb == cprov)
+				iprovb = NULL;
+		}
+	}
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprova), PROVENANCE_LOCK_SOCKET);
+	rc = generates(RL_SND_MSG, cprov, tprov, iprova, NULL, 0);
+	if (rc < 0)
+		goto out;
+	if (iprovb)
+		rc = derives(RL_RCV_UNIX, iprova, iprovb, NULL, 0);
+out:
+	spin_unlock(prov_lock(iprova));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	if (peer)
+		sock_put(peer);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_recvmsg_always/socket_recvmsg hook is
+ * triggered.
+ *
+ * This hook is triggered when checking permission before receiving a message
+ * from a socket.
+ * This function is similar to the above provenance_socket_sendmsg_always
+ * function except the direction is reversed.
+ * Specifically, if we know the sending socket, we have
+ * record provenance relation RL_SND_UNIX by calling "derives" function.
+ * Information flows from the sending socket (@peer) to the receiving socket
+ * (@sock).
+ * Then record provenance relation RL_RCV_MSG by calling "uses" function.
+ * Information flows from the receiving socket to the calling process, and
+ * eventually to its cred.
+ * @param sock The receiving socket structure.
+ * @param msg The message structure.
+ * @param size The size of message structure.
+ * @param flags The operational flags.
+ * @return 0 if permission is granted, and no error occurred; -ENOMEM if the
+ * receiving socket's provenance entry does not exist; Other error codes
+ * inherited from uses and derives function.
+ *
+ */
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+static int provenance_socket_recvmsg_always(struct socket *sock,
+					    struct msghdr *msg,
+					    int size,
+					    int flags)
+#else
+static int provenance_socket_recvmsg(struct socket *sock,
+				     struct msghdr *msg,
+				     int size,
+				     int flags)
+#endif /* CONFIG_SECURITY_FLOW_FRIENDLY */
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	struct provenance *pprov = NULL;
+	struct sock *peer = NULL;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_socket_inode_provenance(sock);
+
+	if (!iprov)
+		return -ENOMEM;
+	if (sock->sk->sk_family == PF_UNIX &&
+	    sock->sk->sk_type != SOCK_DGRAM) { // datagran handled by unix_may_send
+		peer = unix_peer_get(sock->sk);
+		if (peer) {
+			pprov = get_sk_provenance(peer);
+			if (pprov == cprov)
+				pprov = NULL;
+		}
+	}
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	if (pprov) {
+		rc = derives(RL_SND_UNIX, pprov, iprov, NULL, flags);
+		if (rc < 0)
+			goto out;
+	}
+	rc = uses(RL_RCV_MSG, iprov, tprov, cprov, NULL, flags);
+out:
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	if (peer)
+		sock_put(peer);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when socket_sock_rcv_skb hook is triggered.
+ *
+ * This hooks is triggered when checking permissions on incoming network
+ * packets.
+ * This hook is distinct from Netfilter's IP input hooks since it is the first
+ * time that the incoming sk_buff @skb has been associated with a particular
+ * socket, @sk.
+ * Must not sleep inside this hook because some callers hold spinlocks.
+ * If the socket inode is tracked,
+ * create a packet provenance node and fill the provenance information of the
+ * node from @skb,
+ * and record provenance relation RL_RCV_PACKET by calling "derives" function.
+ * Information flows from the packet to the socket.
+ * We only handle IPv4 in this function for now (i.e. PF_INET family only).
+ * @param sk The sock (not socket) associated with the incoming sk_buff.
+ * @param skb The incoming network data.
+ * @return 0 if no error occurred; -ENOMEM if sk provenance does not exist.
+ * Other error codes inherited from derives function.
+ *
+ */
+static int provenance_socket_sock_rcv_skb(struct sock *sk, struct sk_buff *skb)
+{
+	struct provenance *iprov;
+	struct provenance *pckprov;
+	uint16_t family = sk->sk_family;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	if (family != PF_INET)
+		return 0;
+
+	iprov = get_sk_inode_provenance(sk);
+	if (!iprov)
+		return -ENOMEM;
+
+	if (provenance_is_tracked(prov_elt(iprov))) {
+		pckprov = provenance_alloc_with_ipv4_skb(ENT_PACKET, skb);
+
+		if (!pckprov)
+			return -ENOMEM;
+
+		if (should_record_packet_content(prov_elt(iprov)))
+			record_packet_content(skb, pckprov);
+
+		spin_lock_irqsave(prov_lock(iprov), irqflags);
+		rc = derives(RL_RCV_PACKET, pckprov, iprov, NULL, 0);
+		spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+		free_provenance(pckprov);
+	}
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when unix_stream_connect hook is triggered.
+ *
+ * This hook is triggered when checking permissions before establishing a Unix
+ * domain stream connection b]etween @sock and @other.
+ * Unix domain connection is local communication.
+ * Since this is simply to connect (no information should flow between the two
+ * local sockets yet), we do not use receiving socket information @other or new
+ * socket @newsk.
+ * Record provenance relation RL_CONNECT by calling "generates" function.
+ * Information flows from the calling process's cred to the task , and
+ * eventually to the sending socket.
+ * @param sock The (sending) sock structure.
+ * @param other The peer (i.e., receiving) sock structure. Unused parameter.
+ * @param newsk The new sock structure. Unused parameter.
+ * @return 0 if permission is granted; Other error code inherited from generates
+ * function.
+ *
+ */
+static int provenance_unix_stream_connect(struct sock *sock,
+					  struct sock *other,
+					  struct sock *newsk)
+{
+	struct provenance *cprov;
+	struct provenance *tprov;
+	struct provenance *iprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	cprov = get_cred_provenance();
+	tprov = get_task_provenance(true);
+	iprov = get_sk_inode_provenance(sock);
+
+	spin_lock_irqsave_nested(prov_lock(cprov), irqflags, PROVENANCE_LOCK_PROC);
+	spin_lock_nested(prov_lock(iprov), PROVENANCE_LOCK_INODE);
+	rc = generates(RL_CONNECT_UNIX_STREAM, cprov, tprov, iprov, NULL, 0);
+	spin_unlock(prov_lock(iprov));
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when unix_may_send hook is triggered.
+ *
+ * This hook is triggered when checking permissions before connecting or sending
+ * datagrams from @sock to @other.
+ * Record provenance relation RL_SND_UNIX by calling "derives" function.
+ * Information flows from the sending socket (@sock) to the receiving socket
+ * (@other).
+ * @param sock The socket structure.
+ * @param other The peer socket structure.
+ * @return 0 if permission is granted and no error occurred; Other error codes
+ * inherited from derives function.
+ *
+ */
+static int provenance_unix_may_send(struct socket *sock,
+				    struct socket *other)
+{
+	struct provenance *iprov;
+	struct provenance *oprov;
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	iprov = get_socket_inode_provenance(sock);
+	oprov = get_socket_inode_provenance(other);
+
+	spin_lock_irqsave_nested(prov_lock(iprov), irqflags, PROVENANCE_LOCK_SOCKET);
+	spin_lock_nested(prov_lock(oprov), PROVENANCE_LOCK_SOCK);
+	rc = derives(RL_SND_UNIX, iprov, oprov, NULL, 0);
+	spin_unlock(prov_lock(oprov));
+	spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when bprm_creds_for_exec hook is triggered.
+ *
+ * This hook is triggered when saving security information in the bprm->security
+ * field, typically based on information about the bprm->file, for later use by
+ * the apply_creds hook.
+ * This hook may also optionally check permissions (e.g. for transitions between
+ * security domains).
+ * This hook may be called multiple times during a single execve, e.g. for
+ * interpreters.
+ * The hook can tell whether it has already been called by checking to see if
+ * @bprm->security is non-NULL.
+ * If so, then the hook may decide either to retain the security information
+ * saved earlier or to replace it.
+ * Since cred is based on information about the @bprm->file,
+ * information flows from the inode of bprm->file to bprm->cred.
+ * Therefore, record provenance relation RL_EXEC by calling "derives" function.
+ * Relation is not recorded if the inode of bprm->file is set to be opaque.
+ * @param bprm The linux_binprm structure.
+ * @return 0 if the hook is successful and permission is granted; -ENOMEM if
+ * bprm->cred's provenance does not exist. Other error codes inherited from
+ * derives function.
+ *
+ */
+static int provenance_bprm_creds_for_exec(struct linux_binprm *bprm)
+{
+	struct provenance *nprov = provenance_cred(bprm->cred);
+	struct provenance *iprov = get_file_provenance(bprm->file, true);
+	unsigned long irqflags;
+	int rc = 0;
+
+	if (!nprov)
+		return -ENOMEM;
+
+	if (provenance_is_opaque(prov_elt(iprov))) {
+		set_opaque(prov_elt(nprov));
+		return 0;
+	}
+
+	if (!prov_policy.prov_enabled)
+		return 0;
+
+	spin_lock_irqsave(prov_lock(iprov), irqflags);
+	rc = derives(RL_EXEC, iprov, nprov, NULL, 0);
+	spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+	return rc;
+}
+
+/*!
+ * @brief Record provenance when bprm_check hook is triggered.
+ *
+ * This hook mediates the point when a search for a binary handler will begin.
+ * It allows a check the @bprm->security value which is set in the preceding
+ * set_creds call.
+ * The primary difference from set_creds is that the argv list and envp list are
+ * reliably available in @bprm.
+ * This hook may be called multiple times during a single execve;
+ * and in each pass set_creds is called first.
+ * If the inode of bprm->file is opaque, we set the bprm->cred to be opaque
+ * (i.e., do not track).
+ * The relations between the bprm arguments and bprm->cred are recorded by
+ * calling record_args function.
+ * @param bprm The linux_binprm structure.
+ * @return 0 if no error occurred; -ENOMEM if bprm->cred provenance does not
+ * exist. Other error codes inherited from record_args function.
+ *
+ */
+static int provenance_bprm_check_security(struct linux_binprm *bprm)
+{
+	struct provenance *nprov = provenance_cred(bprm->cred);
+	struct provenance *tprov = get_task_provenance(false);
+	struct provenance *iprov = get_file_provenance(bprm->file, false);
+
+	if (!nprov)
+		return -ENOMEM;
+
+	if (provenance_is_opaque(prov_elt(iprov))) {
+		set_opaque(prov_elt(nprov));
+		set_opaque(prov_elt(tprov));
+		return 0;
+	}
+	if (provenance_is_tracked(prov_elt(iprov)))
+		set_tracked(prov_elt(nprov));
+	return record_args(nprov, bprm);
+}
+
+/*!
+ * @brief Record provenance when bprm_committing_creds hook is triggered.
+ *
+ * This hook is triggered when preparing to install the new security attributes
+ * of a process being transformed by an execve operation,
+ * based on the old credentials pointed to by @current->cred,
+ * and the information set in @bprm->cred by the bprm_set_creds hook.
+ * This hook is a good place to perform state changes on the process such as
+ * closing open file descriptors to which access will no longer
+ * be granted when the attributes are changed.
+ * This is called immediately before commit_creds().
+ * Since the process is being transformed to the new process,
+ * record provenance relation RL_EXEC_TASK by calling "derives" function.
+ * Information flows from the old process's cred to the new process's cred.
+ * Cred can also be set by bprm_set_creds, so
+ * record provenance relation RL_EXEC by calling "derives" function.
+ * Information flows from the bprm->file's cred to the new process's cred.
+ * The old process gets the name of the new process by calling record_node_name
+ * function.
+ * Note that if bprm->file's provenance is set to be opaque,
+ * the new process bprm->cred's provenance will therefore be opaque and we do
+ * not track any of the relations.
+ * @param bprm points to the linux_binprm structure.
+ *
+ */
+static void provenance_bprm_committing_creds(struct linux_binprm *bprm)
+{
+	struct provenance *tprov;
+	struct provenance *cprov;
+	struct provenance *nprov;
+	unsigned long irqflags;
+
+	if (!prov_policy.prov_enabled)
+		return;
+
+	tprov = get_task_provenance(true);
+	cprov = get_cred_provenance();
+	nprov = provenance_cred(bprm->cred);
+
+	record_node_name(cprov, bprm->interp, false);
+	spin_lock_irqsave(prov_lock(cprov), irqflags);
+	generates(RL_EXEC_TASK, cprov, tprov, nprov, NULL, 0);
+	spin_unlock_irqrestore(prov_lock(cprov), irqflags);
+}
+
+/*!
+ * @brief Record provenance when sb_alloc_security hook is triggered.
+ *
+ * This hook is triggered when allocating and attaching a security structure to
+ * the sb->s_security field.
+ * The s_security field is initialized to NULL when the structure is allocated.
+ * This function initializes a provenance structure to
+ * the superblock.
+ * It also creates a new provenance node ENT_SBLCK.
+ * SB represents the existence of a device/pipe.
+ * @param sb The super_block structure to be modified.
+ * @return 0 if operation was successful; -ENOMEM if no memory can be allocated
+ * for a new provenance entry. Other error codes unknown.
+ *
+ */
+static int provenance_sb_alloc_security(struct super_block *sb)
+{
+	struct provenance *sbprov = provenance_superblock(sb);
+
+	if (!sbprov)
+		return -ENOMEM;
+	init_provenance_struct(ENT_SBLCK, sbprov);
+	return 0;
+}
+
+/*!
+ * @brief Record provenance when sb_kern_mount hook is triggered.
+ *
+ * This hook is triggered when mounting a kernel device, including pipe.
+ * This function will update the Universal Unique ID of the provenance entry
+ * of the device superblock once it is mounted.
+ * We obtain this information from @sb if it exists, or we give it a random
+ * value.
+ * @param sb The super block structure.
+ * @param flags The operations flags.
+ * @param data
+ * @return always return 0.
+ *
+ */
+static int provenance_sb_kern_mount(struct super_block *sb)
+{
+	int i;
+	uint8_t c = 0;
+	struct provenance *sbprov = provenance_superblock(sb);
+
+	for (i = 0; i < 16; i++) {
+		prov_elt(sbprov)->sb_info.uuid[i] = sb->s_uuid.b[i];
+		c |= sb->s_uuid.b[i];
+	}
+	if (c == 0)     // If no uuid defined, generate a random one.
+		get_random_bytes(prov_elt(sbprov)->sb_info.uuid, 16 * sizeof(uint8_t));
+	return 0;
+}
+
+static int provmon_socket_setsockopt(struct socket *sock, int level, int optname)
+{
+
+	if (sock->sk->sk_family == AF_INET && level == SOL_IP &&
+	    optname == IP_OPTIONS) {
+		printk(KERN_WARNING "Provenance Monitor: %s setting IP options via setsockopt\n",
+		       current->comm);
+		return -ENOPROTOOPT;
+	}
+	return 0;
+
+}
+
+// Feign ignorance to make OpenSSH work again
+static int provmon_socket_getsockopt(struct socket *sock, int level, int optname)
+{
+	if (sock->sk->sk_family == AF_INET && level == SOL_IP &&
+	    optname == IP_OPTIONS) {
+		printk(KERN_WARNING "Provenance Monitor: Feigning IP Options ignorance (getsockopt)\n");
+		return -ENOPROTOOPT;
+	}
+	return 0;
+}
+
+struct lsm_blob_sizes provenance_blob_sizes __lsm_ro_after_init = {
+	.lbs_cred = sizeof(struct provenance),
+	.lbs_file = sizeof(struct provenance),
+	.lbs_inode = sizeof(struct provenance),
+	.lbs_ipc = sizeof(struct provenance),
+	.lbs_msg_msg = sizeof(struct provenance),
+	.lbs_task = sizeof(struct provenance),
+	.lbs_superblock = sizeof(struct provenance),
+};
+
+/*!
+ * @brief Add provenance hooks to security_hook_list.
+ */
+static struct security_hook_list provenance_hooks[] __lsm_ro_after_init = {
+	/* cred related hooks */
+	LSM_HOOK_INIT(cred_free,                provenance_cred_free),
+	LSM_HOOK_INIT(cred_alloc_blank,         provenance_cred_alloc_blank),
+	LSM_HOOK_INIT(cred_prepare,             provenance_cred_prepare),
+	LSM_HOOK_INIT(cred_transfer,            provenance_cred_transfer),
+
+	/* task related hooks */
+	LSM_HOOK_INIT(task_alloc,               provenance_task_alloc),
+	LSM_HOOK_INIT(task_free,                provenance_task_free),
+	LSM_HOOK_INIT(task_fix_setuid,          provenance_task_fix_setuid),
+	LSM_HOOK_INIT(task_setpgid,             provenance_task_setpgid),
+	LSM_HOOK_INIT(task_getpgid,             provenance_task_getpgid),
+	LSM_HOOK_INIT(task_kill,                provenance_task_kill),
+	LSM_HOOK_INIT(ptrace_access_check,      provenance_ptrace_access_check),
+	LSM_HOOK_INIT(ptrace_traceme,           provenance_ptrace_traceme),
+
+	/* inode related hooks */
+	LSM_HOOK_INIT(inode_alloc_security,     provenance_inode_alloc_security),
+	LSM_HOOK_INIT(inode_create,             provenance_inode_create),
+	LSM_HOOK_INIT(inode_free_security,      provenance_inode_free_security),
+	LSM_HOOK_INIT(inode_permission,         provenance_inode_permission),
+	LSM_HOOK_INIT(inode_link,               provenance_inode_link),
+	LSM_HOOK_INIT(inode_unlink,             provenance_inode_unlink),
+	LSM_HOOK_INIT(inode_symlink,            provenance_inode_symlink),
+	LSM_HOOK_INIT(inode_rename,             provenance_inode_rename),
+	LSM_HOOK_INIT(inode_setattr,            provenance_inode_setattr),
+	LSM_HOOK_INIT(inode_getattr,            provenance_inode_getattr),
+	LSM_HOOK_INIT(inode_readlink,           provenance_inode_readlink),
+	LSM_HOOK_INIT(inode_setxattr,           provenance_inode_setxattr),
+	LSM_HOOK_INIT(inode_post_setxattr,      provenance_inode_post_setxattr),
+	LSM_HOOK_INIT(inode_getxattr,           provenance_inode_getxattr),
+	LSM_HOOK_INIT(inode_listxattr,          provenance_inode_listxattr),
+	LSM_HOOK_INIT(inode_removexattr,        provenance_inode_removexattr),
+	LSM_HOOK_INIT(inode_getsecurity,        provenance_inode_getsecurity),
+	LSM_HOOK_INIT(inode_listsecurity,       provenance_inode_listsecurity),
+
+	/* file related hooks */
+	LSM_HOOK_INIT(file_permission,          provenance_file_permission),
+	LSM_HOOK_INIT(mmap_file,                provenance_mmap_file),
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+	LSM_HOOK_INIT(mmap_munmap,              provenance_mmap_munmap),
+#endif
+	LSM_HOOK_INIT(file_ioctl,               provenance_file_ioctl),
+	LSM_HOOK_INIT(file_open,                provenance_file_open),
+	LSM_HOOK_INIT(file_receive,             provenance_file_receive),
+	LSM_HOOK_INIT(file_lock,                provenance_file_lock),
+	LSM_HOOK_INIT(file_send_sigiotask,      provenance_file_send_sigiotask),
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+	LSM_HOOK_INIT(file_splice_pipe_to_pipe, provenance_file_splice_pipe_to_pipe),
+#endif
+	LSM_HOOK_INIT(kernel_read_file,         provenance_kernel_read_file),
+
+	/* msg related hooks */
+	LSM_HOOK_INIT(msg_msg_alloc_security,   provenance_msg_msg_alloc_security),
+	LSM_HOOK_INIT(msg_msg_free_security,    provenance_msg_msg_free_security),
+	LSM_HOOK_INIT(msg_queue_msgsnd,         provenance_msg_queue_msgsnd),
+	LSM_HOOK_INIT(msg_queue_msgrcv,         provenance_msg_queue_msgrcv),
+
+	/* shared memory related hooks */
+	LSM_HOOK_INIT(shm_alloc_security,       provenance_shm_alloc_security),
+	LSM_HOOK_INIT(shm_free_security,        provenance_shm_free_security),
+	LSM_HOOK_INIT(shm_shmat,                provenance_shm_shmat),
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+	LSM_HOOK_INIT(shm_shmdt,                provenance_shm_shmdt),
+#endif
+
+	/* socket related hooks */
+	LSM_HOOK_INIT(sk_alloc_security,        provenance_sk_alloc_security),
+	LSM_HOOK_INIT(socket_post_create,       provenance_socket_post_create),
+	LSM_HOOK_INIT(socket_socketpair,        provenance_socket_socketpair),
+	LSM_HOOK_INIT(socket_bind,              provenance_socket_bind),
+	LSM_HOOK_INIT(socket_connect,           provenance_socket_connect),
+	LSM_HOOK_INIT(socket_listen,            provenance_socket_listen),
+	LSM_HOOK_INIT(socket_accept,            provenance_socket_accept),
+#ifdef CONFIG_SECURITY_FLOW_FRIENDLY
+	LSM_HOOK_INIT(socket_sendmsg_always,    provenance_socket_sendmsg_always),
+	LSM_HOOK_INIT(socket_recvmsg_always,    provenance_socket_recvmsg_always),
+	LSM_HOOK_INIT(mq_timedreceive,          provenance_mq_timedreceive),
+	LSM_HOOK_INIT(mq_timedsend,             provenance_mq_timedsend),
+#else   /* CONFIG_SECURITY_FLOW_FRIENDLY */
+	LSM_HOOK_INIT(socket_sendmsg,           provenance_socket_sendmsg),
+	LSM_HOOK_INIT(socket_recvmsg,           provenance_socket_recvmsg),
+#endif  /* CONFIG_SECURITY_FLOW_FRIENDLY */
+	LSM_HOOK_INIT(socket_sock_rcv_skb,      provenance_socket_sock_rcv_skb),
+	LSM_HOOK_INIT(unix_stream_connect,      provenance_unix_stream_connect),
+	LSM_HOOK_INIT(unix_may_send,            provenance_unix_may_send),
+
+	LSM_HOOK_INIT(socket_setsockopt, provmon_socket_setsockopt),
+	LSM_HOOK_INIT(socket_getsockopt, provmon_socket_getsockopt),
+
+
+	/* exec related hooks */
+	LSM_HOOK_INIT(bprm_check_security,      provenance_bprm_check_security),
+	LSM_HOOK_INIT(bprm_creds_for_exec,      provenance_bprm_creds_for_exec),
+	LSM_HOOK_INIT(bprm_committing_creds,    provenance_bprm_committing_creds),
+
+	/* file system related hooks */
+	LSM_HOOK_INIT(sb_alloc_security,        provenance_sb_alloc_security),
+	LSM_HOOK_INIT(sb_kern_mount,            provenance_sb_kern_mount)
+};
+
+struct kmem_cache *provenance_cache __ro_after_init;
+struct kmem_cache *long_provenance_cache __ro_after_init;
+
+struct kmem_cache *boot_buffer_cache __ro_after_init;
+spinlock_t lock_buffer;
+LIST_HEAD(buffer_list);
+
+struct kmem_cache *long_boot_buffer_cache __ro_after_init;
+spinlock_t lock_long_buffer;
+LIST_HEAD(long_buffer_list);
+
+LIST_HEAD(ingress_ipv4filters);
+LIST_HEAD(egress_ipv4filters);
+LIST_HEAD(secctx_filters);
+LIST_HEAD(user_filters);
+LIST_HEAD(group_filters);
+LIST_HEAD(ns_filters);
+LIST_HEAD(provenance_query_hooks);
+
+struct capture_policy prov_policy;
+
+uint32_t prov_machine_id;
+uint32_t prov_boot_id;
+uint32_t __rcu *epoch;
+bool prov_written;
+
+static void __init init_prov_policy(void)
+{
+	pr_info("Provenance: policy initialization started...");
+	prov_policy.should_duplicate = false;
+	prov_policy.should_compress_node = true;
+	prov_policy.should_compress_edge = true;
+#ifdef CONFIG_SECURITY_PROVENANCE_WHOLE_SYSTEM
+	prov_policy.prov_enabled = true;
+	prov_policy.prov_all = true;
+	pr_info("Provenance: capture at boot on.");
+#else
+	prov_policy.prov_enabled = false;
+	prov_policy.prov_all = false;
+	pr_info("Provenance: capture at boot off.");
+#endif
+	pr_info("Provenance: policy initialization finished.");
+}
+
+static void __init init_boot_cache(void)
+{
+	pr_info("Provenance: boot cache initialization started...");
+	boot_buffer_cache = kmem_cache_create("boot_buffer_cache",
+					      sizeof(struct boot_buffer),
+					      0, SLAB_PANIC, NULL);
+	if (unlikely(!boot_buffer_cache))
+		panic("Provenance: could not allocate boot_buffer_cache.");
+	long_boot_buffer_cache = kmem_cache_create("long_boot_buffer_cache",
+						   sizeof(struct long_boot_buffer),
+						   0, SLAB_PANIC, NULL);
+	if (unlikely(!long_boot_buffer_cache))
+		panic("Provenance: could not allocate long_boot_buffer_cache.");
+	pr_info("Provenance: boot cache initialization finished.");
+}
+
+static void __init init_prov_cache(void)
+{
+	pr_info("Provenance: cache initialization started...");
+	provenance_cache = kmem_cache_create("provenance_struct",
+					     sizeof(struct provenance),
+					     0, SLAB_PANIC, NULL);
+	if (unlikely(!provenance_cache))
+		panic("Provenance: could not allocate provenance_cache.");
+	long_provenance_cache = kmem_cache_create("long_provenance_struct",
+						  sizeof(union long_prov_elt),
+						  0, SLAB_PANIC, NULL);
+	if (unlikely(!long_provenance_cache))
+		panic("Provenance: could not allocate long_provenance_cache.");
+	pr_info("Provenance: cache initialization finished.");
+}
+
+/*!
+ * @brief Operations to start provenance capture.
+ *
+ * Those operations are:
+ * 1. Set up default capture policies.
+ * 2. Machine ID is default to 1.
+ * 3. Boot ID is default to 0.
+ * 4. Set up kernel memory cache for regular provenance entries (NULL on
+ * failure).
+ * 5. Set up kernel memory cache for long provenance entries (NULL on failure).
+ * 6. Set up boot buffer for regualr provenance entries (NULL on failure).
+ * 7. Set up boot buffer for long provenance entries (NULL on failure).
+ * (Note that we set up boot buffer because relayfs is not ready at this point.)
+ * 8. Initialize a workqueue (NULL on failure).
+ * 9. Initialize security for provenance task ("task_init_provenance" function).
+ * 10. Register provenance security hooks.
+ * Work_queue helps persiste provenance of inodes (if needed) during the
+ * operations that cannot sleep,
+ * since persists provenance requires writing to disk (which means sleep is
+ * needed).
+ *
+ */
+static int __init provenance_init(void)
+{
+	pr_info("Provenance: initialization started...");
+	init_prov_policy();
+	prov_machine_id = 0;
+	prov_boot_id = 0;
+	epoch = kmalloc(sizeof(uint32_t), GFP_KERNEL);
+	*epoch = 1;
+	prov_written = false;
+	init_prov_cache();
+	init_boot_cache();
+	spin_lock_init(&lock_buffer);
+	spin_lock_init(&lock_long_buffer);
+	relay_initialized = false;
+	relay_ready = false;
+#ifdef CONFIG_SECURITY_PROVENANCE_PERSISTENCE
+	provq = alloc_workqueue("provq", 0, 0);
+	if (!provq)
+		pr_err("Provenance: could not initialize work queue.");
+#endif
+	task_init_provenance();
+	init_prov_machine();
+	pr_info("Provenance: init propagate query.");
+	init_prov_propagate();
+	pr_info("Provenance: starting in epoch %d.", *epoch);
+	// Register provenance security hooks.
+	security_add_hooks(provenance_hooks,
+			   ARRAY_SIZE(provenance_hooks), "provenance");
+	pr_info("Provenance: hooks ready.");
+	return 0;
+}
+
+/* set blob size and init function */
+DEFINE_LSM(provenance) = {
+	.name = "provenance",
+	.blobs = &provenance_blob_sizes,
+	.init = provenance_init,
+};
diff --git a/security/provenance/include/memcpy_ss.h b/security/provenance/include/memcpy_ss.h
new file mode 100644
index 000000000..95d3cda71
--- /dev/null
+++ b/security/provenance/include/memcpy_ss.h
@@ -0,0 +1,23 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _MEMCPY_SS
+#define _MEMCPY_SS
+
+extern int __memcpy_ss(void *dest,
+		       __kernel_size_t dmax,
+		       const void *src,
+		       __kernel_size_t smax);
+
+#endif // _MEMCPY_SS
diff --git a/security/provenance/include/provenance.h b/security/provenance/include/provenance.h
new file mode 100644
index 000000000..16126bcdb
--- /dev/null
+++ b/security/provenance/include/provenance.h
@@ -0,0 +1,306 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_H
+#define _PROVENANCE_H
+
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/bug.h>
+#include <linux/socket.h>
+#include <linux/lsm_hooks.h>
+#include <linux/msg.h>
+#include <linux/cred.h>
+#include <uapi/linux/mman.h>
+#include <uapi/linux/provenance.h>
+#include <uapi/linux/provenance_types.h>
+#include <uapi/linux/stat.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/xattr.h>
+
+#include "provenance_policy.h"
+#include "provenance_utils.h"
+#include "provenance_filter.h"
+#include "provenance_query.h"
+
+extern atomic64_t prov_relation_id;
+extern atomic64_t prov_node_id;
+extern atomic64_t prov_drop;
+extern uint32_t prov_machine_id;
+extern uint32_t prov_boot_id;
+extern uint32_t __rcu *epoch;
+extern bool prov_written;
+
+#define prov_next_relation_id()	\
+	((uint64_t)atomic64_inc_return(&prov_relation_id))
+#define prov_next_node_id() \
+	((uint64_t)atomic64_inc_return(&prov_node_id))
+
+enum {
+	PROVENANCE_LOCK_PROC,
+	PROVENANCE_LOCK_DIR,
+	PROVENANCE_LOCK_INODE,
+	PROVENANCE_LOCK_MSG,
+	PROVENANCE_LOCK_SHM,
+	PROVENANCE_LOCK_SOCKET,
+	PROVENANCE_LOCK_SOCK
+};
+
+struct provenance {
+	union prov_elt msg;
+	spinlock_t lock;
+};
+
+#define prov_elt(provenance)            (&(provenance->msg))
+#define prov_lock(provenance)           (&(provenance->lock))
+#define prov_entry(provenance)          ((prov_entry_t *)prov_elt(provenance))
+
+#define ASSIGN_NODE_ID    0
+
+extern struct kmem_cache *provenance_cache;
+extern struct kmem_cache *long_provenance_cache;
+
+static __always_inline void init_provenance_struct(uint64_t ntype,
+						   struct provenance *prov)
+{
+	memset(prov, 0, sizeof(struct provenance));
+	spin_lock_init(prov_lock(prov));
+	prov_type(prov_elt(prov)) = ntype;
+	node_identifier(prov_elt(prov)).id = prov_next_node_id();
+	node_identifier(prov_elt(prov)).boot_id = prov_boot_id;
+	node_identifier(prov_elt(prov)).machine_id = prov_machine_id;
+	call_provenance_alloc(prov_entry(prov));
+}
+/*!
+ * @brief Allocate memory for a new provenance node and populate
+ * "node_identifier" information.
+ *
+ * The memory is allocated from "provenance_cache".
+ * The type of the provenance node provided in the argument list must align with
+ * the allowed provenance node type (i.e., not a relation type).
+ * Allowed provenance node types are defined in
+ * "include/uapi/linux/provenance_types.h"
+ * The lock accompanied "provenance" structure is initialized as UNLOCK.
+ * Implicitly, the "version" member of "node_identifier" structure is set to 0
+ * through "zalloc".
+ * This is because the version of a new node starts from 0.
+ * @param ntype The type of the provenance node.
+ * @param gfp GFP flags used in memory allocation in the kernel
+ * @return The pointer to the provenance node (prov_elt + lock structure) or
+ * NULL if allocating memory from cache failed.
+ *
+ */
+static __always_inline struct provenance *alloc_provenance(uint64_t ntype,
+							   gfp_t gfp)
+{
+	struct provenance *prov =  kmem_cache_zalloc(provenance_cache, gfp);
+
+	BUILD_BUG_ON(!prov_type_is_node(ntype));
+
+	if (!prov)
+		return NULL;
+	init_provenance_struct(ntype, prov);
+	return prov;
+}
+
+/*!
+ * @brief Free memory of a provenance node
+ */
+static inline void free_provenance(struct provenance *prov)
+{
+	call_provenance_free(prov_entry(prov));
+	kmem_cache_free(provenance_cache, prov);
+}
+
+/*!
+ * @brief Allocate memory for a new long provenance node and set the provenance
+ * "LONG" flag (in basic_elements).
+ *
+ * Similar to "alloc_provenance" function above, this function allocate memory
+ * for long_prove_elt union structure.
+ * long_prov_elt contains more types of node structures than prov_elt.
+ * "version" member of the identifier is also implicitly set to 0 due to
+ * "zalloc".
+ * Spin lock is not needed because at most one thread will access the structure
+ * at a time, since it is a transient element.
+ * @param ntype The type of the long provenance node.
+ * @return The pointer to the long provenance node (long_prov_elt union
+ * structure) or NULL if allocating memory from cache failed.
+ * @reference GFP_ATOMIC https://www.linuxjournal.com/article/6930
+ *
+ */
+static __always_inline union long_prov_elt *alloc_long_provenance(
+	uint64_t ntype,
+	uint64_t id)
+{
+	union long_prov_elt *prov = kmem_cache_zalloc(long_provenance_cache,
+						      GFP_ATOMIC);
+
+	BUILD_BUG_ON(!prov_type_is_node(ntype));
+	BUILD_BUG_ON(!prov_type_is_long(ntype));
+
+	if (!prov)
+		return NULL;
+	prov_type(prov) = ntype;
+	if (id == 0)
+		node_identifier(prov).id = prov_next_node_id();
+	else
+		node_identifier(prov).id = id;
+	node_identifier(prov).boot_id = prov_boot_id;
+	node_identifier(prov).machine_id = prov_machine_id;
+	call_provenance_alloc(prov);
+	return prov;
+}
+
+/*!
+ * @brief Free memory of a long provenance node
+ */
+static inline void free_long_provenance(union long_prov_elt *prov)
+{
+	call_provenance_free(prov);
+	kmem_cache_free(long_provenance_cache, prov);
+}
+
+#define set_recorded(node) \
+	__set_recorded((union long_prov_elt *)node)
+static inline void __set_recorded(union long_prov_elt *node)
+{
+	rcu_read_lock();
+	node->msg_info.epoch = *epoch;
+	rcu_read_unlock();
+}
+
+#define clear_recorded(node) \
+	__clear_recorded((union long_prov_elt *)node)
+static inline void __clear_recorded(union long_prov_elt *node)
+{
+	node->msg_info.epoch = 0;
+}
+
+#define provenance_is_recorded(node) \
+	__provenance_is_recorded((union long_prov_elt *)node)
+static inline bool __provenance_is_recorded(union long_prov_elt *node)
+{
+	bool ret = true;
+
+	rcu_read_lock();
+	if (*epoch > node->msg_info.epoch)
+		ret = false;
+	rcu_read_unlock();
+	return ret;
+}
+
+#define set_name_recorded(node)	\
+	__set_name_recorded((union long_prov_elt *)node)
+static inline void __set_name_recorded(union long_prov_elt *node)
+{
+	rcu_read_lock();
+	node->msg_info.nepoch = *epoch;
+	rcu_read_unlock();
+}
+
+#define clear_name_recorded(node) \
+	__clear_name_recorded((union long_prov_elt *)node)
+static inline void __clear_name_recorded(union long_prov_elt *node)
+{
+	node->msg_info.nepoch = 0;
+}
+
+#define provenance_is_name_recorded(node) \
+	__provenance_is_name_recorded((union long_prov_elt *)node)
+static inline bool __provenance_is_name_recorded(union long_prov_elt *node)
+{
+	bool ret = true;
+
+	rcu_read_lock();
+	if (*epoch > node->msg_info.nepoch)
+		ret = false;
+	rcu_read_unlock();
+
+	return ret;
+}
+
+// reference to node representing the machine/kernel
+extern union long_prov_elt *prov_machine;
+
+#define set_kernel_recorded(node) \
+	__set_kernel_recorded((union long_prov_elt *)node)
+static inline void __set_kernel_recorded(union long_prov_elt *node)
+{
+	node_kernel_version(node) = node_identifier(prov_machine).version;
+}
+
+#define provenance_is_kernel_recorded(node) \
+	__provenance_is_kernel_recorded((union long_prov_elt *)node)
+static inline bool __provenance_is_kernel_recorded(union long_prov_elt *node)
+{
+	if (node_kernel_version(node) < node_identifier(prov_machine).version)
+		return false;
+	return true;
+}
+
+extern struct lsm_blob_sizes provenance_blob_sizes;
+static inline struct provenance *provenance_cred(const struct cred *cred)
+{
+	return cred->security + provenance_blob_sizes.lbs_cred;
+}
+
+static inline struct provenance *provenance_task(const struct task_struct *task)
+{
+	return task->security + provenance_blob_sizes.lbs_task;
+}
+
+static inline struct provenance *provenance_cred_from_task(
+	struct task_struct *task)
+{
+	struct provenance *prov;
+	const struct cred *cred = get_task_cred(task);
+
+	prov = cred->security + provenance_blob_sizes.lbs_cred;
+	put_cred(cred); // Release cred.
+	return prov;
+}
+
+static inline struct provenance *provenance_file(const struct file *file)
+{
+	return file->f_security + provenance_blob_sizes.lbs_file;
+}
+
+static inline struct provenance *provenance_inode(
+	const struct inode *inode)
+{
+	if (unlikely(!inode->i_security))
+		return NULL;
+	return inode->i_security + provenance_blob_sizes.lbs_inode;
+}
+
+static inline struct provenance *provenance_msg_msg(
+	const struct msg_msg *msg_msg)
+{
+	return msg_msg->security + provenance_blob_sizes.lbs_msg_msg;
+}
+
+static inline struct provenance *provenance_ipc(
+	const struct kern_ipc_perm *ipc)
+{
+	return ipc->security + provenance_blob_sizes.lbs_ipc;
+}
+
+static inline struct provenance *provenance_superblock(
+	const struct super_block *superblock)
+{
+	return superblock->s_security + provenance_blob_sizes.lbs_superblock;
+}
+#endif
diff --git a/security/provenance/include/provenance_filter.h b/security/provenance/include/provenance_filter.h
new file mode 100644
index 000000000..add66f160
--- /dev/null
+++ b/security/provenance/include/provenance_filter.h
@@ -0,0 +1,319 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_FILTER_H
+#define _PROVENANCE_FILTER_H
+
+#include <uapi/linux/provenance.h>
+#include <uapi/linux/provenance_fs.h>
+
+#include "provenance_policy.h"
+#include "provenance_ns.h"
+
+#define HIT_FILTER(filter, data)        ((filter & data) != 0)
+
+#define filter_node(node) \
+	__filter_node(prov_policy.prov_node_filter, node)
+#define filter_propagate_node(node) \
+	__filter_node(prov_policy.prov_propagate_node_filter, node)
+
+/*!
+ * @brief This function decides whether or not a node should be filtered.
+ *
+ * The decision is based on three criteria:
+ * 1. If provenance capture is not enable, then the node should be filtered out.
+ * 2. If the node is set to be opaque, then it should be filtered out.
+ * 3. If the node hits the given filter, then it should be filtered out.
+ * If one of the above criteria is met, then the node should be filtered out.
+ * Otherwise, it should be recorded.
+ * @param filter The supplied filter to be checked against the node.
+ * @param node The node in question (i.e., whether or not to be filtered).
+ * @return true (i.e., should be filtered out) or false (i.e., should not be
+ * filtered out).
+ *
+ */
+static __always_inline bool __filter_node(uint64_t filter, prov_entry_t *node)
+{
+	if (!prov_policy.prov_enabled)
+		return true;
+	if (provenance_is_opaque(node))
+		return true;
+	if (HIT_FILTER(filter, node_identifier(node).type))
+		return true;
+	return false;
+}
+
+/*!
+ * @brief If the relation type is VERSION_TASK or VERSION or NAMED or
+ * NAMED_PROCESS, updating a node's version is unnecessary.
+ * @param relation_type The type of the relation (i.e., edge)
+ *
+ */
+static __always_inline bool filter_update_node(const uint64_t relation_type)
+{
+	if (relation_type == RL_VERSION_TASK)
+		return true;
+	if (relation_type == RL_VERSION)
+		return true;
+	if (relation_type == RL_NAMED)
+		return true;
+	return false;
+}
+
+/*!
+ * @brief This function decides whether or not a relation (i.e., edge) should be
+ * filtered.
+ *
+ * Based on the user supplied filter, a relation (i.e., edge) may be filtered
+ * out so as not to be recorded.
+ * User supplies filter criterion based on the categories of the relations.
+ * There are four categories of the relations: "derived", "generated", "used",
+ * and "informed".
+ * Each category has its own filter supplied by the user.
+ * Depending on the type of the current relation in question, test if the type
+ * of the relation hits the filter (i.e., should be filtered out).
+ * @param type The type of the relation (i.e., edge).
+ * @return true if the relation should be filtered out (i.e., not recorded) or
+ * false if otherwise.
+ *
+ */
+static __always_inline bool filter_relation(const uint64_t type)
+{
+	if (prov_is_derived(type)) {
+		if (HIT_FILTER(prov_policy.prov_derived_filter, type))
+			return true;
+	} else if (prov_is_generated(type)) {
+		if (HIT_FILTER(prov_policy.prov_generated_filter, type))
+			return true;
+	} else if (prov_is_used(type)) {
+		if (HIT_FILTER(prov_policy.prov_used_filter, type))
+			return true;
+	} else if (prov_is_informed(type))
+		if (HIT_FILTER(prov_policy.prov_informed_filter, type))
+			return true;
+	return false;
+}
+
+/*!
+ * @brief This function decides whether or not tracking should propagate.
+ *
+ * Based on the user supplied filter, a relation (i.e., edge) may be filtered
+ * if it is tracked in the propagation.
+ * User supplies filter criterion based on the categories of the relations as
+ * in the "filter_relation" function.
+ * Depending on the type of the current relation in question, test if the type
+ * of the relation hits the filter (i.e., should be filtered out if it is part
+ * of propagation).
+ * @param type The type of the relation (i.e., edge).
+ * @return true if the relation should be filtered out during propagation or
+ * false if otherwise.
+ *
+ */
+static __always_inline bool filter_propagate_relation(uint64_t type)
+{
+	if (prov_is_derived(type)) {
+		if (HIT_FILTER(prov_policy.prov_propagate_derived_filter, type))
+			return true;
+	} else if (prov_is_generated(type)) {
+		if (HIT_FILTER(prov_policy.prov_propagate_generated_filter,
+			       type))
+			return true;
+	} else if (prov_is_used(type)) {
+		if (HIT_FILTER(prov_policy.prov_propagate_used_filter,
+			       type))
+			return true;
+	} else if (prov_is_informed(type))
+		if (HIT_FILTER(prov_policy.prov_propagate_informed_filter,
+			       type))
+			return true;
+	return false;
+}
+
+/*!
+ * @brief Whether a provenance relation between two nodes should be recorded
+ * based on the user-defined filter.
+ *
+ * If either the relation type or at least one of the two end nodes are filtered
+ * out (i.e., not to be recorded as defined by the user),
+ * Then this function will return false.
+ * Otherwise, the relation should be recorded and thus the function will return
+ * true.
+ * @param type The type of the relation
+ * @param from The provenance node entry of the source node.
+ * @param to The provenance node entry of the destination node.
+ * @return True if the relation of type 'type' should be recorded; False if
+ * otherwise.
+ *
+ */
+static __always_inline bool should_record_relation(const uint64_t type,
+						   prov_entry_t *from,
+						   prov_entry_t *to)
+{
+	if (filter_relation(type))
+		return false;
+	if (filter_node(from) || filter_node(to))
+		return false;
+	return true;
+}
+
+/*!
+ * @brief Define an abstract list. See concrete example below.
+ */
+#define declare_filter_list(filter_name, type) \
+	struct filter_name {		       \
+		struct list_head list;	       \
+		struct type filter;	       \
+	};				       \
+	extern struct list_head filter_name;
+
+/*!
+ * @brief Define an abstract operation that returns op value of an item in a
+ * list. See concrete example below.
+ */
+#define declare_filter_whichOP(function_name, type, variable)		\
+	static __always_inline uint8_t function_name(uint32_t variable)	\
+	{								\
+		struct list_head *listentry, *listtmp;			\
+		struct type *tmp;					\
+		list_for_each_safe(listentry, listtmp, &type) {		\
+			tmp = list_entry(listentry, struct type, list);	\
+			if (tmp->filter.variable == variable) {		\
+				return tmp->filter.op; }		\
+		}							\
+		return 0;						\
+	}
+
+/*!
+ * @brief Define an abstract operation that deletes an item from a list.
+ * See concrete example below.
+ */
+#define declare_filter_delete(function_name, type, variable)		  \
+	static __always_inline uint8_t function_name(struct type *f)	  \
+	{								  \
+		struct list_head *listentry, *listtmp;			  \
+		struct type *tmp;					  \
+		list_for_each_safe(listentry, listtmp, &type) {		  \
+			tmp = list_entry(listentry, struct type, list);	  \
+			if (tmp->filter.variable == f->filter.variable) { \
+				list_del(listentry);			  \
+				kfree(tmp);				  \
+				return 0;				  \
+			}						  \
+		}							  \
+		return 0;						  \
+	}
+
+/*!
+ * @brief Define an abstract operation that adds/updates the op value of an item
+ * from a list. See concrete example below.
+ */
+#define declare_filter_add_or_update(function_name, type, variable)	  \
+	static __always_inline uint8_t function_name(struct type *f)	  \
+	{								  \
+		struct list_head *listentry, *listtmp;			  \
+		struct type *tmp;					  \
+		list_for_each_safe(listentry, listtmp, &type) {		  \
+			tmp = list_entry(listentry, struct type, list);	  \
+			if (tmp->filter.variable == f->filter.variable) { \
+				tmp->filter.op = f->filter.op;		  \
+				return 0;				  \
+			}						  \
+		}							  \
+		list_add_tail(&(f->list), &type);			  \
+		return 0;						  \
+	}
+/*
+ * A list of secinfo structs (defined in /include/uapi/linux/provenance.h, same
+ * as the following)
+ */
+declare_filter_list(secctx_filters, secinfo);
+
+/*
+ * Return op value of an item of a specific secid in the secctx_filters list if
+ * exists; return 0 otherwise
+ */
+declare_filter_whichOP(prov_secctx_whichOP, secctx_filters, secid);
+
+/*
+ * Delete the element in secctx_filters list with the same secid as the item
+ * given in the function argument
+ */
+declare_filter_delete(prov_secctx_delete, secctx_filters, secid);
+
+/*
+ * Add or update op value of an item of a specific secid, which is the same as
+ * the item given in the function argument.
+ */
+declare_filter_add_or_update(prov_secctx_add_or_update, secctx_filters, secid);
+
+/*!
+ * @brief Same set of operations as above but operate on "userinfo" list.
+ */
+declare_filter_list(user_filters, userinfo);
+declare_filter_whichOP(prov_uid_whichOP, user_filters, uid);
+declare_filter_delete(prov_uid_delete, user_filters, uid);
+declare_filter_add_or_update(prov_uid_add_or_update, user_filters, uid);
+
+/*!
+ * @brief Same set of operations as above but operate on "groupinfo" list.
+ */
+declare_filter_list(group_filters, groupinfo);
+declare_filter_whichOP(prov_gid_whichOP, group_filters, gid);
+declare_filter_delete(prov_gid_delete, group_filters, gid);
+declare_filter_add_or_update(prov_gid_add_or_update, group_filters, gid);
+
+/*!
+ * @brief Based on "op" value of a provenance node, decide whether it should be
+ * tracked/propagated/opaque.
+ *
+ * "op" value is contingent upon "op" values of:
+ * 1. ns (i.e., namespace) elements: ipcns, mntns, pidns, netns, cgroupns,
+ * if the node is of type ENT_PROC, and
+ * 2. secctx (i.e., security context) element if it has secctx, and
+ * 3. uid element if it has uid, and
+ * 4. gid element if it has gid.
+ * @param prov The provenance node in question.
+ *
+ */
+static __always_inline void apply_target(union prov_elt *prov)
+{
+	uint8_t op = 0;
+
+	// track based on ns
+	if (prov_type(prov) == ACT_TASK)
+		op |= prov_ns_whichOP(prov->task_info.utsns,
+				      prov->task_info.ipcns,
+				      prov->task_info.mntns,
+				      prov->task_info.pidns,
+				      prov->task_info.netns,
+				      prov->task_info.cgroupns);
+
+	if (prov_has_secid(node_type(prov)))
+		op |= prov_secctx_whichOP(node_secid(prov));
+
+	if (prov_has_uidgid(node_type(prov))) {
+		op |= prov_uid_whichOP(node_uid(prov));
+		op |= prov_gid_whichOP(node_gid(prov));
+	}
+
+	if (unlikely(op != 0)) {
+		if ((op & PROV_SET_TRACKED) != 0)
+			set_tracked(prov);
+		if ((op & PROV_SET_PROPAGATE) != 0)
+			set_propagate(prov);
+		if ((op & PROV_SET_OPAQUE) != 0)
+			set_opaque(prov);
+	}
+}
+#endif
diff --git a/security/provenance/include/provenance_inode.h b/security/provenance/include/provenance_inode.h
new file mode 100644
index 000000000..7e3a0d8f6
--- /dev/null
+++ b/security/provenance/include/provenance_inode.h
@@ -0,0 +1,604 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_INODE_H
+#define _PROVENANCE_INODE_H
+
+#include <linux/file.h>
+#include <linux/fs.h>
+#include <linux/namei.h>
+#include <linux/xattr.h>
+
+#include "provenance_record.h"
+#include "provenance_policy.h"
+#include "provenance_filter.h"
+#include "memcpy_ss.h"
+
+#define is_inode_dir(inode)             S_ISDIR(inode->i_mode)
+#define is_inode_socket(inode)          S_ISSOCK(inode->i_mode)
+#define is_inode_file(inode)            S_ISREG(inode->i_mode)
+
+/*!
+ * @brief Update the type of the provenance inode node based on the mode of the
+ * inode, and create a version relation between old and new provenance node.
+ *
+ * Based on the mode of the inode, determine the type of the provenance inode
+ * node, choosing from:
+ * ENT_INODE_BLOCK, ENT_INODE_CHAR, ENT_INODE_DIRECTORY, ENT_INODE_PIPE,
+ * ENT_INODE_LINK, ENT_INODE_FILE, ENT_INODE_SOCKET.
+ * Create a new provenance node with the updated type, and a updated version and
+ * a RL_VERSION relation between them if certain criteria are met.
+ * Otherwise, RL_VERSION relation is not needed and we simply update the node
+ * type and mode information.
+ * The operation is done in a nested spin_lock to avoid concurrency.
+ * The criteria are:
+ * 1. The inode_info.mode is not 0 (when mode is zero, this is the first time we
+ * record the inode), and
+ * 2. The inode_info.mode is not already up-to-date, and
+ * 3. The inode is set to be recorded.
+ * @param mode The new updated mode.
+ * @param prov The provenance node to be updated.
+ *
+ */
+static inline void update_inode_type(uint16_t mode, struct provenance *prov)
+{
+	union prov_elt old_prov;
+	uint64_t type = ENT_INODE_UNKNOWN;
+	unsigned long irqflags;
+
+	if (S_ISBLK(mode))
+		type = ENT_INODE_BLOCK;
+	else if (S_ISCHR(mode))
+		type = ENT_INODE_CHAR;
+	else if (S_ISDIR(mode))
+		type = ENT_INODE_DIRECTORY;
+	else if (S_ISFIFO(mode))
+		type = ENT_INODE_PIPE;
+	else if (S_ISLNK(mode))
+		type = ENT_INODE_LINK;
+	else if (S_ISREG(mode))
+		type = ENT_INODE_FILE;
+	else if (S_ISSOCK(mode))
+		type = ENT_INODE_SOCKET;
+	spin_lock_irqsave_nested(prov_lock(prov), irqflags,
+				 PROVENANCE_LOCK_INODE);
+	if (prov_elt(prov)->inode_info.mode != 0
+	    && prov_elt(prov)->inode_info.mode != mode
+	    && provenance_is_recorded(prov_elt(prov))) {
+		__memcpy_ss(&old_prov, sizeof(union prov_elt),
+			    prov_elt(prov), sizeof(old_prov));
+		// We update the info of the new version and record it.
+		prov_elt(prov)->inode_info.mode = mode;
+		prov_type(prov_elt(prov)) = type;
+		node_identifier(prov_elt(prov)).version++;
+		clear_recorded(prov_elt(prov));
+
+		// We record a version edge.
+		__write_relation(RL_VERSION, &old_prov, prov_elt(prov),
+				 NULL, 0);
+		clear_has_outgoing(prov_elt(prov));
+		clear_saved(prov_elt(prov));
+	}
+	prov_elt(prov)->inode_info.mode = mode;
+	prov_type(prov_elt(prov)) = type;
+	spin_unlock_irqrestore(prov_lock(prov), irqflags);
+}
+
+static inline void provenance_mark_as_opaque_dentry(const struct dentry *dentry)
+{
+	struct provenance *prov;
+
+	if (IS_ERR(dentry))
+		return;
+	prov = provenance_inode(dentry->d_inode);
+	if (prov)
+		set_opaque(prov_elt(prov));
+}
+
+/*!
+ * @brief Set the provenance node to be opaque based on the name given in the
+ * argument.
+ *
+ * Based on the given name, we will perform a kernal path lookup and get the
+ * provenance information of that name.
+ * Then we will set the provenance node as opaque.
+ * @param name The name of the file object to be set opaque. Note that every
+ * object in Linux is a file.
+ *
+ */
+static inline void provenance_mark_as_opaque(const char *name)
+{
+	struct path path;
+
+	if (kern_path(name, LOOKUP_FOLLOW, &path)) {
+		pr_err("Provenance: Failed file look up (%s).", name);
+		return;
+	}
+	provenance_mark_as_opaque_dentry(path.dentry);
+}
+
+/*!
+ * @brief Record the name of a provenance node from directory entry.
+ *
+ * Unless specific criteria are met,
+ * the name of the provenance node is looked up through "dentry_path_raw" and
+ * function "record_node_name" is called,
+ * to associate the name of the provenance to the provenance node itself as a
+ * relation.
+ * The criteria to be met are:
+ * 1. The name of the provenance node has been recorded already, or
+ * 2. The provenance node itself has not been recorded.
+ * @param dentry Pointer to dentry of the base directory.
+ * @param prov The provenance node in question.
+ * @return 0 if no error occurred. -ENOMEM if no memory to store the name of the
+ * provenance node. PTR_ERR if path lookup failed.
+ *
+ */
+static inline int record_inode_name_from_dentry(struct dentry *dentry,
+						struct provenance *prov,
+						bool force)
+{
+	char *buffer;
+	char *ptr;
+	int rc;
+
+	if (provenance_is_name_recorded(prov_elt(prov)) ||
+	    !provenance_is_recorded(prov_elt(prov)))
+		return 0;
+
+	buffer = kcalloc(PATH_MAX, sizeof(char), GFP_ATOMIC);
+	if (!buffer)
+		return -ENOMEM;
+	ptr = dentry_path_raw(dentry, buffer, PATH_MAX);
+	if (IS_ERR(ptr))
+		return PTR_ERR(ptr);
+	rc = record_node_name(prov, ptr, force);
+	kfree(buffer);
+	return rc;
+}
+
+/*!
+ * @brief Record the name of the provenance node directly from the inode.
+ *
+ * Unless the name of the provenance node has already been recorded,
+ * or that the provenance node itself is not recorded,
+ * the function will attempt to create a name node for the provenance node by
+ * calling "record_inode_name_from_dentry".
+ * To call that function, we will find a hashed alias of inode, which is a
+ * dentry struct, and then pass that information to the function.
+ * @param inode The inode whose name we look up and assocaite it with the
+ * provenance node.
+ * @param prov The provenance node in question.
+ * @return 0 if no error occurred or if "dentry" returns NULL.
+ *
+ */
+static inline int record_inode_name(struct inode *inode,
+				    struct provenance *prov)
+{
+	struct dentry *dentry;
+	int rc;
+
+	if (provenance_is_name_recorded(prov_elt(prov))
+	    || !provenance_is_recorded(prov_elt(prov)))
+		return 0;
+	dentry = d_find_alias(inode);
+	// We did not find a dentry, not sure if it should ever happen.
+	if (!dentry)
+		return 0;
+	rc = record_inode_name_from_dentry(dentry, prov, false);
+	dput(dentry);
+	return rc;
+}
+
+/*!
+ * @brief Update provenance information of an inode node.
+ *
+ * Update provenance entry of an inode node unless that provenance node is set
+ * to be opaque.
+ * The update operation includes:
+ * 1. Record the name of the inode, which creates a named relation between the
+ * name node and the inode.
+ * 2. Update i_ino information in inode_info structure.
+ * 3. Update uid and gid information of the inode node.
+ * 4. Update secid information of the inode node.
+ * 5. Update the type of the inode node itself.
+ * @param inode The inode in question whose provenance entry to be updated.
+ *
+ */
+static inline void refresh_inode_provenance(struct inode *inode,
+					    struct provenance *prov)
+{
+	if (provenance_is_opaque(prov_elt(prov)))
+		return;
+	prov_elt(prov)->inode_info.ino = inode->i_ino;
+	node_uid(prov_elt(prov)) = __kuid_val(inode->i_uid);
+	node_gid(prov_elt(prov)) = __kgid_val(inode->i_gid);
+	security_inode_getsecid(inode, &(prov_elt(prov)->inode_info.secid));
+	update_inode_type(inode->i_mode, prov);
+}
+
+/*!
+ * @brief Initialize the provenance of the inode.
+ *
+ * We do not initialize the inode if it has already been initialized, or
+ * failure occurred.
+ * Provenance extended attributes are copied to the inode provenance in this
+ * function, unless the inode does not support xattr.
+ * @param inode The inode structure in which we initialize provenance.
+ * @param opt_dentry The directory entry pointer.
+ * @return 0 if no error occurred; -ENOMEM if no more memory to allocate for the
+ * provenance entry. Other error codes inherited or unknown.
+ *
+ */
+static inline int inode_init_provenance(struct inode *inode,
+					struct dentry *opt_dentry,
+					struct provenance *prov)
+{
+	union prov_elt *buf;
+	struct dentry *dentry;
+	int rc = 0;
+
+	if (provenance_is_initialized(prov_elt(prov)))
+		return 0;
+	spin_lock_nested(prov_lock(prov), PROVENANCE_LOCK_INODE);
+	if (provenance_is_initialized(prov_elt(prov))) {
+		spin_unlock(prov_lock(prov));
+		return 0;
+	}
+
+	set_initialized(prov_elt(prov));
+	spin_unlock(prov_lock(prov));
+	update_inode_type(inode->i_mode, prov);
+	// xattr not supported on this inode
+	if (!(inode->i_opflags & IOP_XATTR))
+		return 0;
+	if (opt_dentry)
+		dentry = dget(opt_dentry);
+	else
+		dentry = d_find_alias(inode);
+	if (!dentry)
+		return 0;
+	buf = kmalloc(sizeof(union prov_elt), GFP_NOFS);
+	if (!buf) {
+		clear_initialized(prov_elt(prov));
+		dput(dentry);
+		return -ENOMEM;
+	}
+	rc = __vfs_getxattr(dentry, inode, XATTR_NAME_PROVENANCE,
+			    buf, sizeof(union prov_elt));
+	dput(dentry);
+	if (rc < 0) {
+		if (rc != -ENODATA && rc != -EOPNOTSUPP) {
+			clear_initialized(prov_elt(prov));
+			goto free_buf;
+		} else {
+			rc = 0;
+			goto free_buf;
+		}
+	}
+	__memcpy_ss(prov_elt(prov), sizeof(union prov_elt),
+		    buf, sizeof(union prov_elt));
+	rc = 0;
+free_buf:
+	kfree(buf);
+	return rc;
+}
+
+/*!
+ * @brief This function returns the provenance of an inode.
+ *
+ * This function either initialize the provenance of the inode
+ * (if not initialized) and/or refreshes the provenance of the inode if needed.
+ * If the function can sleep, provenance information of the inode should be
+ * refreshed.
+ * @param inode The inode in question.
+ * @param may_sleep Bool value signifies whether this function can sleep.
+ * @return provenance struct pointer.
+ *
+ * @todo Error checking in this function should be included since
+ * "inode_init_provenance" can fail (i.e., non-zero return value).
+ * @todo We may not want to update (call refresh_inode_provenance) all the time.
+ */
+static inline struct provenance *get_inode_provenance(struct inode *inode,
+						      bool may_sleep)
+{
+	struct provenance *iprov = provenance_inode(inode);
+
+	might_sleep_if(may_sleep);
+	if (!provenance_is_initialized(prov_elt(iprov)) && may_sleep)
+		inode_init_provenance(inode, NULL, iprov);
+	if (may_sleep) {
+		refresh_inode_provenance(inode, iprov);
+		record_inode_name(inode, iprov);
+	}
+	return iprov;
+}
+
+/*!
+ * @brief This function returns the provenance of the given directory entry
+ * based on its inode.
+ *
+ * This function ultimately calls "get_inode_provenance" function.
+ * We find the inode of the dentry (if this dentry were to be opened as a file)
+ * by calling "d_backing_inode" function.
+ * @param dentry The dentry whose provenance is to be returned.
+ * @param may_sleep Bool value used in "get_inode_provenance" function
+ * (See above)
+ * @return provenance struct pointer or NULL if inode does not exist.
+ *
+ */
+static inline struct provenance *get_dentry_provenance(struct dentry *dentry,
+						       bool may_sleep)
+{
+	struct inode *inode = d_backing_inode(dentry);
+
+	if (!inode)
+		return NULL;
+	return get_inode_provenance(inode, may_sleep);
+}
+
+/*!
+ * @brief This function returns the provenance of the given file based on its
+ * inode.
+ *
+ * This function ultimately calls "get_inode_provenance" function.
+ * We find the inode of the file by calling "file_inode" function.
+ * @param file The file whose provenance is to be returned.
+ * @param may_sleep Bool value used in "get_inode_provenance" function
+ * (See above)
+ * @return provenance struct pointer or NULL if inode does not exist.
+ *
+ */
+static inline struct provenance *get_file_provenance(struct file *file,
+						     bool may_sleep)
+{
+	struct inode *inode = file_inode(file);
+
+	if (!inode)
+		return NULL;
+	return get_inode_provenance(inode, may_sleep);
+}
+
+static inline void save_provenance(struct dentry *dentry)
+{
+	struct provenance *prov;
+	union prov_elt buf;
+
+	if (!dentry)
+		return;
+	prov = get_dentry_provenance(dentry, false);
+	if (!prov)
+		return;
+	spin_lock(prov_lock(prov));
+	// not initialised or already saved
+	if (!provenance_is_initialized(prov_elt(prov))
+	    || provenance_is_saved(prov_elt(prov))) {
+		spin_unlock(prov_lock(prov));
+		return;
+	}
+	__memcpy_ss(&buf, sizeof(union prov_elt),
+		    prov_elt(prov), sizeof(union prov_elt));
+	set_saved(prov_elt(prov));
+	spin_unlock(prov_lock(prov));
+	clear_recorded(&buf);
+	clear_name_recorded(&buf);
+	if (!dentry)
+		return;
+	__vfs_setxattr_noperm(&init_user_ns, dentry, XATTR_NAME_PROVENANCE,
+			      &buf, sizeof(union prov_elt), 0);
+}
+
+/*!
+ * @brief This function records relations related to setting extended file
+ * attributes.
+ *
+ * xattr is a long provenance entry and is transient (i.e., freed after
+ * recorded).
+ * Unless certain criteria are met, several relations are recorded when a
+ * process attempts to write xattr of a file:
+ * 1. Record a RL_PROC_READ relation between a task process and its cred.
+ * Information flows from cred to the task process, and
+ * 2. Record a given type @type of relation between the process and xattr
+ * provenance entry. Information flows from the task to the xattr, and
+ * 3-1. If the given type is RL_SETXATTR, then record a RL_SETXATTR_INODE
+ * relation between xattr and the file inode. Information flows from xattr
+ * to inode;
+ * 3-2. otherwise (the only other case is that the given type is
+ * RL_RMVXATTR_INODE), record a RL_RMVXATTR_INODE relation between xattr and the
+ * file inode. Information flows from xattr to inode.
+ * The criteria to be met so as not to record the relations are:
+ * 1. If any of the cred, task, and inode provenance are not tracked and if the
+ * capture all is not set, or
+ * 2. If the relation @type should not be recorded, or
+ * 3. Failure occurred.
+ * xattr name and value pair is recorded in the long provenance entry.
+ * @param type The type of relation to be recorded.
+ * @param iprov The inode provenance entry.
+ * @param tprov The task provenance entry.
+ * @param cprov The cred provenance entry.
+ * @param name The name of the extended attribute.
+ * @param value The value of that attribute.
+ * @param size The size of the value.
+ * @param flags The flags passed by LSM hooks.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated from
+ * long provenance cache to create a new long provenance entry. Other error
+ * codes from "record_relation" function or unknown.
+ *
+ */
+static __always_inline int record_write_xattr(uint64_t type,
+					      struct provenance *iprov,
+					      struct provenance *tprov,
+					      struct provenance *cprov,
+					      const char *name,
+					      const void *value,
+					      size_t size,
+					      const uint64_t flags)
+{
+	union long_prov_elt *xattr;
+	int rc = 0;
+
+	if (!provenance_is_tracked(prov_elt(iprov))
+	    && !provenance_is_tracked(prov_elt(tprov))
+	    && !provenance_is_tracked(prov_elt(cprov))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(type, prov_entry(cprov), prov_entry(iprov)))
+		return 0;
+	xattr = alloc_long_provenance(ENT_XATTR, 0);
+	if (!xattr)
+		return -ENOMEM;
+	__memcpy_ss(xattr->xattr_info.name, PROV_XATTR_NAME_SIZE,
+		    name, PROV_XATTR_NAME_SIZE - 1);
+	xattr->xattr_info.name[PROV_XATTR_NAME_SIZE - 1] = '\0';
+	if (value) {
+		if (size < PROV_XATTR_VALUE_SIZE) {
+			xattr->xattr_info.size = size;
+			__memcpy_ss(xattr->xattr_info.value,
+				    PROV_XATTR_VALUE_SIZE,
+				    value,
+				    size);
+		} else {
+			xattr->xattr_info.size = PROV_XATTR_VALUE_SIZE;
+			__memcpy_ss(xattr->xattr_info.value,
+				    PROV_XATTR_VALUE_SIZE,
+				    value,
+				    PROV_XATTR_VALUE_SIZE);
+		}
+	}
+	rc = record_relation(RL_PROC_READ, prov_entry(cprov),
+			     prov_entry(tprov), NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = record_relation(type, prov_entry(tprov), xattr, NULL, flags);
+	if (rc < 0)
+		goto out;
+	if (type == RL_SETXATTR)
+		rc = record_relation(RL_SETXATTR_INODE, xattr,
+				     prov_entry(iprov), NULL, flags);
+	else
+		rc = record_relation(RL_RMVXATTR_INODE, xattr,
+				     prov_entry(iprov), NULL, flags);
+out:
+	free_long_provenance(xattr);
+	return rc;
+}
+
+/*!
+ * @brief This function records relations related to reading extended file
+ * attributes.
+ *
+ * xattr is a long provenance entry and is transient (i.e., freed after
+ * recorded).
+ * Unless certain criteria are met, several relations are recorded when a
+ * process attempts to read xattr of a file:
+ * 1. Record a RL_GETXATTR_INODE relation between inode and xattr. Information
+ * flows from inode to xattr (to get xattr of an inode).
+ * 2. Record a RL_GETXATTR relation between xattr and task process. Information
+ * flows from xattr to the task (task reads the xattr).
+ * 3. Record a RL_PROC_WRITE relation between task and its cred. Information
+ * flows from task to its cred.
+ * The criteria to be met so as not to record the relations are:
+ * 1. If any of the cred, task, and inode provenance are not tracked and if the
+ * capture all is not set, or
+ * 2. If the relation RL_GETXATTR should not be recorded, or
+ * 3. Failure occurred.
+ * @param cprov The cred provenance entry.
+ * @param tprov The task provenance entry.
+ * @param name The name of the extended attribute.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated
+ * from long provenance cache to create a new long provenance entry. Other error
+ * codes from "record_relation" function or unknown.
+ *
+ */
+static __always_inline int record_read_xattr(struct provenance *cprov,
+					     struct provenance *tprov,
+					     struct provenance *iprov,
+					     const char *name)
+{
+	union long_prov_elt *xattr;
+	int rc = 0;
+
+	if (!provenance_is_tracked(prov_elt(iprov))
+	    && !provenance_is_tracked(prov_elt(tprov))
+	    && !provenance_is_tracked(prov_elt(cprov))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(RL_GETXATTR, prov_entry(iprov),
+				    prov_entry(cprov)))
+		return 0;
+	xattr = alloc_long_provenance(ENT_XATTR, 0);
+	if (!xattr) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	__memcpy_ss(xattr->xattr_info.name, PROV_XATTR_NAME_SIZE,
+		    name, PROV_XATTR_NAME_SIZE - 1);
+	xattr->xattr_info.name[PROV_XATTR_NAME_SIZE - 1] = '\0';
+
+	rc = record_relation(RL_GETXATTR_INODE, prov_entry(iprov),
+			     xattr, NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = record_relation(RL_GETXATTR, xattr,
+			     prov_entry(tprov), NULL, 0);
+	if (rc < 0)
+		goto out;
+	rc = record_relation(RL_PROC_WRITE, prov_entry(tprov),
+			     prov_entry(cprov), NULL, 0);
+out:
+	free_long_provenance(xattr);
+	return rc;
+}
+
+#define FILE__EXECUTE           0x00000001UL
+#define FILE__READ              0x00000002UL
+#define FILE__APPEND            0x00000004UL
+#define FILE__WRITE             0x00000008UL
+#define DIR__SEARCH             0x00000010UL
+#define DIR__WRITE              0x00000020UL
+#define DIR__READ               0x00000040UL
+
+/*!
+ * @brief Helper function to return permissions of a file/directory from mask.
+ *
+ * @param mode The mode of the inode.
+ * @param mask The permission mask.
+ * @return The permission of the file/directory/socket....
+ *
+ */
+static inline uint32_t file_mask_to_perms(int mode, unsigned int mask)
+{
+	uint32_t av = 0;
+
+	if (!S_ISDIR(mode)) {
+		if (mask & MAY_EXEC)
+			av |= FILE__EXECUTE;
+		if (mask & MAY_READ)
+			av |= FILE__READ;
+		if (mask & MAY_APPEND)
+			av |= FILE__APPEND;
+		else if (mask & MAY_WRITE)
+			av |= FILE__WRITE;
+	} else {
+		if (mask & MAY_EXEC)
+			av |= DIR__SEARCH;
+		if (mask & MAY_WRITE)
+			av |= DIR__WRITE;
+		if (mask & MAY_READ)
+			av |= DIR__READ;
+	}
+
+	return av;
+}
+#endif
diff --git a/security/provenance/include/provenance_machine.h b/security/provenance/include/provenance_machine.h
new file mode 100644
index 000000000..4a557fac0
--- /dev/null
+++ b/security/provenance/include/provenance_machine.h
@@ -0,0 +1,24 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_MACHINE_H
+#define _PROVENANCE_MACHINE_H
+
+#include <uapi/linux/provenance.h>
+
+extern union long_prov_elt *prov_machine;
+
+void init_prov_machine(void);
+void refresh_prov_machine(void);
+#endif
diff --git a/security/provenance/include/provenance_net.h b/security/provenance/include/provenance_net.h
new file mode 100644
index 000000000..2d6c57b94
--- /dev/null
+++ b/security/provenance/include/provenance_net.h
@@ -0,0 +1,411 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_NET_H
+#define _PROVENANCE_NET_H
+
+#include <net/sock.h>
+#include <net/ip.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_ipv6.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/udp.h>
+#include <linux/skbuff.h>
+
+#include "provenance.h"
+#include "provenance_policy.h"
+#include "provenance_inode.h"
+#include "memcpy_ss.h"
+
+/*!
+ * @brief Returns the provenance entry pointer of the inode associated with
+ * sock.
+ *
+ * @param sock The socket structure whose provenance to be obtained.
+ * @return The provenance entry pointer of the socket or NULL if it does not
+ * exist.
+ *
+ */
+static inline struct provenance *get_socket_inode_provenance(
+	struct socket *sock)
+{
+	struct inode *inode = SOCK_INODE(sock);
+	struct provenance *iprov = NULL;
+
+	if (inode)
+		iprov = get_inode_provenance(inode, false);
+	return iprov;
+}
+
+/*!
+ * @brief Returns the provenance entry pointer of the inode associated with sk.
+ *
+ * This function calls the function get_socket_inode_provenance.
+ * This is becasue only socket has an inode associated with it.
+ * We obtain the socket structure from sk structure: @sk->sk_socket.
+ * We obtain socket from sock and return the provenance entry pointer.
+ * @param sk The sock structure whose provenance to be obtained.
+ * @return The provenance entry pointer of the corresponding socket.
+ *
+ */
+static inline struct provenance *get_sk_inode_provenance(struct sock *sk)
+{
+	struct socket *sock = sk->sk_socket;
+
+	if (!sock)
+		return NULL;
+	return get_socket_inode_provenance(sock);
+}
+
+/*!
+ * @brief Return the provenance entry pointer of sk.
+ *
+ * @param sk The sock structure.
+ * @return The provenance entry pointer.
+ *
+ */
+static inline struct provenance *get_sk_provenance(struct sock *sk)
+{
+	struct provenance *pprov = sk->sk_provenance;
+
+	if (node_type(prov_elt(pprov)) != ACT_TASK)
+		return NULL;
+
+	return pprov;
+}
+
+#define ihlen(ih)    (ih->ihl * 4)
+
+/*!
+ * @brief Extract TCP header information and store it in packet_identifier
+ * struct of provenance entry.
+ *
+ * @param skb The socket buffer.
+ * @param ih The IP header.
+ * @param offset
+ * @param id The packet identifier structure of provenance entry.
+ *
+ */
+static __always_inline void __extract_tcp_info(struct sk_buff *skb,
+					       struct iphdr *ih,
+					       int offset,
+					       struct packet_identifier *id)
+{
+	struct tcphdr _tcph;
+	struct tcphdr *th;
+	int tcpoff;
+
+	if (ntohs(ih->frag_off) & IP_OFFSET)
+		return;
+	tcpoff = offset + ihlen(ih);    // Point to tcp packet.
+	th = skb_header_pointer(skb, tcpoff, sizeof(_tcph), &_tcph);
+	if (!th)
+		return;
+	id->snd_port = (__force uint16_t)th->source;
+	id->rcv_port = (__force uint16_t)th->dest;
+	id->seq = (__force uint32_t)th->seq;
+}
+
+/*!
+ * @brief Extract UPD header information and store it in packet_identifier
+ * struct of provenance entry.
+ *
+ * @param skb The socket buffer.
+ * @param ih The IP header.
+ * @param offset
+ * @param id The packet identifier structure of provenance entry.
+ *
+ */
+static __always_inline void __extract_udp_info(struct sk_buff *skb,
+					       struct iphdr *ih,
+					       int offset,
+					       struct packet_identifier *id)
+{
+	struct udphdr _udph;
+	struct udphdr *uh;
+	int udpoff;
+
+	if (ntohs(ih->frag_off) & IP_OFFSET)
+		return;
+	udpoff = offset + ihlen(ih);  // point to udp packet
+	uh = skb_header_pointer(skb, udpoff, sizeof(_udph), &_udph);
+	if (!uh)
+		return;
+	id->snd_port = (__force uint16_t)uh->source;
+	id->rcv_port = (__force uint16_t)uh->dest;
+}
+
+/*!
+ * @brief Parse network packet information @skb into a packet provenance entry
+ * @prov.
+ *
+ * We parse a series of IP information from @skb and create a provenance entry
+ * node ENT_PACKET.
+ * Depending on the type of the packet (i.e., TCP or UDP), we call either
+ * __extract_tcp_info or __extract_udp_info subfunction to parse.
+ * @param skb Socket buffer where packet information lies.
+ * @param prov The provenance entry pointer.
+ * @return 0 if no error occurred; -EINVAL if error during obtaining packet
+ * meta-data; Other error codes unknown.
+ *
+ */
+static __always_inline struct provenance *provenance_alloc_with_ipv4_skb(
+	uint64_t type, struct sk_buff *skb)
+{
+	struct provenance *prov;
+	int offset;
+	struct iphdr _iph;
+	struct iphdr *ih;
+
+	offset = skb_network_offset(skb);
+	// We obtain the IP header.
+	ih = skb_header_pointer(skb, offset, sizeof(_iph), &_iph);
+	if (!ih)
+		return NULL;
+
+	if (ihlen(ih) < sizeof(_iph))
+		return NULL;
+
+	prov =  kmem_cache_zalloc(provenance_cache, GFP_ATOMIC);
+
+	packet_identifier(prov_elt(prov)).type = type;
+	// Collect IP element of prov identifier.
+	// force parse endian casting
+	packet_identifier(prov_elt(prov)).id = (__force uint16_t)ih->id;
+	packet_identifier(prov_elt(prov)).snd_ip = (__force uint32_t)ih->saddr;
+	packet_identifier(prov_elt(prov)).rcv_ip = (__force uint32_t)ih->daddr;
+	packet_identifier(prov_elt(prov)).protocol = ih->protocol;
+	packet_info(prov_elt(prov)).len = (__force size_t)ih->tot_len;
+
+	switch (ih->protocol) {
+	case IPPROTO_TCP:
+		__extract_tcp_info(skb, ih,
+				   offset, &packet_identifier(prov_elt(prov)));
+		break;
+	case IPPROTO_UDP:
+		__extract_udp_info(skb, ih,
+				   offset, &packet_identifier(prov_elt(prov)));
+		break;
+	default:
+		break;
+	}
+	call_provenance_alloc(prov_entry(prov));
+	return prov;
+}
+
+struct ipv4_filters {
+	struct list_head list;
+	struct prov_ipv4_filter filter;
+};
+
+extern struct list_head ingress_ipv4filters;
+extern struct list_head egress_ipv4filters;
+
+/*!
+ * @brief Returns op value of the filter of a specific IP and/or port.
+ *
+ * This function goes through a filter list,
+ * and attempts to match the given @ip and @port.
+ * If matched, the op value of the matched element will be returned.
+ * @param filters The list to go through.
+ * @param ip The IP to match.
+ * @param port The port to match.
+ * @return 0 if not found or the op value of the matched element in the list.
+ *
+ */
+static inline uint8_t prov_ipv4_whichOP(struct list_head *filters,
+					uint32_t ip,
+					uint32_t port)
+{
+	struct list_head *listentry, *listtmp;
+	struct ipv4_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, filters) {
+		tmp = list_entry(listentry, struct ipv4_filters, list);
+		// Match IP
+		if ((tmp->filter.mask & ip)
+		    == (tmp->filter.mask & tmp->filter.ip))
+			// Any port or a specific match
+			if (tmp->filter.port == 0 || tmp->filter.port == port)
+				return tmp->filter.op;
+	}
+	return 0;
+}
+
+/*!
+ * @brief Delete an element in the filter list that matches a specific filter.
+ *
+ * This function goes through a filter list,
+ * and attempts to match the given filter.
+ * If matched, the matched element will be removed from the list.
+ * @param filters The list to go through.
+ * @param f The filter to match its mask, ip and port.
+ * @return Always return 0.
+ *
+ */
+static inline uint8_t prov_ipv4_delete(struct list_head *filters,
+				       struct ipv4_filters *f)
+{
+	struct list_head *listentry, *listtmp;
+	struct ipv4_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, filters) {
+		tmp = list_entry(listentry, struct ipv4_filters, list);
+		if (tmp->filter.mask == f->filter.mask &&
+		    tmp->filter.ip == f->filter.ip &&
+		    tmp->filter.port == f->filter.port) {
+			list_del(listentry);
+			kfree(tmp);
+			return 0;       // Should only get one.
+		}
+	}
+	return 0;
+}
+
+/*!
+ * @brief Add or update an element in the filter list that matches a specific
+ * filter.
+ *
+ * This function goes through a filter list,
+ * and attempts to match the given filter.
+ * If matched, the matched element's op value will be updated based on the given
+ * filter @f or the element will be added if no matches.
+ * @param filters The list to go through.
+ * @param f The filter to match its mask, ip and port.
+ * @return Always return 0.
+ *
+ */
+static inline uint8_t prov_ipv4_add_or_update(struct list_head *filters,
+					      struct ipv4_filters *f)
+{
+	struct list_head *listentry, *listtmp;
+	struct ipv4_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, filters) {
+		tmp = list_entry(listentry, struct ipv4_filters, list);
+		if (tmp->filter.mask == f->filter.mask &&
+		    tmp->filter.ip == f->filter.ip &&
+		    tmp->filter.port == f->filter.port) {
+			tmp->filter.op |= f->filter.op;
+			return 0; // you should only get one
+		}
+	}
+	// If not already in the list, we add it.
+	list_add_tail(&(f->list), filters);
+	return 0;
+}
+
+/*!
+ * @brief Record the address provenance node that binds to the socket node.
+ *
+ * This function creates a long provenance entry node ENT_ADDR that binds to the
+ * socket provenance entry @prov.
+ * Record provenance relation RL_NAMED by calling "record_relation" function.
+ * Relation will not be recorded, if:
+ * 1. The socket inode is not recorded or the name (addr) of the socket has been
+ * recorded already, or
+ * 2. Failure occurs.
+ * The information in the ENT_ADDR node is filled in from @address and @addrlen.
+ * This provenance node is short-lived and thus we free the memory once we have
+ * recorded the relation.
+ * @param address The address of the socket.
+ * @param addrlen The length of the addres.
+ * @param prov The provenance entry pointer of the socket.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated for the
+ * new long provenance node ENT_ADDR; Other error codes inherited from
+ * record_relation function.
+ *
+ */
+static __always_inline int record_address(struct sockaddr *address,
+					  int addrlen,
+					  struct provenance *prov)
+{
+	union long_prov_elt *addr_info;
+	int rc = 0;
+
+	if (provenance_is_name_recorded(prov_elt(prov))
+	    || !provenance_is_recorded(prov_elt(prov)))
+		return 0;
+
+	addr_info = alloc_long_provenance(ENT_ADDR, 0);
+	if (!addr_info) {
+		rc = -ENOMEM;
+		goto out;
+	}
+	addr_info->address_info.length = addrlen;
+	__memcpy_ss(&(addr_info->address_info.addr),
+		    sizeof(struct sockaddr_storage), address, addrlen);
+
+	rc = record_relation(RL_ADDRESSED, addr_info,
+			     prov_entry(prov), NULL, 0);
+	set_name_recorded(prov_elt(prov));
+out:
+	free_long_provenance(addr_info);
+	return rc;
+}
+
+static inline void record_packet_content(struct sk_buff *skb,
+					 struct provenance *pckprov)
+{
+	union long_prov_elt *cnt;
+
+	cnt = alloc_long_provenance(ENT_PCKCNT, 0);
+	if (!cnt)
+		return;
+
+	cnt->pckcnt_info.length = skb_end_offset(skb);
+	if (cnt->pckcnt_info.length >= PATH_MAX) {
+		cnt->pckcnt_info.truncated = PROV_TRUNCATED;
+		__memcpy_ss(cnt->pckcnt_info.content, PATH_MAX,
+			    skb->head, PATH_MAX);
+	} else
+		__memcpy_ss(cnt->pckcnt_info.content, PATH_MAX,
+			    skb->head, cnt->pckcnt_info.length);
+	record_relation(RL_PCK_CNT, cnt, prov_entry(pckprov), NULL, 0);
+	free_long_provenance(cnt);
+}
+
+
+
+static __always_inline int check_track_socket(const struct sockaddr *address,
+					      const int addrlen,
+					      struct list_head *ipv4_filters,
+					      struct provenance *cprov,
+					      struct provenance *iprov)
+{
+	struct sockaddr_in *ipv4_addr;
+	uint8_t op;
+
+	if (address->sa_family == PF_INET) {
+		ipv4_addr = (struct sockaddr_in *)address;
+		// force parse endian casting
+		op = prov_ipv4_whichOP(
+			ipv4_filters,
+			(__force uint32_t)ipv4_addr->sin_addr.s_addr,
+			(__force uint32_t)ipv4_addr->sin_port);
+		if ((op & PROV_SET_TRACKED) != 0) {
+			set_tracked(prov_elt(iprov));
+			set_tracked(prov_elt(cprov));
+		}
+		if ((op & PROV_SET_PROPAGATE) != 0) {
+			set_propagate(prov_elt(iprov));
+			set_propagate(prov_elt(cprov));
+		}
+		if ((op & PROV_SET_RECORD) != 0)
+			set_record_packet(prov_elt(iprov));
+	}
+	return 0;
+}
+#endif
diff --git a/security/provenance/include/provenance_ns.h b/security/provenance/include/provenance_ns.h
new file mode 100644
index 000000000..760e2eaf5
--- /dev/null
+++ b/security/provenance/include/provenance_ns.h
@@ -0,0 +1,139 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_NS_H
+#define _PROVENANCE_NS_H
+
+struct ns_filters {
+	struct list_head list;
+	struct nsinfo filter;
+};
+
+extern struct list_head ns_filters;
+
+/*!
+ * @brief Return the op value for a specific namespace filter in the ns_filters
+ * list.
+ *
+ * The specific namespace filter must have the same values of the namespaces as
+ * in the argument list or is IGNORE_NS.
+ * @param utsns UTS namespace.
+ * @param ipcns Interprocess communication namespace.
+ * @param mntns Mount namespace.
+ * @param pidns Process ID namespace.
+ * @param netns Network namespace.
+ * @param cgroupns Control group namespace.
+ * @return op value or 0
+ *
+ */
+static inline uint8_t prov_ns_whichOP(uint32_t utsns,
+				      uint32_t ipcns,
+				      uint32_t mntns,
+				      uint32_t pidns,
+				      uint32_t netns,
+				      uint32_t cgroupns)
+{
+	struct list_head *listentry, *listtmp;
+	struct ns_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, &ns_filters) {
+		tmp = list_entry(listentry, struct ns_filters, list);
+		if ((tmp->filter.cgroupns == cgroupns
+		     || tmp->filter.cgroupns == IGNORE_NS)
+		    && (tmp->filter.utsns == utsns
+			|| tmp->filter.utsns == IGNORE_NS)
+		    && (tmp->filter.ipcns == ipcns
+			|| tmp->filter.ipcns == IGNORE_NS)
+		    && (tmp->filter.mntns == mntns
+			|| tmp->filter.mntns == IGNORE_NS)
+		    && (tmp->filter.pidns == pidns
+			|| tmp->filter.pidns == IGNORE_NS)
+		    && (tmp->filter.netns == netns
+			|| tmp->filter.netns == IGNORE_NS))
+			return tmp->filter.op;
+	}
+	return 0;
+}
+
+/*!
+ * @brief Remove a specific namespace filter in the ns_filters list.
+ *
+ * The specific namespace filter must have the same values as the ns_filter
+ * in the argument list.
+ * @postcondition At most one element should be removed in the list.
+ * @param f The ns_filter that is checked against to remove the filter in the
+ * list.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static inline uint8_t prov_ns_delete(struct ns_filters *f)
+{
+	struct list_head *listentry, *listtmp;
+	struct ns_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, &ns_filters) {
+		tmp = list_entry(listentry, struct ns_filters, list);
+		if (tmp->filter.cgroupns == f->filter.cgroupns
+		    && tmp->filter.utsns == f->filter.utsns
+		    && tmp->filter.ipcns == f->filter.ipcns
+		    && tmp->filter.mntns == f->filter.mntns
+		    && tmp->filter.pidns == f->filter.pidns
+		    && tmp->filter.netns == f->filter.netns
+		    ) {
+			list_del(listentry);
+			kfree(tmp);
+			return 0; // You should only get one
+		}
+	}
+	return 0;
+}
+
+
+/*!
+ * @brief Update the op value of a specific namespace filter in the ns_filters
+ * list.
+ *
+ * The specific namespace filter must have the same values as the ns_filter in
+ * the argument list.
+ * The op value is updated to the same as the ns_filters in the argument list.
+ * If we cannot find the matching filter in the list, we add the filter at the
+ * tail end of the list.
+ * @postcondition At most one element should be updated in the list.
+ * @param f The ns_filter that is checked against to update the filter in the
+ * list.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static inline uint8_t prov_ns_add_or_update(struct ns_filters *f)
+{
+	struct list_head *listentry, *listtmp;
+	struct ns_filters *tmp;
+
+	list_for_each_safe(listentry, listtmp, &ns_filters) {
+		tmp = list_entry(listentry, struct ns_filters, list);
+		if (tmp->filter.cgroupns == f->filter.cgroupns
+		    && tmp->filter.utsns == f->filter.utsns
+		    && tmp->filter.ipcns == f->filter.ipcns
+		    && tmp->filter.mntns == f->filter.mntns
+		    && tmp->filter.pidns == f->filter.pidns
+		    && tmp->filter.netns == f->filter.netns
+		    ) {
+			tmp->filter.op = f->filter.op;
+			return 0; // You should only get one
+		}
+	}
+	list_add_tail(&(f->list), &ns_filters);
+	return 0;
+}
+#endif
diff --git a/security/provenance/include/provenance_policy.h b/security/provenance/include/provenance_policy.h
new file mode 100644
index 000000000..0ba0f1b43
--- /dev/null
+++ b/security/provenance/include/provenance_policy.h
@@ -0,0 +1,62 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_POLICY_H
+#define _PROVENANCE_POLICY_H
+
+/*!
+ * @brief provenance capture policy defined by the user.
+ *
+ */
+struct capture_policy {
+	// Whether provenance capture is enabled.
+	bool prov_enabled;
+	// Whether to record provenance of all kernel object.
+	bool prov_all;
+	// Whether nodes should be compressed into one if possible.
+	bool should_compress_node;
+	// Whether edges should be compressed into one if possible.
+	bool should_compress_edge;
+	// every time a relation is recorded the two end nodes will be recorded
+	// again if set to true.
+	bool should_duplicate;
+	// Node to be filtered out (i.e., not recorded).
+	uint64_t prov_node_filter;
+	// Node to be filtered out if it is part of propagate.
+	uint64_t prov_propagate_node_filter;
+	// Edge of category "derived" to be filtered out.
+	uint64_t prov_derived_filter;
+	// Edge of category "generated" to be filtered out.
+	uint64_t prov_generated_filter;
+	// Edge of category "used" to be filtered out.
+	uint64_t prov_used_filter;
+	// Edge of category "informed" to be filtered out.
+	uint64_t prov_informed_filter;
+	// Edge of category "derived" to be filtered out if it is part of
+	// propagate.
+	uint64_t prov_propagate_derived_filter;
+	// Edge of category "generated" to be filtered out if it is part of
+	// propagate.
+	uint64_t prov_propagate_generated_filter;
+	// Edge of category "used" to be filtered out if it is part of
+	// propagate.
+	uint64_t prov_propagate_used_filter;
+	// Edge of category "informed" to be filtered out if it is part of
+	// propagate.
+	uint64_t prov_propagate_informed_filter;
+};
+
+extern struct capture_policy prov_policy;
+
+#endif
diff --git a/security/provenance/include/provenance_query.h b/security/provenance/include/provenance_query.h
new file mode 100644
index 000000000..ddb3642e2
--- /dev/null
+++ b/security/provenance/include/provenance_query.h
@@ -0,0 +1,97 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_QUERY_H
+#define _PROVENANCE_QUERY_H
+
+#include <linux/provenance_query.h>
+
+int init_prov_propagate(void);
+
+static inline int call_provenance_flow(prov_entry_t *from,
+				       prov_entry_t *edge,
+				       prov_entry_t *to)
+{
+	int rc = 0;
+	struct list_head *listentry, *listtmp;
+	struct provenance_query_hooks *fcn;
+
+	list_for_each_safe(listentry, listtmp, &provenance_query_hooks) {
+		fcn = list_entry(listentry, struct provenance_query_hooks,
+				 list);
+		if (fcn->flow)
+			rc |= fcn->flow(from, edge, to);
+	}
+	return rc;
+}
+
+static inline int call_provenance_alloc(prov_entry_t *elt)
+{
+	int rc = 0;
+	struct list_head *listentry, *listtmp;
+	struct provenance_query_hooks *fcn;
+
+	list_for_each_safe(listentry, listtmp, &provenance_query_hooks) {
+		fcn = list_entry(listentry, struct provenance_query_hooks,
+				 list);
+		if (fcn->alloc)
+			rc |= fcn->alloc(elt);
+	}
+	return rc;
+}
+
+static inline int call_provenance_free(prov_entry_t *elt)
+{
+	int rc = 0;
+	struct list_head *listentry, *listtmp;
+	struct provenance_query_hooks *fcn;
+
+	list_for_each_safe(listentry, listtmp, &provenance_query_hooks) {
+		fcn = list_entry(listentry, struct provenance_query_hooks,
+				 list);
+		if (fcn->free)
+			rc |= fcn->free(elt);
+	}
+	return rc;
+}
+
+/*!
+ * @brief Call out_edge and in_edge function.
+ *
+ * Simply call both call_provenance_out_edge and call_provenance_in_edge
+ * function.
+ * @param from The source node provenance entry pointer.
+ * @param to The destination node provenance entry pointer.
+ * @param edge The edge provenance entry pointer.
+ * @return 0 if no error occurred; -EPERM if flow is disallowed. Other error
+ * codes inherited.
+ *
+ */
+static inline int call_query_hooks(prov_entry_t *from,
+				   prov_entry_t *to,
+				   prov_entry_t *edge)
+{
+	int rc = 0;
+
+	rc = call_provenance_flow(from, edge, to);
+	if ((rc & PROVENANCE_RAISE_WARNING) == PROVENANCE_RAISE_WARNING)
+		pr_warn("Provenance: warning raised.\n");
+	if ((rc & PROVENANCE_PREVENT_FLOW) == PROVENANCE_PREVENT_FLOW) {
+		pr_err("Provenance: error raised.\n");
+		edge->relation_info.allowed = FLOW_DISALLOWED;
+		return -EPERM;
+	}
+	return 0;
+}
+#endif
diff --git a/security/provenance/include/provenance_record.h b/security/provenance/include/provenance_record.h
new file mode 100644
index 000000000..984d5dbab
--- /dev/null
+++ b/security/provenance/include/provenance_record.h
@@ -0,0 +1,583 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_RECORD_H
+#define _PROVENANCE_RECORD_H
+
+#include "provenance.h"
+#include "provenance_relay.h"
+#include "memcpy_ss.h"
+
+/*!
+ * @brief This function updates the version of a provenance node.
+ *
+ * Versioning is used to avoid cycles in a provenance graph.
+ * Given a provenance node, unless a certain criteria are met, the node should
+ * be versioned to avoid cycles.
+ * "old_prov" holds the older version of the node while "prov" is updated to
+ * the newer version.
+ * "prov" and "old_prov" have the same information except the version number.
+ * Once the node with a new version is created, a relation between the old and
+ * the new version should be estabilished.
+ * The relation is either "RL_VERSION_TASK" or "RL_VERSION" depending on the
+ * type of the nodes (note that they should be of the same type).
+ * If the nodes are of type AC_TASK, then the relation should be
+ * "RL_VERSION_TASK"; otherwise it is "RL_VERSION".
+ * The new node is not recorded (therefore "recorded" flag is unset) until we
+ * record it in the "__write_relation" function.
+ * The new node is not saved for persistance in this function. So we clear the
+ * saved bit inherited from the older version node.
+ * The criteria that should be met to not to update the version are:
+ * 1. If nodes are set to be compressed and do not have outgoing edges, or
+ * 2. If the argument "type" is a relation whose destination node's version
+ * should not be updated becasue the "type" itself either is a VERSION type or
+ * a NAMED type.
+ * @param type The type of the relation.
+ * @param prov The pointer to the provenance node whose version may need to be
+ * updated.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int __update_version(const uint64_t type,
+					    prov_entry_t *prov)
+{
+	union prov_elt old_prov;
+	int rc = 0;
+
+	if (!provenance_has_outgoing(prov) && prov_policy.should_compress_node)
+		return 0;
+
+	if (filter_update_node(type))
+		return 0;
+
+	// Copy the current provenance prov to old_prov.
+	__memcpy_ss(&old_prov, sizeof(union prov_elt),
+		    prov, sizeof(union prov_elt));
+
+	// Update the version of prov to the newer version.
+	node_identifier(prov).version++;
+	clear_recorded(prov);
+
+	// Record the version relation between two versions of the same
+	// identity.
+	if (node_identifier(prov).type == ACT_TASK)
+		rc = __write_relation(RL_VERSION_TASK, &old_prov,
+				      prov, NULL, 0);
+	else
+		rc = __write_relation(RL_VERSION, &old_prov, prov, NULL, 0);
+	// Newer version now has no outgoing edge.
+	clear_has_outgoing(prov);
+	// For inode provenance persistance
+	clear_saved(prov);
+	return rc;
+}
+
+/*!
+ * @brief This function records a provenance relation (i.e., edge) between two
+ * provenance nodes unless certain criteria are met.
+ *
+ * Unless edges are to be compressed and certain criteria are met,
+ * this function would attempt to update the version of the destination node,
+ * and create a relation between the source node and the newer version (if
+ * version is updated) of the destination node.
+ * Version should be updated every time an information flow occurs,
+ * Unless:
+ * 1. The relation to be recorded here is to explicitly update a version, or
+ * 2. Compression of nodes is used.
+ * The criteria to be met so as not to record the relation are:
+ * 1. Compression of edges are set. (Multiple edges should be compressed to 1
+ * edge.), and
+ * 2. The type of the edges being recorded are the same as before (we only
+ * compress same edges that occurs consecutively on the two nodes).
+ * The relation is recorded by calling the "__write_relation" function.
+ * @param type The type of the relation
+ * @param from The pointer to the source provenance node
+ * @param to The pointer to the destination provenance node
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int record_relation(const uint64_t type,
+					   prov_entry_t *from,
+					   prov_entry_t *to,
+					   const struct file *file,
+					   const uint64_t flags)
+{
+	int rc = 0;
+
+	BUILD_BUG_ON(!prov_type_is_relation(type));
+
+	if (prov_policy.should_compress_edge) {
+		if (node_previous_id(to) == node_identifier(from).id
+		    && node_previous_version(to) == node_identifier(from).version
+		    && node_previous_type(to) == type)
+			return 0;
+
+		node_previous_id(to) = node_identifier(from).id;
+		node_previous_version(to) = node_identifier(from).version;
+		node_previous_type(to) = type;
+	}
+
+	rc = __update_version(type, to);
+	if (rc < 0)
+		return rc;
+	set_has_outgoing(from); // The source node now has an outgoing edge.
+	rc = __write_relation(type, from, to, file, flags);
+	return rc;
+}
+
+/*!
+ * @brief This function record a provenance relation that signifies termination
+ * of an activity.
+ *
+ * Unless certain criteria are met, a termination relation is recorded of an
+ * activity.
+ * Because of this special relation, we will only update the version of the
+ * provenance node that is about to be terminated (i.e., an activity).
+ * The criteria that need to be met not to record this relation are:
+ * 1. The provenance node itself is not recorded and capture all provenance is
+ * not set, or
+ * 2. The provenance node should be filtered out (i.e., not recorded).
+ * @param type The type of termination relation to be recorded.
+ * @param prov The provenance node in question (i.e., about to be terminated).
+ * @return 0 if no errors occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int record_terminate(uint64_t type,
+					    struct provenance *prov)
+{
+	union prov_elt old_prov;
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_close(type));
+
+	if (!provenance_is_recorded(prov_elt(prov)) && !prov_policy.prov_all)
+		return 0;
+	if (filter_node(prov_entry(prov)))
+		return 0;
+
+	__memcpy_ss(&old_prov, sizeof(union prov_elt),
+		    prov_elt(prov), sizeof(union prov_elt));
+	node_identifier(prov_elt(prov)).version++;
+	clear_recorded(prov_elt(prov));
+
+	rc = __write_relation(type, &old_prov, prov_elt(prov), NULL, 0);
+	// Newer version now has no outgoing edge.
+	clear_has_outgoing(prov_elt(prov));
+	return rc;
+}
+
+/*!
+ * @brief This function records the name of a provenance node. The name itself
+ * is a provenance node so there exists a new relation between the name and the
+ * node.
+ *
+ * Unless the node has already have a name or is not recorded, calling this
+ * function will generate a new naming relation between the node and its name.
+ * The name node is transient and should not have any further use.
+ * Therefore, once we record the name node, we will free the memory allocated
+ * for the name provenance node.
+ * The name node has type "ENT_PATH", and the name has max length PATH_MAX.
+ * Depending on the type of the node in question, the relation between the node
+ * and the name node can be:
+ * 1. RL_NAMED_PROCESS, if the node in question is ACT_TASK node, or
+ * 2. RL_NAMED otherwise.
+ * Recording the relation is located in a critical section.
+ * No other thread can update the node in question, when its named is being
+ * attached.
+ * @param node The provenance node to which we create a new name node and a
+ * naming relation between them.
+ * @param name The name of the provenance node.
+ * @return 0 if no error occurred. -ENOMEM if no memory can be allocated for
+ * long provenance name node.
+ *
+ */
+static __always_inline int record_node_name(struct provenance *node,
+					    const char *name,
+					    bool force)
+{
+	union long_prov_elt *fname_prov;
+	int rc;
+
+	if (provenance_is_opaque(prov_elt(node)))
+		return 0;
+
+	if ((provenance_is_name_recorded(prov_elt(node)) && !force)
+	    || !provenance_is_recorded(prov_elt(node)))
+		return 0;
+
+	fname_prov = alloc_long_provenance(ENT_PATH, djb2_hash(name));
+	if (!fname_prov)
+		return -ENOMEM;
+
+	strscpy(fname_prov->file_name_info.name, name, PATH_MAX);
+	fname_prov->file_name_info.length =
+		strnlen(fname_prov->file_name_info.name, PATH_MAX);
+
+	// Here we record the relation.
+	spin_lock(prov_lock(node));
+	rc = record_relation(RL_NAMED, fname_prov,
+			     prov_entry(node), NULL, 0);
+	set_name_recorded(prov_elt(node));
+	spin_unlock(prov_lock(node));
+	free_long_provenance(fname_prov);
+	return rc;
+}
+
+static __always_inline int record_kernel_link(prov_entry_t *node)
+{
+	int rc;
+
+	if (provenance_is_kernel_recorded(node) ||
+	    !provenance_is_recorded(node))
+		return 0;
+
+	rc = record_relation(RL_RAN_ON, prov_machine, node, NULL, 0);
+	set_kernel_recorded(node);
+	return rc;
+}
+
+static __always_inline int current_update_shst(struct provenance *cprov,
+					       bool read);
+
+/*!
+ * @brief Record "used" relation from entity provenance node to activity
+ * provenance node, including its memory state.
+ *
+ * This function applies to only "used" relation between two provenance nodes.
+ * Unless all nodes involved (entity, activity, activity_mem) are set not to be
+ * tracked and prov_all is also turned off,
+ * or unless the relation type is set not to be tracked,
+ * relation will be captured.
+ * At least two relations will possibly be captured:
+ * 1. Whatever relation between entity and activity given by the argument
+ * "type", and
+ * 2. RL_PROC_WRITE relation between activity and activity_mem
+ * If activity_mem has memory mapped files, a SH_WRITE relation may be captured
+ * (see function definition of "current_update_shst").
+ * @param type The type of relation (in the category of "used") between entity
+ * and activity.
+ * @param entity The entity provenance node.
+ * @param activity The activity provenance node.
+ * @param activity_mem The memory provenance node of the activity.
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int uses(const uint64_t type,
+				struct provenance *entity,
+				struct provenance *activity,
+				struct provenance *activity_mem,
+				const struct file *file,
+				const uint64_t flags)
+{
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_used(type));
+
+	// Check if the nodes match some capture options.
+	apply_target(prov_elt(entity));
+	apply_target(prov_elt(activity));
+	apply_target(prov_elt(activity_mem));
+
+	if (provenance_is_opaque(prov_elt(entity))
+	    || provenance_is_opaque(prov_elt(activity))
+	    || provenance_is_opaque(prov_elt(activity_mem)))
+		return 0;
+
+	if (!provenance_is_tracked(prov_elt(entity))
+	    && !provenance_is_tracked(prov_elt(activity))
+	    && !provenance_is_tracked(prov_elt(activity_mem))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(
+		    type, prov_entry(entity), prov_entry(activity)))
+		return 0;
+
+	rc = record_relation(type, prov_entry(entity),
+			     prov_entry(activity), file, flags);
+	if (rc < 0)
+		return rc;
+	rc = record_kernel_link(prov_entry(activity));
+	if (rc < 0)
+		return rc;
+	rc = record_relation(RL_PROC_WRITE, prov_entry(activity),
+			     prov_entry(activity_mem), NULL, 0);
+	if (rc < 0)
+		return rc;
+	return current_update_shst(activity_mem, false);
+}
+
+/*!
+ * @brief Record "used" relation from entity provenance node to activity
+ * provenance node. This function is a stripped-down version of "uses"
+ * function above.
+ *
+ * This function applies to only "used" relation between two provenance nodes
+ * and does almost the same as the above "uses" function.
+ * Except that it does not deal with "activity_mem" provenance node.
+ * @param type The type of relation (in the category of "used") between entity
+ * and activity.
+ * @param entity The entity provenance node.
+ * @param activity The activity provenance node.
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int uses_two(const uint64_t type,
+				    struct provenance *entity,
+				    struct provenance *activity,
+				    const struct file *file,
+				    const uint64_t flags)
+{
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_used(type));
+
+	apply_target(prov_elt(entity));
+	apply_target(prov_elt(activity));
+
+	if (provenance_is_opaque(prov_elt(entity))
+	    || provenance_is_opaque(prov_elt(activity)))
+		return 0;
+
+	if (!provenance_is_tracked(prov_elt(entity))
+	    && !provenance_is_tracked(prov_elt(activity))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(
+		    type, prov_entry(entity), prov_entry(activity)))
+		return 0;
+	rc = record_relation(type, prov_entry(entity),
+			     prov_entry(activity), file, flags);
+	if (rc < 0)
+		return rc;
+	return record_kernel_link(prov_entry(activity));
+}
+
+/*!
+ * @brief Record "generated" relation from activity provenance node (including
+ * its memory state) to entity provenance node.
+ *
+ * This function applies to only "generated" relation between two provenance
+ * nodes.
+ * Unless all nodes involved (entity, activity, activity_mem) are set not to be
+ * tracked and prov_all is also turned off,
+ * or unless the relation type is set not to be tracked,
+ * relation will be captured.
+ * At least two relations will possibly be captured:
+ * 1. RL_PROC_READ relation between activity_mem and activity
+ * 1. Whatever relation between activity and entity given by the argument
+ * "type", and
+ * If activity_mem has memory mapped files, a SH_READ relation may be captured
+ * (see function definition of "current_update_shst").
+ * @param type The type of relation (in the category of "generated") between
+ * activity and entity.
+ * @param activity_mem The memory provenance node of the activity.
+ * @param activity The activity provenance node.
+ * @param entity The entity provenance node.
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int generates(const uint64_t type,
+				     struct provenance *activity_mem,
+				     struct provenance *activity,
+				     struct provenance *entity,
+				     const struct file *file,
+				     const uint64_t flags)
+{
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_generated(type));
+
+	apply_target(prov_elt(activity_mem));
+	apply_target(prov_elt(activity));
+	apply_target(prov_elt(entity));
+
+	if (provenance_is_tracked(prov_elt(activity_mem)))
+		set_tracked(prov_elt(activity));
+
+	if (provenance_is_opaque(prov_elt(activity_mem)))
+		set_opaque(prov_elt(activity));
+
+	if (provenance_is_opaque(prov_elt(entity))
+	    || provenance_is_opaque(prov_elt(activity))
+	    || provenance_is_opaque(prov_elt(activity_mem)))
+		return 0;
+
+	if (!provenance_is_tracked(prov_elt(activity_mem))
+	    && !provenance_is_tracked(prov_elt(activity))
+	    && !provenance_is_tracked(prov_elt(entity))
+	    && !prov_policy.prov_all)
+		return 0;
+
+	if (!should_record_relation(
+		    type, prov_entry(activity), prov_entry(entity)))
+		return 0;
+
+	rc = current_update_shst(activity_mem, true);
+	if (rc < 0)
+		return rc;
+	rc = record_relation(RL_PROC_READ, prov_entry(activity_mem),
+			     prov_entry(activity), NULL, 0);
+	if (rc < 0)
+		return rc;
+	rc = record_kernel_link(prov_entry(activity));
+	if (rc < 0)
+		return rc;
+	rc = record_relation(type, prov_entry(activity),
+			     prov_entry(entity), file, flags);
+	return rc;
+}
+
+/*!
+ * @brief Record "derived" relation from one entity provenance node to another
+ * entity provenance node.
+ *
+ * This function applies to only "derived" relation between two entity
+ * provenance nodes.
+ * Unless both nodes involved (from, to) are set not to be tracked and prov_all
+ * is also turned off,
+ * or unless the relation type is set not to be tracked,
+ * relation will be captured.
+ * The relation is whatever relation between one entity to another given by the
+ * argument "type".
+ * @param type The type of relation (in the category of "derived") between
+ * two entities.
+ * @param from The entity provenance node.
+ * @param to The other entity provenance node.
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int derives(const uint64_t type,
+				   struct provenance *from,
+				   struct provenance *to,
+				   const struct file *file,
+				   const uint64_t flags)
+{
+	BUILD_BUG_ON(!prov_is_derived(type));
+
+	apply_target(prov_elt(from));
+	apply_target(prov_elt(to));
+
+	if (provenance_is_opaque(prov_elt(from))
+	    || provenance_is_opaque(prov_elt(to)))
+		return 0;
+
+	if (!provenance_is_tracked(prov_elt(from))
+	    && !provenance_is_tracked(prov_elt(to))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(type, prov_entry(from), prov_entry(to)))
+		return 0;
+
+	return record_relation(
+		type, prov_entry(from), prov_entry(to), file, flags);
+}
+
+/*!
+ * @brief Record "informed" relation from one activity provenance node to
+ * another activity provenance node.
+ *
+ * This function applies to only "informed" relation between two activity
+ * provenance nodes.
+ * Unless both nodes involved (from, to) are set not to be tracked and prov_all
+ * is also turned off,
+ * or unless the relation type is set not to be tracked,
+ * relation will be captured.
+ * The relation is whatever relation between one activity node to another given
+ * by the argument "type".
+ * @param type The type of relation (in the category of "informed") between
+ * two activities.
+ * @param from The activity provenance node.
+ * @param to The other activity provenance node.
+ * @param file Information related to LSM hooks.
+ * @param flags Information related to LSM hooks.
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int informs(const uint64_t type,
+				   struct provenance *from,
+				   struct provenance *to,
+				   const struct file *file,
+				   const uint64_t flags)
+{
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_informed(type));
+
+	apply_target(prov_elt(from));
+	apply_target(prov_elt(to));
+
+	if (provenance_is_opaque(prov_elt(from))
+	    || provenance_is_opaque(prov_elt(to)))
+		return 0;
+
+	if (!provenance_is_tracked(prov_elt(from))
+	    && !provenance_is_tracked(prov_elt(to))
+	    && !prov_policy.prov_all)
+		return 0;
+	if (!should_record_relation(type, prov_entry(from), prov_entry(to)))
+		return 0;
+	rc = record_kernel_link(prov_entry(from));
+	if (rc < 0)
+		return rc;
+	rc = record_kernel_link(prov_entry(to));
+	if (rc < 0)
+		return rc;
+	return record_relation(
+		type, prov_entry(from), prov_entry(to), file, flags);
+}
+
+static __always_inline int record_influences_kernel(const uint64_t type,
+						    struct provenance *entity,
+						    struct provenance *activity,
+						    const struct file *file)
+{
+	int rc;
+
+	BUILD_BUG_ON(!prov_is_influenced(type));
+
+	apply_target(prov_elt(entity));
+	apply_target(prov_elt(activity));
+
+	if (provenance_is_opaque(prov_elt(entity))
+	    || provenance_is_opaque(prov_elt(activity)))
+		return 0;
+	if (!provenance_is_tracked(prov_elt(entity))
+	    && !provenance_is_tracked(prov_elt(activity))
+	    && !prov_policy.prov_all)
+		return 0;
+	rc = record_relation(RL_LOAD_FILE, prov_entry(entity),
+			     prov_entry(activity), file, 0);
+	if (rc < 0)
+		goto out;
+	rc = record_relation(type, prov_entry(activity), prov_machine, NULL, 0);
+out:
+	return rc;
+}
+
+static __always_inline void record_machine(void)
+{
+	pr_info("Provenance: recording machine node...");
+	__write_node(prov_machine);
+}
+#endif
diff --git a/security/provenance/include/provenance_relay.h b/security/provenance/include/provenance_relay.h
new file mode 100644
index 000000000..fe6680e12
--- /dev/null
+++ b/security/provenance/include/provenance_relay.h
@@ -0,0 +1,189 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_RELAY_H
+#define _PROVENANCE_RELAY_H
+
+#include <linux/relay.h>
+#include <linux/spinlock.h>
+#include <linux/jiffies.h>
+#include <linux/list.h>
+#include <uapi/linux/provenance.h>
+
+#include "provenance_filter.h"
+#include "provenance_query.h"
+#include "memcpy_ss.h"
+
+#define PROV_RELAY_BUFF_EXP 20
+#define PROV_RELAY_BUFF_SIZE ((1 << PROV_RELAY_BUFF_EXP) * sizeof(uint8_t))
+#define PROV_NB_SUBBUF 64
+#define PROV_INITIAL_BUFF_SIZE (1024 * 16)
+#define PROV_INITIAL_LONG_BUFF_SIZE 512
+
+struct boot_buffer {
+	struct list_head list;
+	union prov_elt msg;
+};
+
+struct long_boot_buffer {
+	struct list_head list;
+	union long_prov_elt msg;
+};
+
+void write_boot_buffer(void);
+bool is_relay_full(struct rchan *chan);
+void prov_flush(void);
+
+extern struct kmem_cache *boot_buffer_cache;
+extern spinlock_t lock_buffer;
+extern struct list_head buffer_list;
+
+extern struct kmem_cache *long_boot_buffer_cache;
+extern spinlock_t lock_long_buffer;
+extern struct list_head long_buffer_list;
+
+extern bool relay_ready;
+extern bool relay_initialized;
+
+void prov_write(union prov_elt *msg, size_t size);
+void long_prov_write(union long_prov_elt *msg, size_t size);
+
+static __always_inline void tighten_identifier(union prov_identifier *id)
+{
+	if (id->node_id.type == ENT_PACKET)
+		return;
+	if (id->node_id.boot_id == 0)
+		id->node_id.boot_id = prov_boot_id;
+	id->node_id.machine_id = prov_machine_id;
+}
+
+/*!
+ * @brief Write provenance node to relay buffer.
+ *
+ * There are some checks before the provenance node is written to the relay
+ * buffer which can be consumed by userspace client.
+ * If those checks are passed and the provenance node should be written to the
+ * relay buffer,
+ * Call either "prov_write" or "long_prov_write" depending on whether the node
+ * is a regular or a long provenance node.
+ * Then mark the provenance node as recorded.
+ * The checks include:
+ * 1. If the node has already been recorded and the user policy is set to not
+ * duplicate recorded node, then do not record again.
+ * 2. If the provenance is not a packet node (which means it should have machine
+ * ID) and the provenacne is not recorded,
+ *              record the machine and boot ID because during boot it is
+ * possible that these information is not ready yet (in camconfd) and need to be
+ * set again here.
+ * @param node Provenance node (could be either regular or long)
+ *
+ */
+static __always_inline void __write_node(prov_entry_t *node)
+{
+	BUG_ON(prov_type_is_relation(node_type(node)));
+
+	if (provenance_is_recorded(node) && !prov_policy.should_duplicate)
+		return;
+	tighten_identifier(&get_prov_identifier(node));
+	set_recorded(node);
+	if (prov_type_is_long(node_type(node)))
+		long_prov_write(node, sizeof(union long_prov_elt));
+	else
+		prov_write((union prov_elt *)node, sizeof(union prov_elt));
+}
+
+
+static __always_inline uint64_t current_provid(void)
+{
+	struct provenance *prov = provenance_task(current);
+
+	if (!prov)
+		return 0;
+	return node_identifier(prov_elt(prov)).id;
+}
+
+static __always_inline void __prepare_relation(const uint64_t type,
+					       union prov_elt *relation,
+					       prov_entry_t *f,
+					       prov_entry_t *t,
+					       const struct file *file,
+					       const uint64_t flags)
+{
+	memset(relation, 0, sizeof(union prov_elt));
+	prov_type(relation) = type;
+	relation_identifier(relation).id = prov_next_relation_id();
+	relation_identifier(relation).boot_id = prov_boot_id;
+	relation_identifier(relation).machine_id = prov_machine_id;
+	__memcpy_ss(&(relation->relation_info.snd),
+		    sizeof(union prov_identifier),
+		    &get_prov_identifier(f),
+		    sizeof(union prov_identifier));
+	__memcpy_ss(&(relation->relation_info.rcv),
+		    sizeof(union prov_identifier),
+		    &get_prov_identifier(t),
+		    sizeof(union prov_identifier));
+	if (file) {
+		relation->relation_info.set = FILE_INFO_SET;
+		relation->relation_info.offset = file->f_pos;
+	}
+	relation->relation_info.flags = flags;
+	rcu_read_lock();
+	relation->msg_info.epoch = *epoch;
+	rcu_read_unlock();
+	relation->relation_info.task_id = current_provid();
+}
+
+/*!
+ * @brief Write provenance relation to relay buffer.
+ *
+ * The relation will only be recorded if no user-supplied filter is applicable
+ * to the type of the relation or the end nodes.
+ * This is checked by "should_record_relation" function.
+ * Two end nodes are recorded by calling "__write_node" function before the
+ * relation itself is recorded.
+ * CamQuery is called for provenance runtime analysis of this provenance
+ * relation (i.e., edge) before the relation is recorded to relay.
+ * @param type The type of the relation (i.e., edge)
+ * @param from The source node of the provenance edge
+ * @param to The destination node of the provenance edge
+ * @param file Information related to LSM hooks
+ * @param flags Information related to LSM hooks
+ * @return 0 if no error occurred. Other error codes unknown.
+ *
+ */
+static __always_inline int __write_relation(const uint64_t type,
+					    void *from,
+					    void *to,
+					    const struct file *file,
+					    const uint64_t flags)
+{
+	union prov_elt relation;
+	prov_entry_t *f = from;
+	prov_entry_t *t = to;
+	int rc = 0;
+
+	if (!should_record_relation(type, f, t))
+		return 0;
+
+	// Record the two end nodes
+	__write_node(f);
+	__write_node(t);
+	__prepare_relation(type, &relation, f, t, file, flags);
+	// Call query hooks for propagate tracking.
+	rc = call_query_hooks(f, t, (prov_entry_t *)&relation);
+	// Finally record the relation (i.e., edge) to relay buffer.
+	prov_write(&relation, sizeof(union prov_elt));
+	return rc;
+}
+#endif
diff --git a/security/provenance/include/provenance_task.h b/security/provenance/include/provenance_task.h
new file mode 100644
index 000000000..4f076f676
--- /dev/null
+++ b/security/provenance/include/provenance_task.h
@@ -0,0 +1,582 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_TASK_H
+#define _PROVENANCE_TASK_H
+
+#include <linux/cred.h>
+#include <linux/binfmts.h>
+#include <linux/sched.h>
+#include <linux/sched/task.h>
+#include <linux/sched/mm.h>
+#include <linux/sched/signal.h>
+#include <linux/utsname.h>
+#include <linux/ipc_namespace.h>
+#include <linux/mnt_namespace.h>
+#include <linux/mm.h> // used for get_page
+#include <net/net_namespace.h>
+#include <linux/pid_namespace.h>
+#include <linux/sched/cputime.h>
+#include "../../../fs/mount.h" // nasty
+
+#include "provenance_relay.h"
+#include "provenance_inode.h"
+#include "provenance_policy.h"
+#include "memcpy_ss.h"
+
+#define KB              1024
+#define MB              (1024 * KB)
+#define KB_MASK         (~(KB - 1))
+
+/*!
+ * @summary The following current_XXX functions are to obtain XXX
+ * information of the current process.
+ */
+#define current_pid()    (current->pid)
+static inline uint32_t get_cgroupns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct cgroup_namespace *cns;
+
+	if (task->nsproxy) {
+		cns = task->nsproxy->cgroup_ns;
+		if (cns) {
+			get_cgroup_ns(cns);
+			id = cns->ns.inum;
+			put_cgroup_ns(cns);
+		}
+	}
+	return id;
+}
+
+static inline uint32_t get_utsns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct uts_namespace *ns;
+
+	if (task->nsproxy) {
+		ns = task->nsproxy->uts_ns;
+		if (ns) {
+			get_uts_ns(ns);
+			id = ns->ns.inum;
+			put_uts_ns(ns);
+		}
+	}
+	return id;
+}
+
+static inline uint32_t get_ipcns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct ipc_namespace *ns;
+
+	if (task->nsproxy) {
+		ns = task->nsproxy->ipc_ns;
+		if (ns) {
+			get_ipc_ns(ns);
+			id = ns->ns.inum;
+			put_ipc_ns(ns);
+		}
+	}
+	return id;
+}
+
+static inline uint32_t get_mntns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct mnt_namespace *ns;
+
+	if (task->nsproxy) {
+		ns = task->nsproxy->mnt_ns;
+		if (ns) {
+			get_mnt_ns(ns);
+			id = ns->ns.inum;
+			put_mnt_ns(ns);
+		}
+	}
+	return id;
+}
+
+static inline uint32_t get_netns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct net *ns;
+
+	if (task->nsproxy) {
+		ns = task->nsproxy->net_ns;
+		if (ns) {
+			get_net(ns);
+			id = ns->ns.inum;
+			put_net(ns);
+		}
+	}
+	return id;
+}
+
+static inline uint32_t get_pidns(struct task_struct *task)
+{
+	uint32_t id = 0;
+	struct pid_namespace *ns;
+
+	ns = task_active_pid_ns(task);
+	if (ns)
+		id = ns->ns.inum;
+	return id;
+}
+
+static inline void update_task_namespaces(struct task_struct *task,
+					  struct provenance *prov)
+{
+	task_lock(task);
+	prov_elt(prov)->task_info.utsns = get_utsns(task);
+	prov_elt(prov)->task_info.ipcns = get_ipcns(task);
+	prov_elt(prov)->task_info.mntns = get_mntns(task);
+	prov_elt(prov)->task_info.pidns = get_pidns(task);
+	prov_elt(prov)->task_info.netns = get_netns(task);
+	prov_elt(prov)->task_info.cgroupns = get_cgroupns(task);
+	task_unlock(task);
+}
+
+#define vm_write(flags) ((flags & VM_WRITE) == VM_WRITE)
+#define vm_read(flags) ((flags & VM_READ) == VM_READ)
+#define vm_exec(flags) ((flags & VM_EXEC) == VM_EXEC)
+#define vm_mayshare(flags) ((flags & (VM_SHARED | VM_MAYSHARE)) != 0)
+#define vm_write_mayshare(flags) (vm_write(flags) && vm_mayshare(flags))
+#define vm_read_exec_mayshare(flags) \
+	((vm_read(flags) || vm_exec(flags)) && vm_mayshare(flags))
+
+/*!
+ * @brief Record shared mmap relations of a process.
+ *
+ * The function goes through all the mmapped files of the "current" process,
+ * and for every shared mmaped file,
+ * if the mmapped file has provenance entry,
+ * record provenance relation between the mmaped file and the current process
+ * based on the permission flags and the action (read, exec, or write).
+ * If read/exec, record provenance relation RL_SH_READ by calling
+ * "record_relation" function.
+ * If write, record provenance relation RL_SH_WRITE by calling "record_relation"
+ * function.
+ * @param cprov The cred provenance entry pointer of the current process.
+ * @param read Whether the operation is read or not.
+ * @return 0 if no error occurred or "mm" is NULL; Other error codes inherited
+ * from record_relation function or unknown.
+ *
+ */
+static __always_inline int current_update_shst(struct provenance *cprov,
+					       bool read)
+{
+	struct mm_struct *mm = get_task_mm(current);
+	struct vm_area_struct *vma;
+	struct file *mmapf;
+	vm_flags_t flags;
+	struct provenance *mmprov;
+	int rc = 0;
+
+	if (!mm)
+		return rc;
+	vma = mm->mmap;
+	while (vma) { // We go through all the mmaped files.
+		mmapf = vma->vm_file;
+		if (mmapf) {
+			flags = vma->vm_flags;
+			mmprov = get_file_provenance(mmapf, false);
+			if (mmprov) {
+				if (vm_read_exec_mayshare(flags) && read)
+					rc = record_relation(RL_SH_READ,
+							     prov_entry(mmprov),
+							     prov_entry(cprov),
+							     mmapf,
+							     flags);
+				if (vm_write_mayshare(flags) && !read)
+					rc = record_relation(RL_SH_WRITE,
+							     prov_entry(cprov),
+							     prov_entry(mmprov),
+							     mmapf,
+							     flags);
+			}
+		}
+		vma = vma->vm_next;
+	}
+	mmput_async(mm);        // Release the file.
+	return rc;
+}
+
+/*!
+ * @brief Record the name of the task @task, and associate the name to the
+ * provenance entry @prov by creating a relation by calling "record_node_name"
+ * function.
+ *
+ * Unless failure occurs or certain criteria are met,
+ * we obtain the name of the task from its "mm_exe_file", and create a
+ * RL_NAMED_PROCESS relation by calling "record_node_name" function.
+ * Criteria to be met so as not to record task name are:
+ * 1. The name of the provenance node has already been recorded, or
+ * 2. The provenance node itself is not recorded, or
+ * 3. The "mm_exe_file"'s provenance is set to be opaque (if so, the @prov
+ * itself will be set opaque).
+ * @param task The task whose name is to be obtained.
+ * @param prov The provenance entry that will be associated with the task name.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated for
+ * buffer to hold file path.
+ *
+ */
+static inline int record_task_name(struct task_struct *task,
+				   struct provenance *prov)
+{
+	// const struct cred *cred;
+	struct provenance *fprov;
+	struct mm_struct *mm;
+	struct file *exe_file;
+	char *buffer;
+	char *ptr;
+	int rc = 0;
+
+	if (provenance_is_name_recorded(prov_elt(prov)) ||
+	    !provenance_is_recorded(prov_elt(prov)))
+		return 0;
+
+	mm = get_task_mm(task);
+	if (!mm)
+		goto out;
+	exe_file = get_mm_exe_file(mm);
+	mmput_async(mm);
+	if (exe_file) {
+		fprov = get_file_provenance(exe_file, false);
+		if (provenance_is_opaque(prov_elt(fprov))) {
+			fput(exe_file); // Release the file.
+			set_opaque(prov_elt(prov));
+			goto out;
+		}
+
+		// Memory allocation not allowed to sleep.
+		buffer = kcalloc(PATH_MAX, sizeof(char), GFP_ATOMIC);
+		if (!buffer) {
+			fput(exe_file); // Release the file.
+			rc = -ENOMEM;
+			goto out;
+		}
+		ptr = file_path(exe_file, buffer, PATH_MAX);
+		fput(exe_file); // Release the file.
+		rc = record_node_name(prov, ptr, false);
+		kfree(buffer);
+	}
+out:
+	return rc;
+}
+
+/*!
+ * @brief Update @prov with process performance information associated with
+ * @task.
+ *
+ * @param task The task whose performance information to be obtained.
+ * @param prov The provenance entry to be updated.
+ *
+ */
+static inline void update_task_perf(struct task_struct *task,
+				    struct provenance *prov)
+{
+	struct mm_struct *mm;
+	uint64_t utime;
+	uint64_t stime;
+
+	if (!task)
+		return;
+
+	// time
+	task_cputime_adjusted(task, &utime, &stime);
+	prov_elt(prov)->task_info.utime = div_u64(utime, NSEC_PER_USEC);
+	prov_elt(prov)->task_info.stime = div_u64(stime, NSEC_PER_USEC);
+
+	// memory
+	mm = get_task_mm(task);
+	if (mm) {
+		// KB
+		prov_elt(prov)->task_info.vm =
+			mm->total_vm  * PAGE_SIZE / KB;
+		prov_elt(prov)->task_info.rss =
+			get_mm_rss(mm) * PAGE_SIZE / KB;
+		prov_elt(prov)->task_info.hw_vm =
+			get_mm_hiwater_vm(mm) * PAGE_SIZE / KB;
+		prov_elt(prov)->task_info.hw_rss =
+			get_mm_hiwater_rss(mm) * PAGE_SIZE / KB;
+		mmput_async(mm);
+	}
+	// IO
+#ifdef CONFIG_TASK_IO_ACCOUNTING
+	// KB
+	prov_elt(prov)->task_info.rbytes = task->ioac.read_bytes & KB_MASK;
+	prov_elt(prov)->task_info.wbytes = task->ioac.write_bytes & KB_MASK;
+	prov_elt(prov)->task_info.cancel_wbytes =
+		task->ioac.cancelled_write_bytes & KB_MASK;
+#else
+	// KB
+	prov_elt(prov)->task_info.rbytes = task->ioac.rchar & KB_MASK;
+	prov_elt(prov)->task_info.wbytes = task->ioac.wchar & KB_MASK;
+	prov_elt(prov)->task_info.cancel_wbytes = 0;
+#endif
+}
+
+/*!
+ * @brief Update and return provenance entry of cred structure.
+ *
+ * This function records the name of the current process and associates it with
+ * the cred provenance entry,
+ * unless the provenance is set to be opqaue, in which case no update is
+ * performed.
+ * The cred provenance entry is also updated with UID, GID, namespaces, secid,
+ * and perform information.
+ * @return The pointer to the cred provenance entry.
+ *
+ */
+static inline struct provenance *get_cred_provenance(void)
+{
+	// returns provenance pointer of current_cred().
+	struct provenance *prov = provenance_cred(current_cred());
+	unsigned long irqflags;
+
+	if (provenance_is_opaque(prov_elt(prov)))
+		return prov;
+	record_task_name(current, prov);
+	spin_lock_irqsave_nested(prov_lock(prov),
+				 irqflags, PROVENANCE_LOCK_PROC);
+	prov_elt(prov)->proc_info.tgid = task_tgid_nr(current);
+	prov_elt(prov)->proc_info.uid = __kuid_val(current_uid());
+	prov_elt(prov)->proc_info.gid = __kgid_val(current_gid());
+	security_task_getsecid_obj(current, &(prov_elt(prov)->proc_info.secid));
+	spin_unlock_irqrestore(prov_lock(prov), irqflags);
+	return prov;
+}
+
+/*!
+ * @brief Return the provenance of current process.
+ *
+ * Get the provenance entry of the current process and update its pid and vpid.
+ * We need to update pid and vpid here because when the task is first
+ * initialized,
+ * these information is not available.
+ * @return The provenance entry pointer.
+ *
+ * @todo We do not want to waste resource to attempt to update pid and vpid
+ * every time, since only the first update is needed. Find a better way to do
+ * update only once.
+ */
+static inline struct provenance *get_task_provenance(bool link)
+{
+	struct provenance *tprov = provenance_task(current);
+
+	prov_elt(tprov)->task_info.pid = task_pid_nr(current);
+	prov_elt(tprov)->task_info.vpid = task_pid_vnr(current);
+	update_task_perf(current, tprov);
+	update_task_namespaces(current, tprov);
+	if (!provenance_is_opaque(prov_elt(tprov)) && link)
+		record_kernel_link(prov_entry(tprov));
+	return tprov;
+}
+
+/*!
+ * @brief Return process's provenance from @pid.
+ *
+ * @param pid The pid of the process whose provenance is to be returned.
+ * @return The provenance entry pointer or NULL if process does not exist.
+ *
+ */
+static inline struct provenance *prov_from_vpid(pid_t pid)
+{
+	struct provenance *cprov;
+	// Function is in /kernel/pid.c
+	struct task_struct *dest = find_task_by_vpid(pid);
+
+	if (!dest)
+		return NULL;
+
+	cprov = provenance_cred(__task_cred(dest));
+	if (!cprov)
+		return NULL;
+	return cprov;
+}
+
+/*!
+ * Helper function used to copy arguments.
+ * See fs/exec.c
+ *
+ */
+static inline struct page *__get_arg_page_r(struct linux_binprm *bprm,
+					    unsigned long pos)
+{
+	struct page *page;
+	int ret;
+
+	/*
+	 * We are doing an exec().  'current' is the process
+	 * doing the exec and bprm->mm is the new process's mm.
+	 */
+	mmap_read_lock(bprm->mm);
+	ret = get_user_pages_remote(bprm->mm, pos, 1, FOLL_FORCE,
+				    &page, NULL, NULL);
+	mmap_read_unlock(bprm->mm);
+	if (ret <= 0)
+		return NULL;
+
+	return page;
+}
+
+/*!
+ * Copy bprm arguments. Helper function.
+ * See fs/exec.c
+ *
+ */
+static inline int copy_argv_bprm(struct linux_binprm *bprm, char *buff,
+				 size_t len)
+{
+	int rv = 0;
+	unsigned long ofs, bytes;
+	struct page *page = NULL, *new_page;
+	const char *kaddr;
+	unsigned long pos;
+
+	pos = bprm->p;
+	ofs = pos % PAGE_SIZE;
+	while (len) {
+		new_page = __get_arg_page_r(bprm, pos);
+		if (!new_page) {
+			rv = -E2BIG;
+			goto out;
+		}
+		if (page) {
+			flush_dcache_page(page);
+			kunmap(page);
+			put_page(page);
+		}
+		page = new_page;
+		kaddr = kmap(page);
+
+		flush_cache_page(bprm->vma, pos, page_to_pfn(page));
+
+		bytes = min_t(unsigned int, len, PAGE_SIZE - ofs);
+		__memcpy_ss(buff, len, kaddr + ofs, bytes);
+		pos += bytes;
+		buff += bytes;
+		len -= bytes;
+		ofs = 0;
+	}
+	rv = pos - bprm->p;
+
+out:
+	if (page) {
+		flush_dcache_page(page);
+		kunmap(page);
+		put_page(page);
+	}
+	return rv;
+}
+
+/*!
+ * @brief Record ARG/ENV and create a relation betwene bprm->cred (in hooks.c)
+ * and the args.
+ *
+ * This is a helper funtion used by record_args function.
+ * It records @arg by:
+ * 1. Creating a long provenance entry of type @vtype
+ * (either ENT_ARG or ENT_ENV), and
+ * 2. Recording a provenance relation @etype (either RL_ARG or RL_ENV depending
+ * on @vtype) between the @arg and @prov
+ * The length of the argument should not be longer than PATH_MAX, otherwise we
+ * have to truncate the argument.
+ * Note that the provenance entry is short-lived.
+ * After we record the relation, we will free the long provenance entry.
+ * @param prov The provenance entry pointer to which @arg has a relation.
+ * @param vtype The type of the newly created long provenance entry.
+ * @param etype The relation between @prov and @arg.
+ * @param arg The value of the argument.
+ * @param len The length of the argument.
+ * @return 0 if no error occurred; -ENOMEM if no memory can be allocated from
+ * long provenance cache; Other error codes inherited from record_relation
+ * function or unknown.
+ *
+ */
+static __always_inline int record_arg(struct provenance *prov,
+				      uint64_t vtype,
+				      uint64_t etype,
+				      const char *arg,
+				      size_t len)
+{
+	union long_prov_elt *aprov;
+	int rc = 0;
+
+	aprov = alloc_long_provenance(vtype, 0);
+	if (!aprov)
+		return -ENOMEM;
+	aprov->arg_info.length = len;
+	if (len >= PATH_MAX)
+		aprov->arg_info.truncated = PROV_TRUNCATED;
+	strscpy(aprov->arg_info.value, arg, PATH_MAX);
+
+	rc = record_relation(etype, aprov, prov_entry(prov), NULL, 0);
+	free_long_provenance(aprov);
+	return rc;
+}
+
+/*!
+ * @brief Record all arguments to @prov.
+ *
+ * We will only record all the arguments if @prov is tracked or capture all is
+ * set.
+ * We record both ENT_ARG and ENT_ENV types of arguments and relations RL_ARG
+ * and RL_ENV between those arguments and @prov,
+ * by calling record_arg function.
+ * @param prov The provenance entry pointer where arguments should be associated
+ * with.
+ * @param bprm The binary parameter structure.
+ * @return 0 if no error occurred; -ENOMEM if no memory available to copy
+ * arguments. Other error codes unknown.
+ *
+ */
+static inline int record_args(struct provenance *prov,
+			      struct linux_binprm *bprm)
+{
+	char *argv;
+	char *ptr;
+	unsigned long len;
+	size_t size;
+	int rc = 0;
+	int argc;
+	int envc;
+
+	if (!provenance_is_tracked(prov_elt(prov)) && !prov_policy.prov_all)
+		return 0;
+	len = bprm->exec - bprm->p;
+	argv = kzalloc(len, GFP_KERNEL);
+	if (!argv)
+		return -ENOMEM;
+	rc = copy_argv_bprm(bprm, argv, len);
+	if (rc < 0)
+		return -ENOMEM;
+	argc = bprm->argc;
+	envc = bprm->envc;
+	ptr = argv;
+	while (argc-- > 0) {
+		size = strnlen(ptr, len);
+		record_arg(prov, ENT_ARG, RL_ARG, ptr, size);
+		ptr += size + 1;
+	}
+	while (envc-- > 0) {
+		size = strnlen(ptr, len);
+		record_arg(prov, ENT_ENV, RL_ENV, ptr, size);
+		ptr += size + 1;
+	}
+	kfree(argv);
+	return 0;
+}
+#endif
diff --git a/security/provenance/include/provenance_utils.h b/security/provenance/include/provenance_utils.h
new file mode 100644
index 000000000..c77dc583a
--- /dev/null
+++ b/security/provenance/include/provenance_utils.h
@@ -0,0 +1,31 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#ifndef _PROVENANCE_UTILS_H
+#define _PROVENANCE_UTILS_H
+
+/* djb2 hash implementation by Dan Bernstein */
+static inline uint64_t djb2_hash(const char *str)
+{
+	uint64_t hash = 5381;
+	int c = *str;
+
+	while (c) {
+		hash = ((hash << 5) + hash) + c;
+		c = *++str;
+	}
+	return hash;
+}
+
+#endif
diff --git a/security/provenance/machine.c b/security/provenance/machine.c
new file mode 100644
index 000000000..a8dd3e97b
--- /dev/null
+++ b/security/provenance/machine.c
@@ -0,0 +1,51 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include "provenance.h"
+#include "provenance_machine.h"
+#include "memcpy_ss.h"
+
+static union long_prov_elt __prov_machine;
+union long_prov_elt *prov_machine;
+
+void refresh_prov_machine(void)
+{
+	struct new_utsname *uname = utsname();
+
+	__memcpy_ss(&(prov_machine->machine_info.utsname),
+		    sizeof(struct new_utsname),
+		    uname,
+		    sizeof(struct new_utsname));
+	node_identifier(prov_machine).id = djb2_hash(CAMFLOW_COMMIT);
+	node_identifier(prov_machine).boot_id = prov_boot_id;
+	node_identifier(prov_machine).machine_id = prov_machine_id;
+	clear_recorded(prov_machine);
+}
+
+void init_prov_machine(void)
+{
+	prov_machine = &__prov_machine;
+	prov_machine->machine_info.cam_major = CAMFLOW_VERSION_MAJOR;
+	prov_machine->machine_info.cam_minor = CAMFLOW_VERSION_MINOR;
+	prov_machine->machine_info.cam_patch = CAMFLOW_VERSION_PATCH;
+	__memcpy_ss(prov_machine->machine_info.commit,
+		    PROV_COMMIT_MAX_LENGTH,
+		    CAMFLOW_COMMIT,
+		    strnlen(CAMFLOW_COMMIT,
+			    PROV_COMMIT_MAX_LENGTH));
+	prov_type(prov_machine) = AGT_MACHINE;
+	node_identifier(prov_machine).version = 1;
+	refresh_prov_machine();
+	call_provenance_alloc(prov_machine);
+}
diff --git a/security/provenance/memcpy_ss.c b/security/provenance/memcpy_ss.c
new file mode 100644
index 000000000..52be2c8ee
--- /dev/null
+++ b/security/provenance/memcpy_ss.c
@@ -0,0 +1,66 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/printk.h>
+#include <linux/bug.h>
+
+#include "include/memcpy_ss.h"
+
+#define RSIZE_MAX_MEM (256UL << 20)   // 256MB
+
+int __memcpy_ss(void *dest, __kernel_size_t dmax,
+		const void *src, __kernel_size_t smax)
+{
+	uint8_t *dp = dest;
+	const uint8_t *sp = src;
+
+	if (WARN_ON(!dp)) {
+		pr_err("%s: dest is null.", __func__);
+		return -EFAULT;
+	}
+	if (WARN_ON(dmax == 0)) {
+		pr_err("%s: dmax is 0.", __func__);
+		return -EINVAL;
+	}
+	if (WARN_ON(dmax > RSIZE_MAX_MEM)) {
+		pr_err("%s: dmax is too large.", __func__);
+		return -EINVAL;
+	}
+	if (WARN_ON(!sp)) {
+		pr_err("%s: sp is null.", __func__);
+		memset(dp, 0, dmax);
+		return -EFAULT;
+	}
+	if (WARN_ON(smax == 0)) { // nothing to copy
+		pr_err("%s: smax is 0.", __func__);
+		memset(dp, 0, dmax);
+		return 0;
+	}
+	if (WARN_ON(smax > dmax)) {
+		pr_err("%s: smax greater than dmax.", __func__);
+		memset(dp, 0, dmax);
+		return -EINVAL;
+	}
+	// check for overlap
+	if (WARN_ON(((dp > sp) && (dp < (sp + smax))) ||
+		    ((sp > dp) && (sp < (dp + smax))))) {
+		pr_err("%s: dest and src overlap.", __func__);
+		memset(dp, 0, dmax);
+		return -EINVAL;
+	}
+	memcpy(dp, sp, smax);
+	return 0;
+}
diff --git a/security/provenance/netfilter.c b/security/provenance/netfilter.c
new file mode 100644
index 000000000..a852f7a5b
--- /dev/null
+++ b/security/provenance/netfilter.c
@@ -0,0 +1,155 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <net/net_namespace.h>
+
+#include "provenance.h"
+#include "provenance_net.h"
+#include "provenance_task.h"
+
+/*!
+ * @brief Record provenance of an outgoing packets, which is done through
+ * NetFilter (instead of LSM) hooks.
+ *
+ * We record the provenance relation RL_SND_PACKET by calling "derives"
+ * function.
+ * Information flows from the sending socket to the outgoing packet.
+ * We will not record the provenance if:
+ * 1. The calling process cred's provenance (obtained from current_provenance)
+ * is not recorded or does not exist, or
+ * 2. The socket inode's provenance does not exist.
+ * We will create a new packet provenance node for this relation.
+ * @param skb The socket buffer that contain packet information.
+ * @return always return NF_ACCEPT.
+ *
+ */
+static unsigned int provenance_ipv4_out(void *priv,
+					struct sk_buff *skb,
+					const struct nf_hook_state *state)
+{
+	struct provenance *cprov = provenance_cred_from_task(current);
+	struct provenance *iprov = NULL;
+	struct provenance *pckprov;
+	unsigned long irqflags;
+
+	if (!cprov)
+		return NF_ACCEPT;
+	if (provenance_is_tracked(prov_elt(cprov))) {
+		iprov = get_sk_inode_provenance(skb->sk);
+		if (!iprov)
+			return NF_ACCEPT;
+
+		pckprov = provenance_alloc_with_ipv4_skb(ENT_PACKET, skb);
+		if (!pckprov)
+			return -ENOMEM;
+
+		if (should_record_packet_content(prov_elt(iprov)))
+			record_packet_content(skb, pckprov);
+
+		spin_lock_irqsave(prov_lock(iprov), irqflags);
+		derives(RL_SND_PACKET, iprov, pckprov, NULL, 0);
+		spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+		free_provenance(pckprov);
+	}
+	return NF_ACCEPT;
+}
+
+// Needs to be tested/tweaked
+static unsigned int provenance_ipv4_in(void *priv,
+				       struct sk_buff *skb,
+				       const struct nf_hook_state *state)
+{
+	struct provenance *cprov = provenance_cred_from_task(current);
+	struct provenance *iprov = NULL;
+	struct provenance *pckprov;
+	unsigned long irqflags;
+
+	if (!cprov)
+		return NF_ACCEPT;
+	if (provenance_is_tracked(prov_elt(cprov))) {
+		iprov = get_sk_inode_provenance(skb->sk);
+		if (!iprov)
+			return NF_ACCEPT;
+
+		pckprov = provenance_alloc_with_ipv4_skb(ENT_PACKET, skb);
+		if (!pckprov)
+			return -ENOMEM;
+
+		if (should_record_packet_content(prov_elt(iprov)))
+			record_packet_content(skb, pckprov);
+
+		spin_lock_irqsave(prov_lock(iprov), irqflags);
+		derives(RL_SND_PACKET, iprov, pckprov, NULL, 0);
+		spin_unlock_irqrestore(prov_lock(iprov), irqflags);
+		free_provenance(pckprov);
+	}
+	return NF_ACCEPT;
+}
+
+/* Netfilter hook operations */
+static struct nf_hook_ops provenance_nf_ops[] = {
+	{
+		.hook = provenance_ipv4_out,
+		.pf = NFPROTO_IPV4,
+		.hooknum = NF_INET_LOCAL_OUT,
+		.priority = NF_IP_PRI_LAST,
+	},
+	{
+		.hook = provenance_ipv4_in,
+		.pf = NFPROTO_IPV4,
+		.hooknum = NF_INET_LOCAL_IN,
+		.priority = NF_IP_PRI_FIRST,
+	},
+};
+
+/* Register the hooks */
+static int __net_init provenance_nf_register(struct net *net)
+{
+	return nf_register_net_hooks(net, provenance_nf_ops,
+				     ARRAY_SIZE(provenance_nf_ops));
+}
+/* Unregister the hooks */
+static void __net_exit provenance_nf_unregister(struct net *net)
+{
+	nf_unregister_net_hooks(net, provenance_nf_ops,
+				ARRAY_SIZE(provenance_nf_ops));
+}
+
+static struct pernet_operations provenance_net_ops = {
+	.init = provenance_nf_register,
+	.exit = provenance_nf_unregister,
+};
+
+/*!
+ * Initialization of netfilter hooks.
+ */
+static int __init provenance_nf_ip_init(void)
+{
+	int err;
+
+	pr_info("Provenance: registering netfilter hooks.\n");
+	err = register_pernet_subsys(&provenance_net_ops);
+	if (err)
+		panic("Provenance: register_pernet_subsys error %d\n", err);
+	return 0;
+}
+
+static void __exit provenance_nf_ip_exit(void)
+{
+	pr_info("Provenance: unregistering netfilter hooks.\n");
+	unregister_pernet_subsys(&provenance_net_ops);
+}
+
+module_init(provenance_nf_ip_init);
+module_exit(provenance_nf_ip_exit);
diff --git a/security/provenance/propagate.c b/security/provenance/propagate.c
new file mode 100644
index 000000000..3e3861996
--- /dev/null
+++ b/security/provenance/propagate.c
@@ -0,0 +1,43 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include "provenance.h"
+#include "provenance_query.h"
+
+static int flow(prov_entry_t *from, prov_entry_t *edge, prov_entry_t *to)
+{
+	if (provenance_does_propagate(from) && provenance_is_tracked(from))
+		// can propagate over edge?
+		if (!filter_propagate_relation(prov_type(edge)) &&
+		    !filter_propagate_node(to)) {
+			set_tracked(to);
+			set_propagate(to);
+			provenance_taint_merge(prov_taint(to), prov_taint(from));
+		}
+	return 0;
+}
+
+static struct provenance_query_hooks hooks = {
+	QUERY_HOOK_INIT(flow, flow),
+};
+
+/*!
+ * Register the propagate hooks.
+ */
+int init_prov_propagate(void)
+{
+	register_provenance_query_hooks(&hooks);
+	pr_info("Provenance: propagate ready.\n");
+	return 0;
+}
diff --git a/security/provenance/query.c b/security/provenance/query.c
new file mode 100644
index 000000000..0f609a97d
--- /dev/null
+++ b/security/provenance/query.c
@@ -0,0 +1,49 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <linux/rculist.h>
+#include <uapi/asm-generic/errno-base.h>
+
+#include "provenance_query.h"
+
+/*!
+ * @brief Register provenance query hooks.
+ *
+ * @param hook The provenance_query_hooks pointer.
+ * @return 0 if no error occurred; -ENOMEM if hook is NULL (does not exist yet).
+ *
+ */
+int register_provenance_query_hooks(struct provenance_query_hooks *hook)
+{
+	if (!hook)
+		return -ENOMEM;
+	pr_info("Provenance: registering policy hook...\n");
+	list_add_tail_rcu(&(hook->list), &provenance_query_hooks);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(register_provenance_query_hooks);
+
+/*!
+ * @brief Unregister provenance query hooks.
+ *
+ * @param hook The provenance_query_hooks pointer.
+ * @return 0 if no error occurred.
+ *
+ */
+int unregister_provenance_query_hooks(struct provenance_query_hooks *hook)
+{
+	list_del_rcu(&(hook->list));
+	return 0;
+}
+EXPORT_SYMBOL_GPL(unregister_provenance_query_hooks);
diff --git a/security/provenance/relay.c b/security/provenance/relay.c
new file mode 100644
index 000000000..d4d7b0098
--- /dev/null
+++ b/security/provenance/relay.c
@@ -0,0 +1,356 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/async.h>
+#include <linux/delay.h>
+
+#include "provenance.h"
+#include "provenance_relay.h"
+#include "provenance_machine.h"
+#include "memcpy_ss.h"
+
+#define PROV_BASE_NAME          "provenance"
+#define LONG_PROV_BASE_NAME     "long_provenance"
+
+static struct rchan *prov_chan;
+static struct rchan *long_prov_chan;
+
+/* Global variables: variable declarations in provenance.h */
+atomic64_t prov_relation_id = ATOMIC64_INIT(0);
+atomic64_t prov_node_id = ATOMIC64_INIT(0);
+atomic64_t prov_drop = ATOMIC64_INIT(0);
+
+/*!
+ * @brief Flush every relay buffer element in the relay list.
+ */
+void prov_flush(void)
+{
+	if (unlikely(!relay_ready))
+		return;
+
+	relay_flush(prov_chan);
+	relay_flush(long_prov_chan);
+}
+
+bool is_relay_full(struct rchan *chan)
+{
+	int ret;
+	int rc = 0;
+	struct rchan_buf *buf = *this_cpu_ptr(chan->buf);
+
+	if (buf) {
+		ret = relay_buf_full(buf);
+		if (ret)
+			pr_warn("Provenance: relay (%s) is full.",
+				chan->base_filename);
+		rc += ret;
+	}
+	if (rc)
+		return true;
+	return false;
+}
+
+/*!
+ * @brief Callback function of function "create_buf_file". This callback
+ * function creates relay file in "debugfs".
+ */
+static struct dentry *create_buf_file_handler(const char *filename,
+					      struct dentry *parent,
+					      umode_t mode,
+					      struct rchan_buf *buf,
+					      int *is_global)
+{
+	return debugfs_create_file(filename, mode, parent, buf,
+				   &relay_file_operations);
+}
+
+/*!
+ * @brief Callback function of function "remove_buf_file". This callback
+ * function removes the relay file from "debugfs".
+ */
+static int remove_buf_file_handler(struct dentry *dentry)
+{
+	debugfs_remove(dentry);
+	return 0;
+}
+
+/*
+ * subbuf_start - called on buffer-switch to a new sub-buffer
+ * @buf: the channel buffer containing the new sub-buffer
+ * @subbuf: the start of the new sub-buffer
+ * @prev_subbuf: the start of the previous sub-buffer
+ * @prev_padding: unused space at the end of previous sub-buffer
+ *
+ * return 1 do not log
+ * return 0 do not log
+ */
+static int subbuf_start_handler(struct rchan_buf *buf,
+				void *subbuf,
+				void *prev_subbuf,
+				size_t prev_padding)
+{
+	// the relay is full let's not log
+	// this avoid overwritting
+	if (relay_buf_full(buf)) {
+		// count the number of element dropped
+		atomic64_inc(&prov_drop);
+		return 0;
+	}
+	return 1;
+}
+
+
+/* Relay interface callback functions */
+static struct rchan_callbacks relay_callbacks = {
+	.subbuf_start = subbuf_start_handler,
+	.create_buf_file = create_buf_file_handler,
+	.remove_buf_file = remove_buf_file_handler,
+};
+
+static void __async_handle_boot_buffer(void *_buf, async_cookie_t cookie)
+{
+	struct list_head *ele, *next;
+	struct boot_buffer *entry;
+	unsigned long irqflags;
+
+	msleep(1000);
+	pr_info("Provenance: async boot buffer task %llu running...", cookie);
+
+	spin_lock_irqsave(&lock_buffer, irqflags);
+	list_for_each_safe(ele, next, &buffer_list) {
+		entry = list_entry(ele, struct boot_buffer, list);
+
+		// check if relay is full
+		if (is_relay_full(prov_chan)) {
+			cookie = async_schedule(__async_handle_boot_buffer,
+						NULL);
+			pr_info("Provenance: schedlued async task %llu.",
+				cookie);
+			goto out;
+		}
+
+		// tighten provenance entry
+		tighten_identifier(&get_prov_identifier(&(entry->msg)));
+		if (prov_is_relation(&(entry->msg))) {
+			tighten_identifier(&(entry->msg.relation_info.snd));
+			tighten_identifier(&(entry->msg.relation_info.rcv));
+		}
+
+		relay_write(prov_chan, &(entry->msg), sizeof(union prov_elt));
+
+		list_del(&(entry->list));
+		kmem_cache_free(boot_buffer_cache, entry);
+	}
+	pr_info("Provenance: finished task %llu.", cookie);
+out:
+	spin_unlock_irqrestore(&lock_buffer, irqflags);
+}
+
+static void __async_handle_long_boot_buffer(void *_buf, async_cookie_t cookie)
+{
+	struct list_head *ele, *next;
+	struct long_boot_buffer *entry;
+	unsigned long irqflags;
+
+	msleep(1000);
+	pr_info("Provenance: async long boot buffer task %llu running...",
+		cookie);
+
+	spin_lock_irqsave(&lock_long_buffer, irqflags);
+	list_for_each_safe(ele, next, &long_buffer_list) {
+		entry = list_entry(ele, struct long_boot_buffer, list);
+
+		// check if relay is full
+		if (is_relay_full(prov_chan)) {
+			cookie = async_schedule(__async_handle_long_boot_buffer,
+						NULL);
+			pr_info("Provenance: schedlued long async task %llu.",
+				cookie);
+			goto out;
+		}
+
+		// tighten provenance entry
+		tighten_identifier(&get_prov_identifier(&(entry->msg)));
+
+		relay_write(long_prov_chan, &(entry->msg),
+			    sizeof(union long_prov_elt));
+
+		list_del(&(entry->list));
+		kmem_cache_free(long_boot_buffer_cache, entry);
+	}
+	pr_info("Provenance: finished task %llu.", cookie);
+out:
+	spin_unlock_irqrestore(&lock_long_buffer, irqflags);
+}
+
+bool relay_ready;
+bool relay_initialized;
+/*!
+ * @brief Write whatever in boot buffer to relay buffer when relay buffer is
+ * ready.
+ *
+ * This function writes what's in boot_buffer to relay buffer for regular
+ * provenance entries,
+ * and what's in long_boot_buffer to relay buffer for long provenance entries.
+ * It also frees memory after it is done writing.
+ * Once done, set boolean value relay_ready to true to signal that relay buffer
+ * is ready to be used.
+ *
+ */
+void write_boot_buffer(void)
+{
+	async_cookie_t cookie;
+
+	if (prov_machine_id == 0 || prov_boot_id == 0 || !relay_initialized)
+		return;
+
+	relay_ready = true;
+
+	refresh_prov_machine();
+	relay_write(long_prov_chan, prov_machine, sizeof(union long_prov_elt));
+
+	// asynchronously empty the buffer
+	if (!list_empty(&buffer_list)) {
+		cookie = async_schedule(__async_handle_boot_buffer, NULL);
+		pr_info("Provenance: schedlued async task %llu.",
+			cookie);
+	}
+
+	// asynchronously empty the buffer
+	if (!list_empty(&long_buffer_list)) {
+		cookie = async_schedule(__async_handle_long_boot_buffer, NULL);
+		pr_info("Provenance: schedlued long async task %llu.", cookie);
+	}
+}
+
+static void insert_boot_buffer(union prov_elt *msg)
+{
+	struct boot_buffer *tmp = kmem_cache_zalloc(boot_buffer_cache,
+						    GFP_ATOMIC);
+	unsigned long irqflags;
+
+	__memcpy_ss(&(tmp->msg), sizeof(union prov_elt),
+		    msg, sizeof(union prov_elt));
+	INIT_LIST_HEAD(&(tmp->list));
+	spin_lock_irqsave(&lock_buffer, irqflags);
+	list_add(&(tmp->list), &buffer_list);
+	spin_unlock_irqrestore(&lock_buffer, irqflags);
+}
+
+/*!
+ * @brief Write provenance information to relay buffer or to boot buffer if
+ * relay buffer is not ready yet during boot.
+ *
+ * If in an unlikely event that relay is not ready, provenance information
+ * should be written to the boot buffer.
+ * However, in an unlikely event that the boot buffer is full, an error is
+ * thrown.
+ * Otherwise (i.e., boot buffer is not full) provenance information is written
+ * to the next empty slot in the boot buffer.
+ * If relay buffer is ready, write to relay buffer.
+ * This is because once provenance is read from a relay buffer, it will be
+ * consumed from the buffer.
+ * We therefore need to write to multiple relay buffers if we want to
+ * consume/use same provenance data multiple times.
+ * @param msg Provenance information to be written to either boot buffer or
+ * relay buffer.
+ * @return NULL
+ *
+ */
+void prov_write(union prov_elt *msg, size_t size)
+{
+	BUG_ON(prov_type_is_long(prov_type(msg)));
+
+	prov_jiffies(msg) = get_jiffies_64();
+	if (unlikely(!relay_ready))
+		insert_boot_buffer(msg);
+	else {
+		prov_written = true;
+		relay_write(prov_chan, msg, size);
+	}
+}
+
+static void insert_long_boot_buffer(union long_prov_elt *msg)
+{
+	struct long_boot_buffer *tmp = kmem_cache_zalloc(long_boot_buffer_cache,
+							 GFP_ATOMIC);
+	unsigned long irqflags;
+
+	__memcpy_ss(&(tmp->msg), sizeof(union long_prov_elt),
+		    msg, sizeof(union long_prov_elt));
+	INIT_LIST_HEAD(&(tmp->list));
+	spin_lock_irqsave(&lock_long_buffer, irqflags);
+	list_add(&(tmp->list), &long_buffer_list);
+	spin_unlock_irqrestore(&lock_long_buffer, irqflags);
+}
+
+/*!
+ * @brief Write long provenance information to relay buffer or to boot buffer if
+ * relay buffer is not ready yet during boot.
+ *
+ * This function performs the same function as "prov_write" function except that
+ * it writes a long provenance information,
+ * instead of regular provenance information to the buffer.
+ * @param msg Long provenance information to be written to either long boot
+ * buffer or long relay buffer.
+ *
+ */
+void long_prov_write(union long_prov_elt *msg, size_t size)
+{
+	BUG_ON(!prov_type_is_long(prov_type(msg)));
+
+	prov_jiffies(msg) = get_jiffies_64();
+	if (unlikely(!relay_ready))
+		insert_long_boot_buffer(msg);
+	else {
+		prov_written = true;
+		relay_write(long_prov_chan, msg, size);
+	}
+}
+
+/*!
+ * @brief Initialize relay buffer for provenance.
+ *
+ * Initialize provenance relay buffer with a base relay buffer for regular
+ * provenance entries,
+ * and a base relay buffer for long provenance entries.
+ * Then we can write down whatever is in the boot buffer to relay buffer.
+ * @return 0 if no error occurred.
+ *
+ */
+static int __init relay_prov_init(void)
+{
+	prov_chan = relay_open(PROV_BASE_NAME, NULL, PROV_RELAY_BUFF_SIZE,
+			       PROV_NB_SUBBUF, &relay_callbacks, NULL);
+	if (!prov_chan)
+		panic("Provenance: relay_open failure\n");
+
+	long_prov_chan = relay_open(LONG_PROV_BASE_NAME, NULL,
+				    PROV_RELAY_BUFF_SIZE,
+				    PROV_NB_SUBBUF,
+				    &relay_callbacks,
+				    NULL);
+	if (!long_prov_chan)
+		panic("Provenance: relay_open failure\n");
+
+	relay_initialized = true;
+	init_prov_machine();
+	write_boot_buffer();
+	pr_info("Provenance: relay ready.\n");
+	return 0;
+}
+fs_initcall(relay_prov_init);
diff --git a/security/provenance/type.c b/security/provenance/type.c
new file mode 100644
index 000000000..adf071f46
--- /dev/null
+++ b/security/provenance/type.c
@@ -0,0 +1,547 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2015-2016 University of Cambridge,
+ * Copyright (C) 2016-2017 Harvard University,
+ * Copyright (C) 2017-2018 University of Cambridge,
+ * Copyright (C) 2018-2021 University of Bristol
+ *
+ * Author: Thomas Pasquier <thomas.pasquier@bristol.ac.uk>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2, as
+ * published by the Free Software Foundation; either version 2 of the License,
+ * or (at your option) any later version.
+ */
+#include <linux/provenance_types.h>
+#include "provenance.h"
+
+/* relation string name */
+static const char RL_STR_UNKNOWN[] = "unknown";                                                         // unknown relation should not happen
+static const char RL_STR_READ[] = "read";                                                               // read to inode
+static const char RL_STR_READ_IOCTL[] = "read_ioctl";                                                   // ioctl read
+static const char RL_STR_WRITE[] = "write";                                                             // write to inode
+static const char RL_STR_WRITE_IOCTL[] = "write_ioctl";                                                 // ioctl write
+static const char RL_STR_CLONE_MEM[] = "clone_mem";                                                     // memory copy on clone
+static const char RL_STR_MSG_CREATE[] = "msg_create";                                                   // create msg (IPC message passing)
+static const char RL_STR_SOCKET_CREATE[] = "socket_create";                                             // create socket
+static const char RL_STR_SOCKET_PAIR_CREATE[] = "socket_pair_create";                                   // create socket pair
+static const char RL_STR_INODE_CREATE[] = "inode_create";                                               // create inode
+static const char RL_STR_SETUID[] = "setuid";                                                           // setuid
+static const char RL_STR_SETGID[] = "setpgid";                                                          // setpgid
+static const char RL_STR_GETGID[] = "getpgid";                                                          // getpgid
+static const char RL_STR_SH_WRITE[] = "sh_write";                                                       // writing to shared state
+static const char RL_STR_PROC_WRITE[] = "memory_write";                                                 // writing to process memory (i.e. shared between thread)
+static const char RL_STR_BIND[] = "bind";                                                               // socket bind operation
+static const char RL_STR_CONNECT[] = "connect";                                                         // socket connection operation
+static const char RL_STR_CONNECT_UNIX_STREAM[] = "connect_unix_stream";                                 // unix stream socket connection operation
+static const char RL_STR_LISTEN[] = "listen";                                                           // socket listen operation
+static const char RL_STR_ACCEPT[] = "accept";                                                           // socket accept operation
+static const char RL_STR_OPEN[] = "open";                                                               // file open operation
+static const char RL_STR_FILE_RCV[] = "file_rcv";                                                       // open file descriptor recevied through IPC
+static const char RL_STR_FILE_LOCK[] = "file_lock";                                                     // represent file lock operation
+static const char RL_STR_FILE_SIGIO[] = "file_sigio";                                                   // represent IO signal
+static const char RL_STR_VERSION[] = "version_entity";                                                  // connect version of entity object
+static const char RL_STR_MUNMAP[] = "munmap";                                                           // munmap operation
+static const char RL_STR_SHMDT[] = "shmdt";                                                             // shmdt operation
+static const char RL_STR_LINK[] = "link";                                                               // create a link
+static const char RL_STR_RENAME[] = "rename";                                                           // rename inode
+static const char RL_STR_UNLINK[] = "unlink";                                                           // delete a link
+static const char RL_STR_SYMLINK[] = "symlink";                                                         // create a symlink
+static const char RL_STR_SPLICE_IN[] = "splice_in";                                                     // pipe splice operation from in file
+static const char RL_STR_SPLICE_OUT[] = "splice_out";                                                   // pipe splice operation to out file
+static const char RL_STR_SETATTR[] = "setattr";                                                         // setattr operation (task -> iattr)
+static const char RL_STR_SETATTR_INODE[] = "setattr_inode";                                             // setattr operation (iattr -> inode)
+static const char RL_STR_ACCEPT_SOCKET[] = "accept_socket";                                             // accept operation (parent -> child socket)
+static const char RL_STR_SETXATTR[] = "setxattr";                                                       // setxattr operation (task -> xattr)
+static const char RL_STR_SETXATTR_INODE[] = "setxattr_inode";                                           // setxattr operation (xattr -> inode)
+static const char RL_STR_RMVXATTR[] = "removexattr";                                                    // remove xattr operation (task -> xattr)
+static const char RL_STR_RMVXATTR_INODE[] = "removexattr_inode";                                        // remove xattr operation (xattr -> inode)
+static const char RL_STR_NAMED[] = "named";                                                             // connect path to inode
+static const char RL_STR_ADDRESSED[] = "addressed";                                                     // connect address to inode
+static const char RL_STR_EXEC[] = "exec";                                                               // exec operation
+static const char RL_STR_EXEC_TASK[] = "exec_task";                                                     // exec operation
+static const char RL_STR_PCK_CNT[] = "packet_content";                                                  // connect netwrok packet to its content
+static const char RL_STR_CLONE[] = "clone";                                                             // clone operation
+static const char RL_STR_VERSION_TASK[] = "version_activity";                                           // connection two versions of an activity
+static const char RL_STR_SEARCH[] = "search";                                                           // search operation on directory
+static const char RL_STR_GETATTR[] = "getattr";                                                         // getattr operation
+static const char RL_STR_GETXATTR[] = "getxattr";                                                       // getxattr operation (xattr -> process)
+static const char RL_STR_GETXATTR_INODE[] = "getxattr_inode";                                           // getxattr operation (inode -> xattr)
+static const char RL_STR_LSTXATTR[] = "listxattr";                                                      // listxattr operation
+static const char RL_STR_READ_LINK[] = "read_link";                                                     // readlink operation
+static const char RL_STR_MMAP[] = "mmap";                                                               // mmap mountings
+static const char RL_STR_MMAP_PRIVATE[] = "mmap_private";                                               // mmap private mounting
+static const char RL_STR_SH_READ[] = "sh_read";                                                         // sh_read operation
+static const char RL_STR_PROC_READ[] = "memory_read";                                                   // read from process memory
+static const char RL_STR_SND[] = "send";                                                                // send over socket
+static const char RL_STR_SND_PACKET[] = "send_packet";                                                  // connect socket to packet on send operation
+static const char RL_STR_SND_UNIX[] = "send_unix";                                                      // send over unix socket
+static const char RL_STR_SND_MSG[] = "send_msg";                                                        // send message
+static const char RL_STR_SND_MSG_Q[] = "send_msg_queue";                                                // send message to queue
+static const char RL_STR_RCV[] = "receive";                                                             // receive socket operation
+static const char RL_STR_RCV_PACKET[] = "receive_packet";                                               // connect packet to socket on receive operation
+static const char RL_STR_RCV_UNIX[] = "receive_unix";                                                   // receive on unix socket
+static const char RL_STR_RCV_MSG[] = "receive_msg";                                                     // receive message
+static const char RL_STR_RCV_MSG_Q[] = "receive_msg_queue";                                             // receive message from queue
+static const char RL_STR_PERM[] = "perm_check";                                                         // check permission
+static const char RL_STR_TERMINATE_TASK[] = "terminate_task";                                           // created when task data structure is freed
+static const char RL_STR_TERMINATE_PROC[] = "terminate_proc";                                           // created when cred data structure is freed
+static const char RL_STR_FREED[] = "free";                                                              // created when an inode is freed
+static const char RL_STR_ARG[] = "arg";                                                                 // connect arg value to process
+static const char RL_STR_ENV[] = "env";                                                                 // connect env value to process
+static const char RL_STR_LOG[] = "log";                                                                 // connect string to task
+static const char RL_STR_SH_ATTACH[] = "sh_attach";                                                     // attach sh
+static const char RL_STR_SH_CREATE[] = "sh_create";                                                     // sh create perm
+static const char RL_STR_LOAD_FILE[] = "load_file";                                                     // load file into kernel
+static const char RL_STR_RAN_ON[] = "ran_on";                                                           // task run on this machine
+static const char RL_STR_LOAD_UNKNOWN[] = "load_unknown";                                               // load file into kernel
+static const char RL_STR_LOAD_FIRMWARE[] = "load_firmware";                                             // load file into kernel
+static const char RL_STR_LOAD_MODULE[] = "load_module";                                                 // load file into kernel
+static const char RL_STR_LOAD_KEXEC_IMAGE[] = "load_kexec_image";                                       // load file into kernel
+static const char RL_STR_LOAD_KEXEC_INITRAMFS[] = "load_kexec_initramfs";                               // load file into kernel
+static const char RL_STR_LOAD_POLICY[] = "load_policy";                                                 // load file into kernel
+static const char RL_STR_LOAD_CERTIFICATE[] = "load_certificate";                                       // load file into kernel
+static const char RL_STR_LOAD_UNDEFINED[] = "load_undefined";                                           // load file into kernel
+static const char RL_STR_PTRACE_ATTACH[] = "ptrace_attach";                                             // ptrace attach effect on memory
+static const char RL_STR_PTRACE_READ[] = "ptrace_read";                                                 // ptrace read from mem
+static const char RL_STR_PTRACE_ATTACH_TASK[] = "ptrace_attach_task";                                   // write info via ptrace effect on task
+static const char RL_STR_PTRACE_READ_TASK[] = "ptrace_read_task";                                       // read info via ptrace effect on task
+static const char RL_STR_PTRACE_TRACEME[] = "ptrace_traceme";                                           // track ptrace_traceme
+static const char RL_STR_DERIVED_DISC[] = "derived_disc";                                               // disclosed type
+static const char RL_STR_GENERATED_DISC[] = "generated_disc";                                           // disclosed type
+static const char RL_STR_USED_DISC[] = "used_disc";                                                     // disclosed type
+static const char RL_STR_INFORMED_DISC[] = "informed_disc";                                             // disclosed type
+static const char RL_STR_INFLUENCED_DISC[] = "influenced_disc";                                         // disclosed type
+static const char RL_STR_ASSOCIATED_DISC[] = "associated_disc";                                         // disclosed type
+
+/* node string name */
+static const char ND_STR_UNKNOWN[] = "unknown";                                 // unkown node type should normally not appear
+static const char ND_STR_STR[] = "string";                                      // simple string used for disclosed log
+static const char ND_STR_TASK[] = "task";                                       // represent a thread from user space POV
+static const char ND_STR_INODE_UNKNOWN[] = "inode_unknown";                     // unknown inode type should normally not appear
+static const char ND_STR_INODE_LINK[] = "link";                                 // link
+static const char ND_STR_INODE_FILE[] = "file";                                 // standard file
+static const char ND_STR_INODE_DIRECTORY[] = "directory";                       // directory
+static const char ND_STR_INODE_CHAR[] = "char";                                 // character device
+static const char ND_STR_INODE_BLOCK[] = "block";                               // block device
+static const char ND_STR_INODE_PIPE[] = "pipe";                                 // pipe
+static const char ND_STR_INODE_SOCKET[] = "socket";                             // network socket
+static const char ND_STR_MSG[] = "msg";                                         // msg as in IPC message passing
+static const char ND_STR_SHM[] = "shm";                                         // shared memory
+static const char ND_STR_ADDR[] = "address";                                    // network address
+static const char ND_STR_SB[] = "sb";                                           // superblock
+static const char ND_STR_PATH[] = "path";                                       // path associated with a file
+static const char ND_STR_DISC_ENTITY[] = "disc_entity";                         // descilosed node representing an entity
+static const char ND_STR_DISC_ACTIVITY[] = "disc_activity";                     // descilosed node representing an activity
+static const char ND_STR_DISC_AGENT[] = "disc_agent";                           // disclosed node representing an agent
+static const char ND_STR_MACHINE[] = "machine";                                 // machine representing an agent
+static const char ND_STR_PACKET[] = "packet";                                   // network packet
+static const char ND_STR_IATTR[] = "iattr";                                     // inode attributes value
+static const char ND_STR_XATTR[] = "xattr";                                     // extended attributes value
+static const char ND_STR_PCKCNT[] = "packet_content";                           // the content of network packet
+static const char ND_STR_ARG[] = "argv";                                        // argument passed to a process
+static const char ND_STR_ENV[] = "envp";                                        // environment parameter
+static const char ND_STR_PROC[] = "process_memory";                             // process memory
+
+#define MATCH_AND_RETURN(str1, str2, v)	\
+	do { if (strcmp(str1, str2) == 0) { return v; } } while (0)
+/* transform from relation ID to string representation */
+const char *relation_str(uint64_t type)
+{
+	switch (type) {
+	case RL_READ:
+		return RL_STR_READ;
+	case RL_READ_IOCTL:
+		return RL_STR_READ_IOCTL;
+	case RL_WRITE:
+		return RL_STR_WRITE;
+	case RL_WRITE_IOCTL:
+		return RL_STR_WRITE_IOCTL;
+	case RL_CLONE_MEM:
+		return RL_STR_CLONE_MEM;
+	case RL_MSG_CREATE:
+		return RL_STR_MSG_CREATE;
+	case RL_SOCKET_CREATE:
+		return RL_STR_SOCKET_CREATE;
+	case RL_SOCKET_PAIR_CREATE:
+		return RL_STR_SOCKET_PAIR_CREATE;
+	case RL_INODE_CREATE:
+		return RL_STR_INODE_CREATE;
+	case RL_SETUID:
+		return RL_STR_SETUID;
+	case RL_SETGID:
+		return RL_STR_SETGID;
+	case RL_GETGID:
+		return RL_STR_GETGID;
+	case RL_BIND:
+		return RL_STR_BIND;
+	case RL_CONNECT:
+		return RL_STR_CONNECT;
+	case RL_CONNECT_UNIX_STREAM:
+		return RL_STR_CONNECT_UNIX_STREAM;
+	case RL_LISTEN:
+		return RL_STR_LISTEN;
+	case RL_ACCEPT:
+		return RL_STR_ACCEPT;
+	case RL_OPEN:
+		return RL_STR_OPEN;
+	case RL_FILE_RCV:
+		return RL_STR_FILE_RCV;
+	case RL_FILE_LOCK:
+		return RL_STR_FILE_LOCK;
+	case RL_FILE_SIGIO:
+		return RL_STR_FILE_SIGIO;
+	case RL_VERSION:
+		return RL_STR_VERSION;
+	case RL_MUNMAP:
+		return RL_STR_MUNMAP;
+	case RL_SHMDT:
+		return RL_STR_SHMDT;
+	case RL_LINK:
+		return RL_STR_LINK;
+	case RL_RENAME:
+		return RL_STR_RENAME;
+	case RL_UNLINK:
+		return RL_STR_UNLINK;
+	case RL_SYMLINK:
+		return RL_STR_SYMLINK;
+	case RL_SPLICE_OUT:
+		return RL_STR_SPLICE_OUT;
+	case RL_SPLICE_IN:
+		return RL_STR_SPLICE_IN;
+	case RL_SETATTR:
+		return RL_STR_SETATTR;
+	case RL_SETATTR_INODE:
+		return RL_STR_SETATTR_INODE;
+	case RL_ACCEPT_SOCKET:
+		return RL_STR_ACCEPT_SOCKET;
+	case RL_SETXATTR:
+		return RL_STR_SETXATTR;
+	case RL_SETXATTR_INODE:
+		return RL_STR_SETXATTR_INODE;
+	case RL_RMVXATTR:
+		return RL_STR_RMVXATTR;
+	case RL_RMVXATTR_INODE:
+		return RL_STR_RMVXATTR_INODE;
+	case RL_NAMED:
+		return RL_STR_NAMED;
+	case RL_ADDRESSED:
+		return RL_STR_ADDRESSED;
+	case RL_EXEC:
+		return RL_STR_EXEC;
+	case RL_EXEC_TASK:
+		return RL_STR_EXEC_TASK;
+	case RL_PCK_CNT:
+		return RL_STR_PCK_CNT;
+	case RL_CLONE:
+		return RL_STR_CLONE;
+	case RL_VERSION_TASK:
+		return RL_STR_VERSION_TASK;
+	case RL_SEARCH:
+		return RL_STR_SEARCH;
+	case RL_GETATTR:
+		return RL_STR_GETATTR;
+	case RL_GETXATTR:
+		return RL_STR_GETXATTR;
+	case RL_GETXATTR_INODE:
+		return RL_STR_GETXATTR_INODE;
+	case RL_LSTXATTR:
+		return RL_STR_LSTXATTR;
+	case RL_READ_LINK:
+		return RL_STR_READ_LINK;
+	case RL_MMAP:
+		return RL_STR_MMAP;
+	case RL_MMAP_PRIVATE:
+		return RL_STR_MMAP_PRIVATE;
+	case RL_SND:
+		return RL_STR_SND;
+	case RL_SND_PACKET:
+		return RL_STR_SND_PACKET;
+	case RL_SND_UNIX:
+		return RL_STR_SND_UNIX;
+	case RL_SND_MSG:
+		return RL_STR_SND_MSG;
+	case RL_SND_MSG_Q:
+		return RL_STR_SND_MSG_Q;
+	case RL_RCV:
+		return RL_STR_RCV;
+	case RL_RCV_PACKET:
+		return RL_STR_RCV_PACKET;
+	case RL_RCV_UNIX:
+		return RL_STR_RCV_UNIX;
+	case RL_RCV_MSG:
+		return RL_STR_RCV_MSG;
+	case RL_RCV_MSG_Q:
+		return RL_STR_RCV_MSG_Q;
+	case RL_PERM:
+		return RL_STR_PERM;
+	case RL_SH_READ:
+		return RL_STR_SH_READ;
+	case RL_PROC_READ:
+		return RL_STR_PROC_READ;
+	case RL_SH_WRITE:
+		return RL_STR_SH_WRITE;
+	case RL_PROC_WRITE:
+		return RL_STR_PROC_WRITE;
+	case RL_TERMINATE_TASK:
+		return RL_STR_TERMINATE_TASK;
+	case RL_TERMINATE_PROC:
+		return RL_STR_TERMINATE_PROC;
+	case RL_FREED:
+		return RL_STR_FREED;
+	case RL_ARG:
+		return RL_STR_ARG;
+	case RL_ENV:
+		return RL_STR_ENV;
+	case RL_LOG:
+		return RL_STR_LOG;
+	case RL_SH_ATTACH:
+		return RL_STR_SH_ATTACH;
+	case RL_SH_CREATE:
+		return RL_STR_SH_CREATE;
+	case RL_LOAD_FILE:
+		return RL_STR_LOAD_FILE;
+	case RL_LOAD_UNKNOWN:
+		return RL_STR_LOAD_UNKNOWN;
+	case RL_LOAD_FIRMWARE:
+		return RL_STR_LOAD_FIRMWARE;
+	case RL_LOAD_MODULE:
+		return RL_STR_LOAD_MODULE;
+	case RL_LOAD_KEXEC_IMAGE:
+		return RL_STR_LOAD_KEXEC_IMAGE;
+	case RL_LOAD_KEXEC_INITRAMFS:
+		return RL_STR_LOAD_KEXEC_INITRAMFS;
+	case RL_LOAD_POLICY:
+		return RL_STR_LOAD_POLICY;
+	case RL_LOAD_CERTIFICATE:
+		return RL_STR_LOAD_CERTIFICATE;
+	case RL_LOAD_UNDEFINED:
+		return RL_STR_LOAD_UNDEFINED;
+	case RL_PTRACE_ATTACH:
+		return RL_STR_PTRACE_ATTACH;
+	case RL_PTRACE_READ:
+		return RL_STR_PTRACE_READ;
+	case RL_PTRACE_ATTACH_TASK:
+		return RL_STR_PTRACE_ATTACH_TASK;
+	case RL_PTRACE_READ_TASK:
+		return RL_STR_PTRACE_READ_TASK;
+	case RL_PTRACE_TRACEME:
+		return RL_STR_PTRACE_TRACEME;
+	case RL_RAN_ON:
+		return RL_STR_RAN_ON;
+	case RL_DERIVED_DISC:
+		return RL_STR_DERIVED_DISC;
+	case RL_GENERATED_DISC:
+		return RL_STR_GENERATED_DISC;
+	case RL_USED_DISC:
+		return RL_STR_USED_DISC;
+	case RL_INFORMED_DISC:
+		return RL_STR_INFORMED_DISC;
+	case RL_INFLUENCED_DISC:
+		return RL_STR_INFLUENCED_DISC;
+	case RL_ASSOCIATED_DISC:
+		return RL_STR_ASSOCIATED_DISC;
+	default:
+		return RL_STR_UNKNOWN;
+	}
+}
+EXPORT_SYMBOL_GPL(relation_str);
+
+/* from string representation to relation ID */
+uint64_t relation_id(const char *str)
+{
+	MATCH_AND_RETURN(str, RL_STR_READ, RL_READ);
+	MATCH_AND_RETURN(str, RL_STR_READ_IOCTL, RL_READ_IOCTL);
+	MATCH_AND_RETURN(str, RL_STR_WRITE, RL_WRITE);
+	MATCH_AND_RETURN(str, RL_STR_WRITE_IOCTL, RL_WRITE_IOCTL);
+	MATCH_AND_RETURN(str, RL_STR_CLONE_MEM, RL_CLONE_MEM);
+	MATCH_AND_RETURN(str, RL_STR_MSG_CREATE, RL_MSG_CREATE);
+	MATCH_AND_RETURN(str, RL_STR_SOCKET_CREATE, RL_SOCKET_CREATE);
+	MATCH_AND_RETURN(str, RL_STR_SOCKET_PAIR_CREATE, RL_SOCKET_PAIR_CREATE);
+	MATCH_AND_RETURN(str, RL_STR_INODE_CREATE, RL_INODE_CREATE);
+	MATCH_AND_RETURN(str, RL_STR_SETUID, RL_SETUID);
+	MATCH_AND_RETURN(str, RL_STR_SETGID, RL_SETGID);
+	MATCH_AND_RETURN(str, RL_STR_GETGID, RL_GETGID);
+	MATCH_AND_RETURN(str, RL_STR_BIND, RL_BIND);
+	MATCH_AND_RETURN(str, RL_STR_CONNECT, RL_CONNECT);
+	MATCH_AND_RETURN(str, RL_STR_CONNECT_UNIX_STREAM, RL_CONNECT_UNIX_STREAM);
+	MATCH_AND_RETURN(str, RL_STR_LISTEN, RL_LISTEN);
+	MATCH_AND_RETURN(str, RL_STR_ACCEPT, RL_ACCEPT);
+	MATCH_AND_RETURN(str, RL_STR_OPEN, RL_OPEN);
+	MATCH_AND_RETURN(str, RL_STR_FILE_RCV, RL_FILE_RCV);
+	MATCH_AND_RETURN(str, RL_STR_FILE_LOCK, RL_FILE_LOCK);
+	MATCH_AND_RETURN(str, RL_STR_FILE_SIGIO, RL_FILE_SIGIO);
+	MATCH_AND_RETURN(str, RL_STR_VERSION, RL_VERSION);
+	MATCH_AND_RETURN(str, RL_STR_MUNMAP, RL_MUNMAP);
+	MATCH_AND_RETURN(str, RL_STR_SHMDT, RL_SHMDT);
+	MATCH_AND_RETURN(str, RL_STR_LINK, RL_LINK);
+	MATCH_AND_RETURN(str, RL_STR_RENAME, RL_RENAME);
+	MATCH_AND_RETURN(str, RL_STR_UNLINK, RL_UNLINK);
+	MATCH_AND_RETURN(str, RL_STR_SYMLINK, RL_SYMLINK);
+	MATCH_AND_RETURN(str, RL_STR_SPLICE_IN, RL_SPLICE_IN);
+	MATCH_AND_RETURN(str, RL_STR_SPLICE_OUT, RL_SPLICE_OUT);
+	MATCH_AND_RETURN(str, RL_STR_SETATTR, RL_SETATTR);
+	MATCH_AND_RETURN(str, RL_STR_SETATTR_INODE, RL_SETATTR_INODE);
+	MATCH_AND_RETURN(str, RL_STR_ACCEPT_SOCKET, RL_ACCEPT_SOCKET);
+	MATCH_AND_RETURN(str, RL_STR_SETXATTR, RL_SETXATTR);
+	MATCH_AND_RETURN(str, RL_STR_SETXATTR_INODE, RL_SETXATTR_INODE);
+	MATCH_AND_RETURN(str, RL_STR_RMVXATTR, RL_RMVXATTR);
+	MATCH_AND_RETURN(str, RL_STR_RMVXATTR_INODE, RL_RMVXATTR_INODE);
+	MATCH_AND_RETURN(str, RL_STR_READ_LINK, RL_READ_LINK);
+	MATCH_AND_RETURN(str, RL_STR_NAMED, RL_NAMED);
+	MATCH_AND_RETURN(str, RL_STR_ADDRESSED, RL_ADDRESSED);
+	MATCH_AND_RETURN(str, RL_STR_EXEC, RL_EXEC);
+	MATCH_AND_RETURN(str, RL_STR_EXEC_TASK, RL_EXEC_TASK);
+	MATCH_AND_RETURN(str, RL_STR_PCK_CNT, RL_PCK_CNT);
+	MATCH_AND_RETURN(str, RL_STR_CLONE, RL_CLONE);
+	MATCH_AND_RETURN(str, RL_STR_VERSION_TASK, RL_VERSION_TASK);
+	MATCH_AND_RETURN(str, RL_STR_SEARCH, RL_SEARCH);
+	MATCH_AND_RETURN(str, RL_STR_GETATTR, RL_GETATTR);
+	MATCH_AND_RETURN(str, RL_STR_GETXATTR, RL_GETXATTR);
+	MATCH_AND_RETURN(str, RL_STR_GETXATTR_INODE, RL_GETXATTR_INODE);
+	MATCH_AND_RETURN(str, RL_STR_LSTXATTR, RL_LSTXATTR);
+	MATCH_AND_RETURN(str, RL_STR_MMAP, RL_MMAP);
+	MATCH_AND_RETURN(str, RL_STR_MMAP_PRIVATE, RL_MMAP_PRIVATE);
+	MATCH_AND_RETURN(str, RL_STR_SND, RL_SND);
+	MATCH_AND_RETURN(str, RL_STR_SND_PACKET, RL_SND_PACKET);
+	MATCH_AND_RETURN(str, RL_STR_SND_UNIX, RL_SND_UNIX);
+	MATCH_AND_RETURN(str, RL_STR_SND_MSG, RL_SND_MSG);
+	MATCH_AND_RETURN(str, RL_STR_SND_MSG_Q, RL_SND_MSG_Q);
+	MATCH_AND_RETURN(str, RL_STR_RCV, RL_RCV);
+	MATCH_AND_RETURN(str, RL_STR_RCV_PACKET, RL_RCV_PACKET);
+	MATCH_AND_RETURN(str, RL_STR_RCV_UNIX, RL_RCV_UNIX);
+	MATCH_AND_RETURN(str, RL_STR_RCV_MSG, RL_RCV_MSG);
+	MATCH_AND_RETURN(str, RL_STR_RCV_MSG_Q, RL_RCV_MSG_Q);
+	MATCH_AND_RETURN(str, RL_STR_PERM, RL_PERM);
+	MATCH_AND_RETURN(str, RL_STR_SH_READ, RL_SH_READ);
+	MATCH_AND_RETURN(str, RL_STR_PROC_READ, RL_PROC_READ);
+	MATCH_AND_RETURN(str, RL_STR_SH_WRITE, RL_SH_WRITE);
+	MATCH_AND_RETURN(str, RL_STR_PROC_WRITE, RL_PROC_WRITE);
+	MATCH_AND_RETURN(str, RL_STR_TERMINATE_TASK, RL_TERMINATE_TASK);
+	MATCH_AND_RETURN(str, RL_STR_TERMINATE_PROC, RL_TERMINATE_PROC);
+	MATCH_AND_RETURN(str, RL_STR_FREED, RL_FREED);
+	MATCH_AND_RETURN(str, RL_STR_ARG, RL_ARG);
+	MATCH_AND_RETURN(str, RL_STR_ENV, RL_ENV);
+	MATCH_AND_RETURN(str, RL_STR_LOG, RL_LOG);
+	MATCH_AND_RETURN(str, RL_STR_SH_ATTACH, RL_SH_ATTACH);
+	MATCH_AND_RETURN(str, RL_STR_SH_CREATE, RL_SH_CREATE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_FILE, RL_LOAD_FILE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_UNKNOWN, RL_LOAD_UNKNOWN);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_FIRMWARE, RL_LOAD_FIRMWARE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_MODULE, RL_LOAD_MODULE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_KEXEC_IMAGE, RL_LOAD_KEXEC_IMAGE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_KEXEC_INITRAMFS,
+			 RL_LOAD_KEXEC_INITRAMFS);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_POLICY, RL_LOAD_POLICY);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_CERTIFICATE, RL_LOAD_CERTIFICATE);
+	MATCH_AND_RETURN(str, RL_STR_LOAD_UNDEFINED, RL_LOAD_UNDEFINED);
+	MATCH_AND_RETURN(str, RL_STR_PTRACE_ATTACH, RL_PTRACE_ATTACH);
+	MATCH_AND_RETURN(str, RL_STR_PTRACE_READ, RL_PTRACE_READ);
+	MATCH_AND_RETURN(str, RL_STR_PTRACE_ATTACH_TASK, RL_PTRACE_ATTACH_TASK);
+	MATCH_AND_RETURN(str, RL_STR_PTRACE_READ_TASK, RL_PTRACE_READ_TASK);
+	MATCH_AND_RETURN(str, RL_STR_PTRACE_TRACEME, RL_PTRACE_TRACEME);
+	MATCH_AND_RETURN(str, RL_STR_RAN_ON, RL_RAN_ON);
+	MATCH_AND_RETURN(str, RL_STR_DERIVED_DISC, RL_DERIVED_DISC);
+	MATCH_AND_RETURN(str, RL_STR_GENERATED_DISC, RL_GENERATED_DISC);
+	MATCH_AND_RETURN(str, RL_STR_USED_DISC, RL_USED_DISC);
+	MATCH_AND_RETURN(str, RL_STR_INFORMED_DISC, RL_INFORMED_DISC);
+	MATCH_AND_RETURN(str, RL_STR_INFLUENCED_DISC, RL_INFLUENCED_DISC);
+	MATCH_AND_RETURN(str, RL_STR_ASSOCIATED_DISC, RL_ASSOCIATED_DISC);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(relation_id);
+
+/* from node ID to string representation */
+const char *node_str(uint64_t type)
+{
+	switch (type) {
+	case ENT_STR:
+		return ND_STR_STR;
+	case ACT_TASK:
+		return ND_STR_TASK;
+	case ENT_INODE_UNKNOWN:
+		return ND_STR_INODE_UNKNOWN;
+	case ENT_INODE_LINK:
+		return ND_STR_INODE_LINK;
+	case ENT_INODE_FILE:
+		return ND_STR_INODE_FILE;
+	case ENT_INODE_DIRECTORY:
+		return ND_STR_INODE_DIRECTORY;
+	case ENT_INODE_CHAR:
+		return ND_STR_INODE_CHAR;
+	case ENT_INODE_BLOCK:
+		return ND_STR_INODE_BLOCK;
+	case ENT_INODE_PIPE:
+		return ND_STR_INODE_PIPE;
+	case ENT_INODE_SOCKET:
+		return ND_STR_INODE_SOCKET;
+	case ENT_MSG:
+		return ND_STR_MSG;
+	case ENT_SHM:
+		return ND_STR_SHM;
+	case ENT_ADDR:
+		return ND_STR_ADDR;
+	case ENT_SBLCK:
+		return ND_STR_SB;
+	case ENT_PATH:
+		return ND_STR_PATH;
+	case ENT_DISC:
+		return ND_STR_DISC_ENTITY;
+	case ACT_DISC:
+		return ND_STR_DISC_ACTIVITY;
+	case AGT_DISC:
+		return ND_STR_DISC_AGENT;
+	case AGT_MACHINE:
+		return ND_STR_MACHINE;
+	case ENT_PACKET:
+		return ND_STR_PACKET;
+	case ENT_IATTR:
+		return ND_STR_IATTR;
+	case ENT_XATTR:
+		return ND_STR_XATTR;
+	case ENT_PCKCNT:
+		return ND_STR_PCKCNT;
+	case ENT_ARG:
+		return ND_STR_ARG;
+	case ENT_ENV:
+		return ND_STR_ENV;
+	case ENT_PROC:
+		return ND_STR_PROC;
+	default:
+		return ND_STR_UNKNOWN;
+	}
+}
+EXPORT_SYMBOL_GPL(node_str);
+
+/* from string to node ID representation */
+uint64_t node_id(const char *str)
+{
+	MATCH_AND_RETURN(str, ND_STR_TASK, ACT_TASK);
+	MATCH_AND_RETURN(str, ND_STR_INODE_UNKNOWN, ENT_INODE_UNKNOWN);
+	MATCH_AND_RETURN(str, ND_STR_INODE_LINK, ENT_INODE_LINK);
+	MATCH_AND_RETURN(str, ND_STR_INODE_FILE, ENT_INODE_FILE);
+	MATCH_AND_RETURN(str, ND_STR_INODE_DIRECTORY, ENT_INODE_DIRECTORY);
+	MATCH_AND_RETURN(str, ND_STR_INODE_CHAR, ENT_INODE_CHAR);
+	MATCH_AND_RETURN(str, ND_STR_INODE_BLOCK, ENT_INODE_BLOCK);
+	MATCH_AND_RETURN(str, ND_STR_INODE_PIPE, ENT_INODE_PIPE);
+	MATCH_AND_RETURN(str, ND_STR_INODE_SOCKET, ENT_INODE_SOCKET);
+	MATCH_AND_RETURN(str, ND_STR_MSG, ENT_MSG);
+	MATCH_AND_RETURN(str, ND_STR_SHM, ENT_SHM);
+	MATCH_AND_RETURN(str, ND_STR_ADDR, ENT_ADDR);
+	MATCH_AND_RETURN(str, ND_STR_SB, ENT_SBLCK);
+	MATCH_AND_RETURN(str, ND_STR_PATH, ENT_PATH);
+	MATCH_AND_RETURN(str, ND_STR_DISC_ENTITY, ENT_DISC);
+	MATCH_AND_RETURN(str, ND_STR_DISC_ACTIVITY, ACT_DISC);
+	MATCH_AND_RETURN(str, ND_STR_DISC_AGENT, AGT_DISC);
+	MATCH_AND_RETURN(str, ND_STR_MACHINE, AGT_MACHINE);
+	MATCH_AND_RETURN(str, ND_STR_PACKET, ENT_PACKET);
+	MATCH_AND_RETURN(str, ND_STR_IATTR, ENT_IATTR);
+	MATCH_AND_RETURN(str, ND_STR_XATTR, ENT_XATTR);
+	MATCH_AND_RETURN(str, ND_STR_PCKCNT, ENT_PCKCNT);
+	MATCH_AND_RETURN(str, ND_STR_ARG, ENT_ARG);
+	MATCH_AND_RETURN(str, ND_STR_ENV, ENT_ENV);
+	MATCH_AND_RETURN(str, ND_STR_PROC, ENT_PROC);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(node_id);
-- 
2.33.1

